{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file of tickers\n",
    "file_path = '/Users/pranavsharma/Downloads/Yahoo Ticker Symbols - September 2017.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "usa_rows = df[df['Unnamed: 4'] == 'USA']\n",
    "tickers = usa_rows.iloc[:, 0].tolist()\n",
    "\n",
    "ticker_lst= ['NVDA','AAPL', 'MSFT', 'AMZN', 'GOOG', 'META', 'TSLA', 'BRK-B', 'AVGO', 'WMT', 'LLY', 'JPM', 'V', 'UNH', 'XOM', 'ORCL', 'MA', 'COST', 'HD', 'PG', 'NFLX' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ticker_lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m EPS\u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m RMSE\u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mticker_lst\u001b[49m:\n\u001b[1;32m      8\u001b[0m     ticker_id\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m      9\u001b[0m     stock_data\u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mdownload(i, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-10-6\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-11-20\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ticker_lst' is not defined"
     ]
    }
   ],
   "source": [
    "ticker_id=[]\n",
    "ND_price=[]\n",
    "PD_price= []\n",
    "EPS= []\n",
    "RMSE= []\n",
    "\n",
    "for i in ticker_lst:\n",
    "    ticker_id.append(i)\n",
    "    stock_data= yf.download(i, start=\"2024-10-6\", end=\"2024-11-20\")\n",
    "    closing= stock_data['Close'][i].tolist()\n",
    "\n",
    "    working_df= pd.DataFrame(columns=['Close'])\n",
    "    working_df['Close']= closing\n",
    "    # Create lag features\n",
    "    working_df['Lag_1'] = working_df['Close'].shift(1)  # Previous day's close\n",
    "    working_df['Lag_2'] = working_df['Close'].shift(2)  # 2 days ago\n",
    "    working_df['Lag_3'] = working_df['Close'].shift(3)  # 3 days ago\n",
    "\n",
    "    # Drop rows with NaN values caused by the lag\n",
    "    working_df = working_df.dropna()\n",
    "\n",
    "    X = working_df[['Lag_1', 'Lag_2', 'Lag_3']]  # Features\n",
    "    y = working_df['Close']  # Target variable\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "    # Train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    RMSE.append(rmse)\n",
    "    \n",
    "    # Prepare the last row of lagged features\n",
    "    last_row = working_df.iloc[-1][['Lag_1', 'Lag_2', 'Lag_3']].values.reshape(1, -1)\n",
    "\n",
    "    # Predict the next day's closing price\n",
    "    next_day_price = model.predict(last_row)\n",
    "    ND_price.append(next_day_price[0])\n",
    "    #print(\"Predicted Next Day Price:\", next_day_price[0])\n",
    "    EPS.append(next_day_price - closing[-1])\n",
    "    PD_price.append(closing[-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df= pd.DataFrame()\n",
    "analysis_df['ticker_id']= ticker_id\n",
    "analysis_df['ND_Predictions']=ND_price\n",
    "analysis_df['PD_price']=PD_price\n",
    "analysis_df['EPS']= EPS\n",
    "analysis_df['RMSE']= RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_id</th>\n",
       "      <th>ND_Predictions</th>\n",
       "      <th>PD_price</th>\n",
       "      <th>EPS</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>139.070303</td>\n",
       "      <td>147.009995</td>\n",
       "      <td>[-7.939691157716624]</td>\n",
       "      <td>4.176227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>229.943609</td>\n",
       "      <td>228.279999</td>\n",
       "      <td>[1.663610121379719]</td>\n",
       "      <td>2.739078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>416.998601</td>\n",
       "      <td>417.790009</td>\n",
       "      <td>[-0.7914071876763273]</td>\n",
       "      <td>4.564206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>204.630460</td>\n",
       "      <td>204.610001</td>\n",
       "      <td>[0.020459513114104766]</td>\n",
       "      <td>5.695086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>179.696753</td>\n",
       "      <td>179.580002</td>\n",
       "      <td>[0.11675097935864187]</td>\n",
       "      <td>3.482673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>META</td>\n",
       "      <td>565.862931</td>\n",
       "      <td>561.090027</td>\n",
       "      <td>[4.7729037529039715]</td>\n",
       "      <td>10.500131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>354.031549</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>[8.031549114468078]</td>\n",
       "      <td>21.053204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BRK-B</td>\n",
       "      <td>467.107251</td>\n",
       "      <td>468.859985</td>\n",
       "      <td>[-1.7527348458533538]</td>\n",
       "      <td>4.235288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AVGO</td>\n",
       "      <td>170.624378</td>\n",
       "      <td>165.350006</td>\n",
       "      <td>[5.274371747801666]</td>\n",
       "      <td>4.036959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WMT</td>\n",
       "      <td>84.208978</td>\n",
       "      <td>86.599998</td>\n",
       "      <td>[-2.3910200843735367]</td>\n",
       "      <td>1.120242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LLY</td>\n",
       "      <td>734.227786</td>\n",
       "      <td>729.729980</td>\n",
       "      <td>[4.497805806936185]</td>\n",
       "      <td>22.299607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JPM</td>\n",
       "      <td>241.547585</td>\n",
       "      <td>243.089996</td>\n",
       "      <td>[-1.5424117714026124]</td>\n",
       "      <td>3.905200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V</td>\n",
       "      <td>313.826752</td>\n",
       "      <td>311.850006</td>\n",
       "      <td>[1.9767457946920786]</td>\n",
       "      <td>2.211883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UNH</td>\n",
       "      <td>587.280419</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>[10.280419047025248]</td>\n",
       "      <td>5.391155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XOM</td>\n",
       "      <td>120.046524</td>\n",
       "      <td>118.629997</td>\n",
       "      <td>[1.4165266612725844]</td>\n",
       "      <td>1.041127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORCL</td>\n",
       "      <td>182.492517</td>\n",
       "      <td>188.899994</td>\n",
       "      <td>[-6.407476907116603]</td>\n",
       "      <td>4.409334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MA</td>\n",
       "      <td>522.460063</td>\n",
       "      <td>519.460022</td>\n",
       "      <td>[3.000041509804987]</td>\n",
       "      <td>3.987863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COST</td>\n",
       "      <td>919.961253</td>\n",
       "      <td>930.150024</td>\n",
       "      <td>[-10.188771030388239]</td>\n",
       "      <td>11.469953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HD</td>\n",
       "      <td>408.697607</td>\n",
       "      <td>406.799988</td>\n",
       "      <td>[1.8976194846022736]</td>\n",
       "      <td>3.884593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PG</td>\n",
       "      <td>169.730878</td>\n",
       "      <td>170.759995</td>\n",
       "      <td>[-1.029116937669329]</td>\n",
       "      <td>1.414132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>839.719453</td>\n",
       "      <td>871.320007</td>\n",
       "      <td>[-31.60055402221451]</td>\n",
       "      <td>21.266972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker_id  ND_Predictions    PD_price                     EPS       RMSE\n",
       "0       NVDA      139.070303  147.009995    [-7.939691157716624]   4.176227\n",
       "1       AAPL      229.943609  228.279999     [1.663610121379719]   2.739078\n",
       "2       MSFT      416.998601  417.790009   [-0.7914071876763273]   4.564206\n",
       "3       AMZN      204.630460  204.610001  [0.020459513114104766]   5.695086\n",
       "4       GOOG      179.696753  179.580002   [0.11675097935864187]   3.482673\n",
       "5       META      565.862931  561.090027    [4.7729037529039715]  10.500131\n",
       "6       TSLA      354.031549  346.000000     [8.031549114468078]  21.053204\n",
       "7      BRK-B      467.107251  468.859985   [-1.7527348458533538]   4.235288\n",
       "8       AVGO      170.624378  165.350006     [5.274371747801666]   4.036959\n",
       "9        WMT       84.208978   86.599998   [-2.3910200843735367]   1.120242\n",
       "10       LLY      734.227786  729.729980     [4.497805806936185]  22.299607\n",
       "11       JPM      241.547585  243.089996   [-1.5424117714026124]   3.905200\n",
       "12         V      313.826752  311.850006    [1.9767457946920786]   2.211883\n",
       "13       UNH      587.280419  577.000000    [10.280419047025248]   5.391155\n",
       "14       XOM      120.046524  118.629997    [1.4165266612725844]   1.041127\n",
       "15      ORCL      182.492517  188.899994    [-6.407476907116603]   4.409334\n",
       "16        MA      522.460063  519.460022     [3.000041509804987]   3.987863\n",
       "17      COST      919.961253  930.150024   [-10.188771030388239]  11.469953\n",
       "18        HD      408.697607  406.799988    [1.8976194846022736]   3.884593\n",
       "19        PG      169.730878  170.759995    [-1.029116937669329]   1.414132\n",
       "20      NFLX      839.719453  871.320007    [-31.60055402221451]  21.266972"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Line plot for prices\n",
    "# ax1.plot(analysis_df.index, analysis_df['PD_price'], label='Actual Price', color='blue')\n",
    "# ax1.plot(analysis_df.index, analysis_df['ND_Predictions'], label='Predicted Price', color='green', linestyle='--')\n",
    "ax1.plot(analysis_df.index, analysis_df['EPS'], label='EPS ', color='blue')\n",
    "ax1.set_xlabel('Index')\n",
    "ax1.set_ylabel('Price', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "# Bar plot for RMSE\n",
    "ax2 = ax1.twinx()\n",
    "bars = ax2.bar(analysis_df.index, analysis_df['RMSE'], alpha=0.3, label='RMSE', color='orange')\n",
    "ax2.set_ylabel('RMSE', color='orange')\n",
    "ax2.tick_params(axis='y', labelcolor='orange')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "# Add TickerID labels on top of bars\n",
    "for bar, ticker_id in zip(bars, analysis_df['ticker_id']):\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2,  # X-coordinate (center of the bar)\n",
    "        bar.get_height(),                  # Y-coordinate (top of the bar)\n",
    "        ticker_id,                         # TickerID to display\n",
    "        ha='center', va='bottom', fontsize=9, rotation=45, color='black'\n",
    "    )\n",
    "\n",
    "plt.title('EPS and RMSE ')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_id</th>\n",
       "      <th>ND_Predictions</th>\n",
       "      <th>PD_price</th>\n",
       "      <th>EPS</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>141.930263</td>\n",
       "      <td>136.020004</td>\n",
       "      <td>[5.910258231811127]</td>\n",
       "      <td>3.997196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>230.336161</td>\n",
       "      <td>232.869995</td>\n",
       "      <td>[-2.533833692123494]</td>\n",
       "      <td>2.688838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>419.447780</td>\n",
       "      <td>418.790009</td>\n",
       "      <td>[0.6577711100059673]</td>\n",
       "      <td>4.241778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>200.049872</td>\n",
       "      <td>201.449997</td>\n",
       "      <td>[-1.4001245095134323]</td>\n",
       "      <td>6.173560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>168.916708</td>\n",
       "      <td>169.429993</td>\n",
       "      <td>[-0.5132842263525959]</td>\n",
       "      <td>3.416303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>META</td>\n",
       "      <td>571.154368</td>\n",
       "      <td>565.109985</td>\n",
       "      <td>[6.044383050197325]</td>\n",
       "      <td>13.072712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>346.185548</td>\n",
       "      <td>338.589996</td>\n",
       "      <td>[7.595552091293939]</td>\n",
       "      <td>14.805429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BRK-B</td>\n",
       "      <td>471.216121</td>\n",
       "      <td>477.429993</td>\n",
       "      <td>[-6.213871580130899]</td>\n",
       "      <td>5.063052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AVGO</td>\n",
       "      <td>170.166202</td>\n",
       "      <td>164.820007</td>\n",
       "      <td>[5.346194944251721]</td>\n",
       "      <td>5.449303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WMT</td>\n",
       "      <td>89.540440</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>[0.04044046276352731]</td>\n",
       "      <td>1.552482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LLY</td>\n",
       "      <td>746.171100</td>\n",
       "      <td>755.000000</td>\n",
       "      <td>[-8.828900204808633]</td>\n",
       "      <td>17.633636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JPM</td>\n",
       "      <td>245.249105</td>\n",
       "      <td>250.289993</td>\n",
       "      <td>[-5.040888645039615]</td>\n",
       "      <td>3.673061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V</td>\n",
       "      <td>310.408944</td>\n",
       "      <td>313.190002</td>\n",
       "      <td>[-2.781057982192408]</td>\n",
       "      <td>2.510007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UNH</td>\n",
       "      <td>586.223123</td>\n",
       "      <td>605.830017</td>\n",
       "      <td>[-19.606893615823992]</td>\n",
       "      <td>13.240187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XOM</td>\n",
       "      <td>121.544716</td>\n",
       "      <td>119.970001</td>\n",
       "      <td>[1.574714664246855]</td>\n",
       "      <td>1.323861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORCL</td>\n",
       "      <td>190.571884</td>\n",
       "      <td>187.990005</td>\n",
       "      <td>[2.5818783591489876]</td>\n",
       "      <td>2.827889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MA</td>\n",
       "      <td>518.891309</td>\n",
       "      <td>526.599976</td>\n",
       "      <td>[-7.708666143424807]</td>\n",
       "      <td>4.892273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COST</td>\n",
       "      <td>957.218634</td>\n",
       "      <td>960.890015</td>\n",
       "      <td>[-3.6713805711794976]</td>\n",
       "      <td>15.022616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HD</td>\n",
       "      <td>414.890780</td>\n",
       "      <td>428.670013</td>\n",
       "      <td>[-13.77923305580066]</td>\n",
       "      <td>8.479558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PG</td>\n",
       "      <td>174.663804</td>\n",
       "      <td>177.389999</td>\n",
       "      <td>[-2.726195424978073]</td>\n",
       "      <td>2.459291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>898.904545</td>\n",
       "      <td>865.590027</td>\n",
       "      <td>[33.314518354840175]</td>\n",
       "      <td>18.765669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker_id  ND_Predictions    PD_price                    EPS       RMSE\n",
       "0       NVDA      141.930263  136.020004    [5.910258231811127]   3.997196\n",
       "1       AAPL      230.336161  232.869995   [-2.533833692123494]   2.688838\n",
       "2       MSFT      419.447780  418.790009   [0.6577711100059673]   4.241778\n",
       "3       AMZN      200.049872  201.449997  [-1.4001245095134323]   6.173560\n",
       "4       GOOG      168.916708  169.429993  [-0.5132842263525959]   3.416303\n",
       "5       META      571.154368  565.109985    [6.044383050197325]  13.072712\n",
       "6       TSLA      346.185548  338.589996    [7.595552091293939]  14.805429\n",
       "7      BRK-B      471.216121  477.429993   [-6.213871580130899]   5.063052\n",
       "8       AVGO      170.166202  164.820007    [5.346194944251721]   5.449303\n",
       "9        WMT       89.540440   89.500000  [0.04044046276352731]   1.552482\n",
       "10       LLY      746.171100  755.000000   [-8.828900204808633]  17.633636\n",
       "11       JPM      245.249105  250.289993   [-5.040888645039615]   3.673061\n",
       "12         V      310.408944  313.190002   [-2.781057982192408]   2.510007\n",
       "13       UNH      586.223123  605.830017  [-19.606893615823992]  13.240187\n",
       "14       XOM      121.544716  119.970001    [1.574714664246855]   1.323861\n",
       "15      ORCL      190.571884  187.990005   [2.5818783591489876]   2.827889\n",
       "16        MA      518.891309  526.599976   [-7.708666143424807]   4.892273\n",
       "17      COST      957.218634  960.890015  [-3.6713805711794976]  15.022616\n",
       "18        HD      414.890780  428.670013   [-13.77923305580066]   8.479558\n",
       "19        PG      174.663804  177.389999   [-2.726195424978073]   2.459291\n",
       "20      NFLX      898.904545  865.590027   [33.314518354840175]  18.765669"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - loss: 1.7950 - mae: 1.3362 - val_loss: 1.5629 - val_mae: 1.2433\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.3318 - mae: 1.1506 - val_loss: 1.1286 - val_mae: 1.0530\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9659 - mae: 0.9790 - val_loss: 0.7842 - val_mae: 0.8735\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6755 - mae: 0.8160 - val_loss: 0.5324 - val_mae: 0.7174\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4674 - mae: 0.6761 - val_loss: 0.3549 - val_mae: 0.5832\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3294 - mae: 0.5652 - val_loss: 0.2557 - val_mae: 0.4905\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2311 - mae: 0.4711 - val_loss: 0.1766 - val_mae: 0.4010\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1554 - mae: 0.3840 - val_loss: 0.1180 - val_mae: 0.3216\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0979 - mae: 0.3020 - val_loss: 0.0731 - val_mae: 0.2436\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0542 - mae: 0.2199 - val_loss: 0.0414 - val_mae: 0.1677\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0266 - mae: 0.1454 - val_loss: 0.0227 - val_mae: 0.1321\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0107 - mae: 0.0872 - val_loss: 0.0144 - val_mae: 0.1071\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0050 - mae: 0.0583 - val_loss: 0.0148 - val_mae: 0.1108\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0079 - mae: 0.0691 - val_loss: 0.0206 - val_mae: 0.1162\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0169 - mae: 0.1136 - val_loss: 0.0285 - val_mae: 0.1242\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0285 - mae: 0.1553 - val_loss: 0.0365 - val_mae: 0.1420\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0397 - mae: 0.1883 - val_loss: 0.0426 - val_mae: 0.1620\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0481 - mae: 0.2096 - val_loss: 0.0453 - val_mae: 0.1710\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0521 - mae: 0.2192 - val_loss: 0.0447 - val_mae: 0.1704\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0517 - mae: 0.2184 - val_loss: 0.0412 - val_mae: 0.1617\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0476 - mae: 0.2087 - val_loss: 0.0356 - val_mae: 0.1459\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0407 - mae: 0.1915 - val_loss: 0.0291 - val_mae: 0.1259\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0328 - mae: 0.1691 - val_loss: 0.0226 - val_mae: 0.1087\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0247 - mae: 0.1429 - val_loss: 0.0169 - val_mae: 0.0932\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0175 - mae: 0.1136 - val_loss: 0.0124 - val_mae: 0.0798\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0117 - mae: 0.0850 - val_loss: 0.0093 - val_mae: 0.0716\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0077 - mae: 0.0651 - val_loss: 0.0078 - val_mae: 0.0723\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0057 - mae: 0.0610 - val_loss: 0.0075 - val_mae: 0.0818\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0056 - mae: 0.0705 - val_loss: 0.0084 - val_mae: 0.0908\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0069 - mae: 0.0784 - val_loss: 0.0099 - val_mae: 0.0981\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0091 - mae: 0.0847 - val_loss: 0.0114 - val_mae: 0.1035\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0112 - mae: 0.0907 - val_loss: 0.0127 - val_mae: 0.1071\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0128 - mae: 0.0949 - val_loss: 0.0133 - val_mae: 0.1086\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0135 - mae: 0.0971 - val_loss: 0.0133 - val_mae: 0.1085\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0133 - mae: 0.0964 - val_loss: 0.0127 - val_mae: 0.1070\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0123 - mae: 0.0930 - val_loss: 0.0117 - val_mae: 0.1042\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0107 - mae: 0.0884 - val_loss: 0.0106 - val_mae: 0.1008\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0090 - mae: 0.0832 - val_loss: 0.0097 - val_mae: 0.0973\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0074 - mae: 0.0787 - val_loss: 0.0087 - val_mae: 0.0925\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0060 - mae: 0.0737 - val_loss: 0.0079 - val_mae: 0.0878\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0050 - mae: 0.0681 - val_loss: 0.0073 - val_mae: 0.0831\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0043 - mae: 0.0628 - val_loss: 0.0069 - val_mae: 0.0787\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0040 - mae: 0.0578 - val_loss: 0.0067 - val_mae: 0.0746\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0040 - mae: 0.0532 - val_loss: 0.0067 - val_mae: 0.0710\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0041 - mae: 0.0498 - val_loss: 0.0067 - val_mae: 0.0682\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0044 - mae: 0.0501 - val_loss: 0.0068 - val_mae: 0.0660\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0046 - mae: 0.0508 - val_loss: 0.0069 - val_mae: 0.0662\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0049 - mae: 0.0518 - val_loss: 0.0069 - val_mae: 0.0671\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0049 - mae: 0.0529 - val_loss: 0.0069 - val_mae: 0.0671\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - mae: 0.0532 - val_loss: 0.0068 - val_mae: 0.0667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step - loss: 1.0599 - mae: 1.0210 - val_loss: 0.8858 - val_mae: 0.9264\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6832 - mae: 0.8153 - val_loss: 0.6054 - val_mae: 0.7532\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4132 - mae: 0.6272 - val_loss: 0.3910 - val_mae: 0.5918\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2417 - mae: 0.4697 - val_loss: 0.2423 - val_mae: 0.4350\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1200 - mae: 0.3134 - val_loss: 0.1506 - val_mae: 0.2911\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0435 - mae: 0.1757 - val_loss: 0.0988 - val_mae: 0.2654\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0172 - mae: 0.1164 - val_loss: 0.0761 - val_mae: 0.2682\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0299 - mae: 0.1367 - val_loss: 0.0722 - val_mae: 0.2675\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0586 - mae: 0.2081 - val_loss: 0.0733 - val_mae: 0.2633\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0821 - mae: 0.2598 - val_loss: 0.0716 - val_mae: 0.2571\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0899 - mae: 0.2759 - val_loss: 0.0669 - val_mae: 0.2517\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0822 - mae: 0.2626 - val_loss: 0.0619 - val_mae: 0.2474\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0648 - mae: 0.2283 - val_loss: 0.0597 - val_mae: 0.2422\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0439 - mae: 0.1824 - val_loss: 0.0637 - val_mae: 0.2364\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0258 - mae: 0.1312 - val_loss: 0.0754 - val_mae: 0.2317\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0141 - mae: 0.0939 - val_loss: 0.0932 - val_mae: 0.2268\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0101 - mae: 0.0873 - val_loss: 0.1146 - val_mae: 0.2552\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0127 - mae: 0.0913 - val_loss: 0.1358 - val_mae: 0.2947\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0181 - mae: 0.1087 - val_loss: 0.1495 - val_mae: 0.3177\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0231 - mae: 0.1242 - val_loss: 0.1568 - val_mae: 0.3291\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0268 - mae: 0.1356 - val_loss: 0.1583 - val_mae: 0.3319\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0285 - mae: 0.1405 - val_loss: 0.1558 - val_mae: 0.3283\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0279 - mae: 0.1386 - val_loss: 0.1498 - val_mae: 0.3193\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0257 - mae: 0.1315 - val_loss: 0.1412 - val_mae: 0.3055\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0225 - mae: 0.1202 - val_loss: 0.1309 - val_mae: 0.2881\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0189 - mae: 0.1097 - val_loss: 0.1198 - val_mae: 0.2680\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0153 - mae: 0.0981 - val_loss: 0.1087 - val_mae: 0.2464\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0123 - mae: 0.0856 - val_loss: 0.0983 - val_mae: 0.2242\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0102 - mae: 0.0801 - val_loss: 0.0890 - val_mae: 0.2190\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0091 - mae: 0.0795 - val_loss: 0.0808 - val_mae: 0.2185\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0089 - mae: 0.0803 - val_loss: 0.0735 - val_mae: 0.2171\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0094 - mae: 0.0818 - val_loss: 0.0679 - val_mae: 0.2154\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0103 - mae: 0.0876 - val_loss: 0.0637 - val_mae: 0.2135\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0113 - mae: 0.0916 - val_loss: 0.0608 - val_mae: 0.2113\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0119 - mae: 0.0938 - val_loss: 0.0585 - val_mae: 0.2083\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0121 - mae: 0.0941 - val_loss: 0.0573 - val_mae: 0.2053\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0118 - mae: 0.0926 - val_loss: 0.0572 - val_mae: 0.2025\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0109 - mae: 0.0895 - val_loss: 0.0579 - val_mae: 0.1998\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0098 - mae: 0.0849 - val_loss: 0.0596 - val_mae: 0.1970\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0085 - mae: 0.0793 - val_loss: 0.0619 - val_mae: 0.1942\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0073 - mae: 0.0728 - val_loss: 0.0649 - val_mae: 0.1912\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0063 - mae: 0.0654 - val_loss: 0.0681 - val_mae: 0.1946\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0056 - mae: 0.0597 - val_loss: 0.0713 - val_mae: 0.1993\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0053 - mae: 0.0587 - val_loss: 0.0740 - val_mae: 0.2029\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0053 - mae: 0.0593 - val_loss: 0.0760 - val_mae: 0.2081\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0056 - mae: 0.0600 - val_loss: 0.0769 - val_mae: 0.2121\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0058 - mae: 0.0610 - val_loss: 0.0766 - val_mae: 0.2132\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0058 - mae: 0.0614 - val_loss: 0.0752 - val_mae: 0.2112\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0057 - mae: 0.0609 - val_loss: 0.0728 - val_mae: 0.2066\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0054 - mae: 0.0593 - val_loss: 0.0696 - val_mae: 0.2004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - loss: 0.0944 - mae: 0.2849 - val_loss: 0.0885 - val_mae: 0.2554\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0342 - mae: 0.1510 - val_loss: 0.0389 - val_mae: 0.1807\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0118 - mae: 0.0844 - val_loss: 0.0163 - val_mae: 0.1170\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0125 - mae: 0.0885 - val_loss: 0.0139 - val_mae: 0.0969\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0210 - mae: 0.1260 - val_loss: 0.0145 - val_mae: 0.0994\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0239 - mae: 0.1382 - val_loss: 0.0148 - val_mae: 0.1006\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0220 - mae: 0.1311 - val_loss: 0.0153 - val_mae: 0.1005\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0174 - mae: 0.1112 - val_loss: 0.0177 - val_mae: 0.1177\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0130 - mae: 0.0925 - val_loss: 0.0205 - val_mae: 0.1320\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0104 - mae: 0.0841 - val_loss: 0.0236 - val_mae: 0.1438\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0097 - mae: 0.0819 - val_loss: 0.0266 - val_mae: 0.1522\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0104 - mae: 0.0806 - val_loss: 0.0292 - val_mae: 0.1577\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0115 - mae: 0.0819 - val_loss: 0.0307 - val_mae: 0.1601\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0123 - mae: 0.0847 - val_loss: 0.0309 - val_mae: 0.1595\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0124 - mae: 0.0865 - val_loss: 0.0298 - val_mae: 0.1565\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0119 - mae: 0.0845 - val_loss: 0.0280 - val_mae: 0.1523\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0108 - mae: 0.0798 - val_loss: 0.0256 - val_mae: 0.1463\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0095 - mae: 0.0742 - val_loss: 0.0237 - val_mae: 0.1407\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0083 - mae: 0.0686 - val_loss: 0.0217 - val_mae: 0.1346\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0075 - mae: 0.0627 - val_loss: 0.0199 - val_mae: 0.1283\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0071 - mae: 0.0601 - val_loss: 0.0185 - val_mae: 0.1232\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0071 - mae: 0.0589 - val_loss: 0.0175 - val_mae: 0.1194\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0073 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.1173\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0075 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.1176\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0075 - mae: 0.0629 - val_loss: 0.0176 - val_mae: 0.1197\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0073 - mae: 0.0610 - val_loss: 0.0186 - val_mae: 0.1233\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0069 - mae: 0.0584 - val_loss: 0.0196 - val_mae: 0.1267\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - mae: 0.0562 - val_loss: 0.0207 - val_mae: 0.1298\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0065 - mae: 0.0543 - val_loss: 0.0214 - val_mae: 0.1319\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0064 - mae: 0.0534 - val_loss: 0.0216 - val_mae: 0.1325\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0064 - mae: 0.0534 - val_loss: 0.0210 - val_mae: 0.1313\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0063 - mae: 0.0533 - val_loss: 0.0199 - val_mae: 0.1284\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0061 - mae: 0.0534 - val_loss: 0.0184 - val_mae: 0.1241\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0059 - mae: 0.0534 - val_loss: 0.0169 - val_mae: 0.1200\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0058 - mae: 0.0535 - val_loss: 0.0157 - val_mae: 0.1163\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0057 - mae: 0.0535 - val_loss: 0.0147 - val_mae: 0.1133\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0058 - mae: 0.0534 - val_loss: 0.0141 - val_mae: 0.1110\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0057 - mae: 0.0531 - val_loss: 0.0137 - val_mae: 0.1093\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0057 - mae: 0.0526 - val_loss: 0.0135 - val_mae: 0.1083\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0056 - mae: 0.0519 - val_loss: 0.0136 - val_mae: 0.1084\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0054 - mae: 0.0509 - val_loss: 0.0139 - val_mae: 0.1089\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0053 - mae: 0.0500 - val_loss: 0.0141 - val_mae: 0.1094\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0052 - mae: 0.0490 - val_loss: 0.0145 - val_mae: 0.1104\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0052 - mae: 0.0482 - val_loss: 0.0147 - val_mae: 0.1109\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0051 - mae: 0.0474 - val_loss: 0.0148 - val_mae: 0.1109\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0051 - mae: 0.0469 - val_loss: 0.0146 - val_mae: 0.1099\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0050 - mae: 0.0465 - val_loss: 0.0141 - val_mae: 0.1080\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0049 - mae: 0.0461 - val_loss: 0.0135 - val_mae: 0.1056\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0048 - mae: 0.0460 - val_loss: 0.0130 - val_mae: 0.1032\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0048 - mae: 0.0459 - val_loss: 0.0125 - val_mae: 0.1013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - loss: 1.0934 - mae: 1.0379 - val_loss: 0.4998 - val_mae: 0.6873\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6877 - mae: 0.8215 - val_loss: 0.2743 - val_mae: 0.4996\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4051 - mae: 0.6266 - val_loss: 0.1185 - val_mae: 0.3117\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2032 - mae: 0.4372 - val_loss: 0.0411 - val_mae: 0.1400\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0785 - mae: 0.2584 - val_loss: 0.0221 - val_mae: 0.1344\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0204 - mae: 0.1255 - val_loss: 0.0521 - val_mae: 0.2099\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0151 - mae: 0.0959 - val_loss: 0.1085 - val_mae: 0.2948\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0446 - mae: 0.1825 - val_loss: 0.1649 - val_mae: 0.3794\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0824 - mae: 0.2672 - val_loss: 0.2023 - val_mae: 0.4269\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1075 - mae: 0.3112 - val_loss: 0.2158 - val_mae: 0.4429\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1136 - mae: 0.3204 - val_loss: 0.2051 - val_mae: 0.4310\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1022 - mae: 0.3016 - val_loss: 0.1777 - val_mae: 0.3987\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0808 - mae: 0.2635 - val_loss: 0.1420 - val_mae: 0.3518\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0577 - mae: 0.2155 - val_loss: 0.1045 - val_mae: 0.2938\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0369 - mae: 0.1602 - val_loss: 0.0701 - val_mae: 0.2284\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0216 - mae: 0.1120 - val_loss: 0.0443 - val_mae: 0.1957\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0129 - mae: 0.0879 - val_loss: 0.0307 - val_mae: 0.1716\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0110 - mae: 0.0876 - val_loss: 0.0238 - val_mae: 0.1496\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0135 - mae: 0.0986 - val_loss: 0.0208 - val_mae: 0.1282\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0185 - mae: 0.1181 - val_loss: 0.0203 - val_mae: 0.1127\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0238 - mae: 0.1364 - val_loss: 0.0206 - val_mae: 0.1056\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0280 - mae: 0.1484 - val_loss: 0.0209 - val_mae: 0.1047\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0300 - mae: 0.1534 - val_loss: 0.0206 - val_mae: 0.1041\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0295 - mae: 0.1521 - val_loss: 0.0197 - val_mae: 0.1034\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0268 - mae: 0.1441 - val_loss: 0.0185 - val_mae: 0.1029\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0227 - mae: 0.1316 - val_loss: 0.0175 - val_mae: 0.1055\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0180 - mae: 0.1166 - val_loss: 0.0171 - val_mae: 0.1138\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0139 - mae: 0.1031 - val_loss: 0.0174 - val_mae: 0.1222\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0107 - mae: 0.0895 - val_loss: 0.0189 - val_mae: 0.1313\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0087 - mae: 0.0788 - val_loss: 0.0210 - val_mae: 0.1398\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0078 - mae: 0.0733 - val_loss: 0.0235 - val_mae: 0.1473\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0076 - mae: 0.0730 - val_loss: 0.0261 - val_mae: 0.1538\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0080 - mae: 0.0744 - val_loss: 0.0283 - val_mae: 0.1584\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0086 - mae: 0.0753 - val_loss: 0.0298 - val_mae: 0.1610\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0093 - mae: 0.0771 - val_loss: 0.0304 - val_mae: 0.1617\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0098 - mae: 0.0780 - val_loss: 0.0303 - val_mae: 0.1609\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0099 - mae: 0.0783 - val_loss: 0.0293 - val_mae: 0.1583\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0096 - mae: 0.0770 - val_loss: 0.0275 - val_mae: 0.1541\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0090 - mae: 0.0742 - val_loss: 0.0252 - val_mae: 0.1486\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0081 - mae: 0.0711 - val_loss: 0.0226 - val_mae: 0.1419\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0073 - mae: 0.0674 - val_loss: 0.0201 - val_mae: 0.1347\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0065 - mae: 0.0654 - val_loss: 0.0178 - val_mae: 0.1276\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0061 - mae: 0.0646 - val_loss: 0.0160 - val_mae: 0.1210\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0058 - mae: 0.0638 - val_loss: 0.0146 - val_mae: 0.1149\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0058 - mae: 0.0628 - val_loss: 0.0136 - val_mae: 0.1096\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0060 - mae: 0.0628 - val_loss: 0.0129 - val_mae: 0.1053\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0061 - mae: 0.0633 - val_loss: 0.0124 - val_mae: 0.1022\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0062 - mae: 0.0642 - val_loss: 0.0120 - val_mae: 0.1004\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0062 - mae: 0.0640 - val_loss: 0.0119 - val_mae: 0.0998\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0060 - mae: 0.0628 - val_loss: 0.0118 - val_mae: 0.1002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - loss: 0.2645 - mae: 0.5076 - val_loss: 0.1146 - val_mae: 0.3259\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1430 - mae: 0.3684 - val_loss: 0.0481 - val_mae: 0.2004\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0607 - mae: 0.2311 - val_loss: 0.0143 - val_mae: 0.0869\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0172 - mae: 0.1113 - val_loss: 0.0086 - val_mae: 0.0832\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0071 - mae: 0.0706 - val_loss: 0.0205 - val_mae: 0.1242\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0180 - mae: 0.1136 - val_loss: 0.0347 - val_mae: 0.1678\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0337 - mae: 0.1643 - val_loss: 0.0412 - val_mae: 0.1878\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0420 - mae: 0.1876 - val_loss: 0.0396 - val_mae: 0.1842\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0412 - mae: 0.1854 - val_loss: 0.0323 - val_mae: 0.1638\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0342 - mae: 0.1650 - val_loss: 0.0229 - val_mae: 0.1326\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0242 - mae: 0.1339 - val_loss: 0.0144 - val_mae: 0.1007\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0148 - mae: 0.1055 - val_loss: 0.0083 - val_mae: 0.0808\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0087 - mae: 0.0812 - val_loss: 0.0057 - val_mae: 0.0676\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0066 - mae: 0.0662 - val_loss: 0.0061 - val_mae: 0.0683\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0078 - mae: 0.0657 - val_loss: 0.0083 - val_mae: 0.0689\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0108 - mae: 0.0848 - val_loss: 0.0107 - val_mae: 0.0755\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0139 - mae: 0.0996 - val_loss: 0.0121 - val_mae: 0.0800\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0156 - mae: 0.1066 - val_loss: 0.0118 - val_mae: 0.0795\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0154 - mae: 0.1063 - val_loss: 0.0103 - val_mae: 0.0746\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0137 - mae: 0.1000 - val_loss: 0.0082 - val_mae: 0.0673\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0110 - mae: 0.0888 - val_loss: 0.0064 - val_mae: 0.0667\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0083 - mae: 0.0741 - val_loss: 0.0054 - val_mae: 0.0660\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0063 - mae: 0.0581 - val_loss: 0.0055 - val_mae: 0.0653\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0052 - mae: 0.0534 - val_loss: 0.0067 - val_mae: 0.0721\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0052 - mae: 0.0583 - val_loss: 0.0085 - val_mae: 0.0813\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0058 - mae: 0.0653 - val_loss: 0.0103 - val_mae: 0.0884\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0067 - mae: 0.0705 - val_loss: 0.0118 - val_mae: 0.0934\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0075 - mae: 0.0738 - val_loss: 0.0126 - val_mae: 0.0959\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0078 - mae: 0.0755 - val_loss: 0.0125 - val_mae: 0.0961\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0077 - mae: 0.0746 - val_loss: 0.0118 - val_mae: 0.0941\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0070 - mae: 0.0713 - val_loss: 0.0105 - val_mae: 0.0904\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0062 - mae: 0.0673 - val_loss: 0.0091 - val_mae: 0.0855\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0054 - mae: 0.0621 - val_loss: 0.0078 - val_mae: 0.0799\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - mae: 0.0565 - val_loss: 0.0068 - val_mae: 0.0742\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0044 - mae: 0.0522 - val_loss: 0.0061 - val_mae: 0.0688\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0044 - mae: 0.0498 - val_loss: 0.0057 - val_mae: 0.0642\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0047 - mae: 0.0507 - val_loss: 0.0055 - val_mae: 0.0639\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0055 - val_mae: 0.0640\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0052 - mae: 0.0544 - val_loss: 0.0055 - val_mae: 0.0640\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0052 - mae: 0.0551 - val_loss: 0.0055 - val_mae: 0.0639\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0051 - mae: 0.0541 - val_loss: 0.0055 - val_mae: 0.0637\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - mae: 0.0520 - val_loss: 0.0056 - val_mae: 0.0636\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0045 - mae: 0.0499 - val_loss: 0.0058 - val_mae: 0.0671\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0042 - mae: 0.0479 - val_loss: 0.0061 - val_mae: 0.0709\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0040 - mae: 0.0478 - val_loss: 0.0066 - val_mae: 0.0745\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0071 - val_mae: 0.0776\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0075 - val_mae: 0.0800\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0041 - mae: 0.0516 - val_loss: 0.0078 - val_mae: 0.0816\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0041 - mae: 0.0527 - val_loss: 0.0079 - val_mae: 0.0821\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0042 - mae: 0.0530 - val_loss: 0.0078 - val_mae: 0.0818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step - loss: 1.3982 - mae: 1.1787 - val_loss: 0.9760 - val_mae: 0.9843\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.8824 - mae: 0.9349 - val_loss: 0.5812 - val_mae: 0.7566\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5083 - mae: 0.7078 - val_loss: 0.3039 - val_mae: 0.5414\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2568 - mae: 0.4996 - val_loss: 0.1258 - val_mae: 0.3392\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0986 - mae: 0.3025 - val_loss: 0.0366 - val_mae: 0.1592\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0213 - mae: 0.1213 - val_loss: 0.0135 - val_mae: 0.0940\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0067 - mae: 0.0703 - val_loss: 0.0290 - val_mae: 0.1317\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0275 - mae: 0.1489 - val_loss: 0.0564 - val_mae: 0.2107\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0603 - mae: 0.2349 - val_loss: 0.0756 - val_mae: 0.2518\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0839 - mae: 0.2807 - val_loss: 0.0790 - val_mae: 0.2586\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0886 - mae: 0.2887 - val_loss: 0.0685 - val_mae: 0.2380\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0761 - mae: 0.2666 - val_loss: 0.0510 - val_mae: 0.1982\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0564 - mae: 0.2268 - val_loss: 0.0334 - val_mae: 0.1497\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0367 - mae: 0.1785 - val_loss: 0.0210 - val_mae: 0.1111\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0222 - mae: 0.1305 - val_loss: 0.0136 - val_mae: 0.0891\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0124 - mae: 0.0913 - val_loss: 0.0111 - val_mae: 0.0896\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0067 - mae: 0.0685 - val_loss: 0.0122 - val_mae: 0.0992\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0050 - mae: 0.0618 - val_loss: 0.0168 - val_mae: 0.1177\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0063 - mae: 0.0658 - val_loss: 0.0229 - val_mae: 0.1339\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0094 - mae: 0.0751 - val_loss: 0.0298 - val_mae: 0.1485\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0126 - mae: 0.0891 - val_loss: 0.0349 - val_mae: 0.1583\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0150 - mae: 0.0999 - val_loss: 0.0371 - val_mae: 0.1627\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0160 - mae: 0.1044 - val_loss: 0.0374 - val_mae: 0.1635\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0154 - mae: 0.1023 - val_loss: 0.0357 - val_mae: 0.1616\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0137 - mae: 0.0950 - val_loss: 0.0327 - val_mae: 0.1574\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0115 - mae: 0.0848 - val_loss: 0.0294 - val_mae: 0.1522\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0091 - mae: 0.0740 - val_loss: 0.0263 - val_mae: 0.1464\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0071 - mae: 0.0654 - val_loss: 0.0235 - val_mae: 0.1401\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0059 - mae: 0.0597 - val_loss: 0.0210 - val_mae: 0.1325\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0055 - mae: 0.0558 - val_loss: 0.0190 - val_mae: 0.1251\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0056 - mae: 0.0554 - val_loss: 0.0175 - val_mae: 0.1186\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0062 - mae: 0.0612 - val_loss: 0.0166 - val_mae: 0.1132\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0069 - mae: 0.0674 - val_loss: 0.0160 - val_mae: 0.1091\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0075 - mae: 0.0715 - val_loss: 0.0158 - val_mae: 0.1070\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0079 - mae: 0.0743 - val_loss: 0.0156 - val_mae: 0.1062\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0080 - mae: 0.0750 - val_loss: 0.0156 - val_mae: 0.1066\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0077 - mae: 0.0734 - val_loss: 0.0157 - val_mae: 0.1081\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0072 - mae: 0.0698 - val_loss: 0.0160 - val_mae: 0.1105\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0065 - mae: 0.0655 - val_loss: 0.0164 - val_mae: 0.1136\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0059 - mae: 0.0603 - val_loss: 0.0171 - val_mae: 0.1171\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0053 - mae: 0.0546 - val_loss: 0.0179 - val_mae: 0.1210\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0049 - mae: 0.0501 - val_loss: 0.0187 - val_mae: 0.1247\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - mae: 0.0497 - val_loss: 0.0196 - val_mae: 0.1279\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - mae: 0.0510 - val_loss: 0.0203 - val_mae: 0.1305\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - mae: 0.0519 - val_loss: 0.0208 - val_mae: 0.1322\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - mae: 0.0536 - val_loss: 0.0210 - val_mae: 0.1330\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0050 - mae: 0.0549 - val_loss: 0.0210 - val_mae: 0.1328\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0051 - mae: 0.0556 - val_loss: 0.0206 - val_mae: 0.1317\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0050 - mae: 0.0555 - val_loss: 0.0199 - val_mae: 0.1297\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - mae: 0.0548 - val_loss: 0.0190 - val_mae: 0.1271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - loss: 0.2507 - mae: 0.4427 - val_loss: 0.0270 - val_mae: 0.1275\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1536 - mae: 0.3278 - val_loss: 0.0128 - val_mae: 0.0898\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0851 - mae: 0.2642 - val_loss: 0.0243 - val_mae: 0.1364\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0484 - mae: 0.2047 - val_loss: 0.0508 - val_mae: 0.2048\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0378 - mae: 0.1566 - val_loss: 0.0756 - val_mae: 0.2609\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0434 - mae: 0.1556 - val_loss: 0.0871 - val_mae: 0.2839\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0514 - mae: 0.1819 - val_loss: 0.0822 - val_mae: 0.2762\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0525 - mae: 0.1947 - val_loss: 0.0654 - val_mae: 0.2449\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0449 - mae: 0.1836 - val_loss: 0.0440 - val_mae: 0.1972\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0328 - mae: 0.1557 - val_loss: 0.0245 - val_mae: 0.1401\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0205 - mae: 0.1189 - val_loss: 0.0110 - val_mae: 0.0814\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0122 - mae: 0.0884 - val_loss: 0.0049 - val_mae: 0.0523\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0096 - mae: 0.0793 - val_loss: 0.0055 - val_mae: 0.0672\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0115 - mae: 0.0836 - val_loss: 0.0094 - val_mae: 0.0867\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0155 - mae: 0.0950 - val_loss: 0.0135 - val_mae: 0.0991\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0188 - mae: 0.1072 - val_loss: 0.0156 - val_mae: 0.1075\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0193 - mae: 0.1103 - val_loss: 0.0153 - val_mae: 0.1063\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0171 - mae: 0.1033 - val_loss: 0.0130 - val_mae: 0.0994\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0131 - mae: 0.0880 - val_loss: 0.0097 - val_mae: 0.0900\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0094 - mae: 0.0697 - val_loss: 0.0065 - val_mae: 0.0778\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0068 - mae: 0.0596 - val_loss: 0.0043 - val_mae: 0.0642\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0059 - mae: 0.0602 - val_loss: 0.0034 - val_mae: 0.0516\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0068 - mae: 0.0692 - val_loss: 0.0036 - val_mae: 0.0425\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0084 - mae: 0.0785 - val_loss: 0.0040 - val_mae: 0.0377\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0096 - mae: 0.0841 - val_loss: 0.0040 - val_mae: 0.0371\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0098 - mae: 0.0848 - val_loss: 0.0038 - val_mae: 0.0405\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0089 - mae: 0.0797 - val_loss: 0.0035 - val_mae: 0.0471\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0074 - mae: 0.0713 - val_loss: 0.0036 - val_mae: 0.0561\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0059 - mae: 0.0617 - val_loss: 0.0042 - val_mae: 0.0647\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0050 - mae: 0.0534 - val_loss: 0.0054 - val_mae: 0.0731\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - mae: 0.0516 - val_loss: 0.0069 - val_mae: 0.0810\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - mae: 0.0515 - val_loss: 0.0083 - val_mae: 0.0872\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0053 - mae: 0.0536 - val_loss: 0.0093 - val_mae: 0.0911\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0056 - mae: 0.0564 - val_loss: 0.0096 - val_mae: 0.0923\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0057 - mae: 0.0570 - val_loss: 0.0093 - val_mae: 0.0912\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0055 - mae: 0.0559 - val_loss: 0.0084 - val_mae: 0.0880\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0050 - mae: 0.0530 - val_loss: 0.0073 - val_mae: 0.0834\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mae: 0.0506 - val_loss: 0.0062 - val_mae: 0.0779\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0053 - val_mae: 0.0724\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0038 - mae: 0.0475 - val_loss: 0.0046 - val_mae: 0.0673\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0039 - mae: 0.0470 - val_loss: 0.0043 - val_mae: 0.0634\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0041 - mae: 0.0474 - val_loss: 0.0041 - val_mae: 0.0609\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0042 - mae: 0.0484 - val_loss: 0.0041 - val_mae: 0.0602\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0043 - mae: 0.0487 - val_loss: 0.0042 - val_mae: 0.0611\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0041 - mae: 0.0477 - val_loss: 0.0044 - val_mae: 0.0635\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0039 - mae: 0.0458 - val_loss: 0.0046 - val_mae: 0.0667\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0036 - mae: 0.0445 - val_loss: 0.0051 - val_mae: 0.0705\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0034 - mae: 0.0433 - val_loss: 0.0057 - val_mae: 0.0742\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0034 - mae: 0.0442 - val_loss: 0.0063 - val_mae: 0.0776\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0034 - mae: 0.0450 - val_loss: 0.0068 - val_mae: 0.0801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - loss: 0.2203 - mae: 0.4470 - val_loss: 0.0043 - val_mae: 0.0627\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0252 - mae: 0.1178 - val_loss: 0.0442 - val_mae: 0.1990\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0412 - mae: 0.1816 - val_loss: 0.0886 - val_mae: 0.2872\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0881 - mae: 0.2779 - val_loss: 0.0745 - val_mae: 0.2616\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0736 - mae: 0.2512 - val_loss: 0.0360 - val_mae: 0.1761\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0351 - mae: 0.1701 - val_loss: 0.0084 - val_mae: 0.0669\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0117 - mae: 0.0942 - val_loss: 0.0050 - val_mae: 0.0691\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0158 - mae: 0.0904 - val_loss: 0.0157 - val_mae: 0.1108\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0335 - mae: 0.1534 - val_loss: 0.0228 - val_mae: 0.1399\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0424 - mae: 0.1810 - val_loss: 0.0198 - val_mae: 0.1286\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0359 - mae: 0.1636 - val_loss: 0.0117 - val_mae: 0.0959\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0220 - mae: 0.1179 - val_loss: 0.0052 - val_mae: 0.0709\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0107 - mae: 0.0704 - val_loss: 0.0053 - val_mae: 0.0526\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0080 - mae: 0.0683 - val_loss: 0.0107 - val_mae: 0.0742\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0124 - mae: 0.0995 - val_loss: 0.0165 - val_mae: 0.1020\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0183 - mae: 0.1237 - val_loss: 0.0181 - val_mae: 0.1081\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0201 - mae: 0.1315 - val_loss: 0.0149 - val_mae: 0.0924\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0167 - mae: 0.1187 - val_loss: 0.0099 - val_mae: 0.0743\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0109 - mae: 0.0933 - val_loss: 0.0063 - val_mae: 0.0627\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0067 - mae: 0.0628 - val_loss: 0.0064 - val_mae: 0.0726\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0063 - mae: 0.0503 - val_loss: 0.0092 - val_mae: 0.0898\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0090 - mae: 0.0681 - val_loss: 0.0120 - val_mae: 0.0999\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0119 - mae: 0.0852 - val_loss: 0.0127 - val_mae: 0.1021\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0123 - mae: 0.0881 - val_loss: 0.0110 - val_mae: 0.0964\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0101 - mae: 0.0759 - val_loss: 0.0085 - val_mae: 0.0850\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0071 - mae: 0.0555 - val_loss: 0.0070 - val_mae: 0.0707\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0055 - mae: 0.0472 - val_loss: 0.0073 - val_mae: 0.0731\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0060 - mae: 0.0595 - val_loss: 0.0086 - val_mae: 0.0756\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0077 - mae: 0.0721 - val_loss: 0.0096 - val_mae: 0.0771\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0087 - mae: 0.0800 - val_loss: 0.0093 - val_mae: 0.0776\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0083 - mae: 0.0767 - val_loss: 0.0083 - val_mae: 0.0772\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0067 - mae: 0.0653 - val_loss: 0.0075 - val_mae: 0.0762\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0053 - mae: 0.0536 - val_loss: 0.0077 - val_mae: 0.0751\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0051 - mae: 0.0447 - val_loss: 0.0086 - val_mae: 0.0826\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0058 - mae: 0.0510 - val_loss: 0.0094 - val_mae: 0.0877\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0066 - mae: 0.0582 - val_loss: 0.0095 - val_mae: 0.0878\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0065 - mae: 0.0581 - val_loss: 0.0089 - val_mae: 0.0834\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0056 - mae: 0.0510 - val_loss: 0.0082 - val_mae: 0.0777\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - mae: 0.0421 - val_loss: 0.0079 - val_mae: 0.0794\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0046 - mae: 0.0466 - val_loss: 0.0081 - val_mae: 0.0808\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0050 - mae: 0.0534 - val_loss: 0.0084 - val_mae: 0.0817\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0055 - mae: 0.0579 - val_loss: 0.0084 - val_mae: 0.0819\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0054 - mae: 0.0577 - val_loss: 0.0081 - val_mae: 0.0815\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0049 - mae: 0.0529 - val_loss: 0.0079 - val_mae: 0.0807\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0044 - mae: 0.0465 - val_loss: 0.0080 - val_mae: 0.0797\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0043 - mae: 0.0416 - val_loss: 0.0084 - val_mae: 0.0790\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0046 - mae: 0.0413 - val_loss: 0.0086 - val_mae: 0.0791\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0048 - mae: 0.0439 - val_loss: 0.0085 - val_mae: 0.0789\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0047 - mae: 0.0427 - val_loss: 0.0082 - val_mae: 0.0796\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0044 - mae: 0.0404 - val_loss: 0.0080 - val_mae: 0.0806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step - loss: 0.4079 - mae: 0.5877 - val_loss: 0.1875 - val_mae: 0.3791\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2120 - mae: 0.3837 - val_loss: 0.0821 - val_mae: 0.1912\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0996 - mae: 0.2488 - val_loss: 0.0504 - val_mae: 0.1846\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0557 - mae: 0.2157 - val_loss: 0.0622 - val_mae: 0.2431\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0594 - mae: 0.2068 - val_loss: 0.0708 - val_mae: 0.2528\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0667 - mae: 0.2140 - val_loss: 0.0610 - val_mae: 0.2318\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0572 - mae: 0.2013 - val_loss: 0.0448 - val_mae: 0.1987\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0378 - mae: 0.1633 - val_loss: 0.0307 - val_mae: 0.1561\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0218 - mae: 0.1287 - val_loss: 0.0254 - val_mae: 0.1435\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0158 - mae: 0.1133 - val_loss: 0.0273 - val_mae: 0.1420\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0178 - mae: 0.1039 - val_loss: 0.0309 - val_mae: 0.1419\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0214 - mae: 0.1142 - val_loss: 0.0310 - val_mae: 0.1396\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0220 - mae: 0.1190 - val_loss: 0.0278 - val_mae: 0.1373\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0186 - mae: 0.1083 - val_loss: 0.0230 - val_mae: 0.1349\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0130 - mae: 0.0882 - val_loss: 0.0193 - val_mae: 0.1327\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0084 - mae: 0.0714 - val_loss: 0.0183 - val_mae: 0.1305\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0067 - mae: 0.0656 - val_loss: 0.0195 - val_mae: 0.1282\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0081 - mae: 0.0786 - val_loss: 0.0214 - val_mae: 0.1261\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0105 - mae: 0.0913 - val_loss: 0.0217 - val_mae: 0.1238\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0118 - mae: 0.0959 - val_loss: 0.0199 - val_mae: 0.1212\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0108 - mae: 0.0921 - val_loss: 0.0168 - val_mae: 0.1185\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0082 - mae: 0.0808 - val_loss: 0.0141 - val_mae: 0.1158\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0057 - mae: 0.0651 - val_loss: 0.0132 - val_mae: 0.1132\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0043 - mae: 0.0534 - val_loss: 0.0144 - val_mae: 0.1113\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0045 - mae: 0.0531 - val_loss: 0.0167 - val_mae: 0.1102\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0056 - mae: 0.0575 - val_loss: 0.0186 - val_mae: 0.1091\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0065 - mae: 0.0609 - val_loss: 0.0191 - val_mae: 0.1103\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0065 - mae: 0.0611 - val_loss: 0.0182 - val_mae: 0.1080\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0056 - mae: 0.0574 - val_loss: 0.0161 - val_mae: 0.1059\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0044 - mae: 0.0522 - val_loss: 0.0138 - val_mae: 0.1047\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0036 - mae: 0.0484 - val_loss: 0.0122 - val_mae: 0.1038\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0036 - mae: 0.0520 - val_loss: 0.0114 - val_mae: 0.1030\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0041 - mae: 0.0567 - val_loss: 0.0111 - val_mae: 0.1024\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0046 - mae: 0.0599 - val_loss: 0.0110 - val_mae: 0.1018\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0046 - mae: 0.0599 - val_loss: 0.0110 - val_mae: 0.1012\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0041 - mae: 0.0568 - val_loss: 0.0114 - val_mae: 0.1006\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0035 - mae: 0.0523 - val_loss: 0.0121 - val_mae: 0.1000\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0031 - mae: 0.0479 - val_loss: 0.0133 - val_mae: 0.0994\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0031 - mae: 0.0457 - val_loss: 0.0144 - val_mae: 0.0990\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0034 - mae: 0.0468 - val_loss: 0.0151 - val_mae: 0.0993\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0150 - val_mae: 0.0988\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0142 - val_mae: 0.0978\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0032 - mae: 0.0456 - val_loss: 0.0130 - val_mae: 0.0975\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0029 - mae: 0.0439 - val_loss: 0.0120 - val_mae: 0.0973\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0027 - mae: 0.0448 - val_loss: 0.0112 - val_mae: 0.0971\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0028 - mae: 0.0464 - val_loss: 0.0107 - val_mae: 0.0969\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0029 - mae: 0.0480 - val_loss: 0.0106 - val_mae: 0.0967\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0029 - mae: 0.0483 - val_loss: 0.0106 - val_mae: 0.0965\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0028 - mae: 0.0472 - val_loss: 0.0108 - val_mae: 0.0963\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0026 - mae: 0.0452 - val_loss: 0.0112 - val_mae: 0.0961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - loss: 0.5967 - mae: 0.7709 - val_loss: 0.3524 - val_mae: 0.5926\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3362 - mae: 0.5784 - val_loss: 0.1769 - val_mae: 0.4180\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1566 - mae: 0.3934 - val_loss: 0.0704 - val_mae: 0.2578\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0483 - mae: 0.2140 - val_loss: 0.0174 - val_mae: 0.1082\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0054 - mae: 0.0651 - val_loss: 0.0085 - val_mae: 0.0790\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0167 - mae: 0.1092 - val_loss: 0.0267 - val_mae: 0.1352\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0566 - mae: 0.2252 - val_loss: 0.0473 - val_mae: 0.1942\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0928 - mae: 0.2937 - val_loss: 0.0558 - val_mae: 0.2157\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1081 - mae: 0.3182 - val_loss: 0.0520 - val_mae: 0.2077\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1023 - mae: 0.3090 - val_loss: 0.0398 - val_mae: 0.1779\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0817 - mae: 0.2745 - val_loss: 0.0251 - val_mae: 0.1329\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0551 - mae: 0.2224 - val_loss: 0.0128 - val_mae: 0.1012\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0304 - mae: 0.1595 - val_loss: 0.0060 - val_mae: 0.0687\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0127 - mae: 0.0925 - val_loss: 0.0052 - val_mae: 0.0536\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0094 - val_mae: 0.0777\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0035 - mae: 0.0543 - val_loss: 0.0166 - val_mae: 0.1175\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0081 - mae: 0.0796 - val_loss: 0.0244 - val_mae: 0.1483\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0145 - mae: 0.1124 - val_loss: 0.0306 - val_mae: 0.1686\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0205 - mae: 0.1370 - val_loss: 0.0343 - val_mae: 0.1793\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0242 - mae: 0.1503 - val_loss: 0.0348 - val_mae: 0.1809\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0248 - mae: 0.1525 - val_loss: 0.0324 - val_mae: 0.1740\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0224 - mae: 0.1445 - val_loss: 0.0278 - val_mae: 0.1600\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0180 - mae: 0.1279 - val_loss: 0.0220 - val_mae: 0.1404\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0127 - mae: 0.1045 - val_loss: 0.0162 - val_mae: 0.1173\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0077 - mae: 0.0773 - val_loss: 0.0111 - val_mae: 0.0925\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0042 - mae: 0.0576 - val_loss: 0.0072 - val_mae: 0.0671\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0026 - mae: 0.0452 - val_loss: 0.0047 - val_mae: 0.0464\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0029 - mae: 0.0437 - val_loss: 0.0034 - val_mae: 0.0429\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - mae: 0.0527 - val_loss: 0.0031 - val_mae: 0.0438\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0062 - mae: 0.0612 - val_loss: 0.0031 - val_mae: 0.0481\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0077 - mae: 0.0687 - val_loss: 0.0032 - val_mae: 0.0510\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0085 - mae: 0.0739 - val_loss: 0.0032 - val_mae: 0.0509\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0082 - mae: 0.0729 - val_loss: 0.0030 - val_mae: 0.0481\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0072 - mae: 0.0663 - val_loss: 0.0028 - val_mae: 0.0429\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0056 - mae: 0.0567 - val_loss: 0.0029 - val_mae: 0.0397\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0040 - mae: 0.0483 - val_loss: 0.0033 - val_mae: 0.0380\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0027 - mae: 0.0399 - val_loss: 0.0041 - val_mae: 0.0420\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0021 - mae: 0.0369 - val_loss: 0.0053 - val_mae: 0.0553\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0020 - mae: 0.0407 - val_loss: 0.0066 - val_mae: 0.0667\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0024 - mae: 0.0458 - val_loss: 0.0078 - val_mae: 0.0754\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0029 - mae: 0.0497 - val_loss: 0.0085 - val_mae: 0.0808\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0035 - mae: 0.0522 - val_loss: 0.0088 - val_mae: 0.0825\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0037 - mae: 0.0535 - val_loss: 0.0085 - val_mae: 0.0809\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0036 - mae: 0.0527 - val_loss: 0.0078 - val_mae: 0.0761\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0032 - mae: 0.0501 - val_loss: 0.0067 - val_mae: 0.0688\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0026 - mae: 0.0468 - val_loss: 0.0056 - val_mae: 0.0596\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0020 - mae: 0.0428 - val_loss: 0.0045 - val_mae: 0.0495\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0016 - mae: 0.0384 - val_loss: 0.0037 - val_mae: 0.0393\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0014 - mae: 0.0341 - val_loss: 0.0030 - val_mae: 0.0329\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0015 - mae: 0.0302 - val_loss: 0.0027 - val_mae: 0.0332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - loss: 0.5859 - mae: 0.7285 - val_loss: 0.6440 - val_mae: 0.7401\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2244 - mae: 0.4087 - val_loss: 0.3280 - val_mae: 0.4597\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0693 - mae: 0.2317 - val_loss: 0.1805 - val_mae: 0.3611\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0705 - mae: 0.2184 - val_loss: 0.1402 - val_mae: 0.3690\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1304 - mae: 0.2995 - val_loss: 0.1347 - val_mae: 0.3632\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1627 - mae: 0.3535 - val_loss: 0.1292 - val_mae: 0.3537\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1503 - mae: 0.3449 - val_loss: 0.1204 - val_mae: 0.3443\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1112 - mae: 0.2901 - val_loss: 0.1167 - val_mae: 0.3370\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0672 - mae: 0.2144 - val_loss: 0.1230 - val_mae: 0.3309\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0343 - mae: 0.1535 - val_loss: 0.1386 - val_mae: 0.3217\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0194 - mae: 0.1199 - val_loss: 0.1617 - val_mae: 0.3106\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0221 - mae: 0.1232 - val_loss: 0.1855 - val_mae: 0.3144\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0349 - mae: 0.1477 - val_loss: 0.2010 - val_mae: 0.3358\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0478 - mae: 0.1816 - val_loss: 0.2026 - val_mae: 0.3413\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0536 - mae: 0.1969 - val_loss: 0.1902 - val_mae: 0.3224\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0500 - mae: 0.1906 - val_loss: 0.1676 - val_mae: 0.2963\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0396 - mae: 0.1653 - val_loss: 0.1383 - val_mae: 0.2977\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0279 - mae: 0.1286 - val_loss: 0.1148 - val_mae: 0.3001\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0197 - mae: 0.1104 - val_loss: 0.1001 - val_mae: 0.3025\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0176 - mae: 0.1102 - val_loss: 0.0947 - val_mae: 0.3049\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0211 - mae: 0.1135 - val_loss: 0.0945 - val_mae: 0.3067\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0266 - mae: 0.1239 - val_loss: 0.0952 - val_mae: 0.3073\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0298 - mae: 0.1301 - val_loss: 0.0946 - val_mae: 0.3065\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0290 - mae: 0.1281 - val_loss: 0.0934 - val_mae: 0.3046\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0249 - mae: 0.1192 - val_loss: 0.0935 - val_mae: 0.3016\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0195 - mae: 0.1097 - val_loss: 0.0974 - val_mae: 0.2986\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0149 - mae: 0.0986 - val_loss: 0.1038 - val_mae: 0.2933\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0124 - mae: 0.0916 - val_loss: 0.1089 - val_mae: 0.2835\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0117 - mae: 0.0884 - val_loss: 0.1157 - val_mae: 0.2779\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0121 - mae: 0.0896 - val_loss: 0.1219 - val_mae: 0.2768\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0130 - mae: 0.0962 - val_loss: 0.1254 - val_mae: 0.2783\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0135 - mae: 0.0999 - val_loss: 0.1257 - val_mae: 0.2795\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0128 - mae: 0.0977 - val_loss: 0.1233 - val_mae: 0.2812\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0114 - mae: 0.0913 - val_loss: 0.1190 - val_mae: 0.2828\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0098 - mae: 0.0829 - val_loss: 0.1140 - val_mae: 0.2843\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0087 - mae: 0.0746 - val_loss: 0.1092 - val_mae: 0.2855\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0083 - mae: 0.0671 - val_loss: 0.1052 - val_mae: 0.2863\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0085 - mae: 0.0661 - val_loss: 0.1023 - val_mae: 0.2868\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0090 - mae: 0.0672 - val_loss: 0.1007 - val_mae: 0.2873\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0093 - mae: 0.0691 - val_loss: 0.1000 - val_mae: 0.2871\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0091 - mae: 0.0683 - val_loss: 0.1003 - val_mae: 0.2864\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0085 - mae: 0.0642 - val_loss: 0.1016 - val_mae: 0.2855\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0077 - mae: 0.0590 - val_loss: 0.1036 - val_mae: 0.2848\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0070 - mae: 0.0569 - val_loss: 0.1059 - val_mae: 0.2838\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0066 - mae: 0.0575 - val_loss: 0.1080 - val_mae: 0.2829\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0066 - mae: 0.0618 - val_loss: 0.1095 - val_mae: 0.2818\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0068 - mae: 0.0662 - val_loss: 0.1099 - val_mae: 0.2809\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0069 - mae: 0.0684 - val_loss: 0.1091 - val_mae: 0.2802\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0068 - mae: 0.0679 - val_loss: 0.1072 - val_mae: 0.2797\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0065 - mae: 0.0651 - val_loss: 0.1047 - val_mae: 0.2796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - loss: 1.4738 - mae: 1.1950 - val_loss: 0.7017 - val_mae: 0.8268\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1569 - mae: 1.0557 - val_loss: 0.5043 - val_mae: 0.6974\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.8717 - mae: 0.9125 - val_loss: 0.3406 - val_mae: 0.5684\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6282 - mae: 0.7700 - val_loss: 0.2142 - val_mae: 0.4441\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4366 - mae: 0.6362 - val_loss: 0.1237 - val_mae: 0.3272\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2869 - mae: 0.5077 - val_loss: 0.0622 - val_mae: 0.2159\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1706 - mae: 0.3788 - val_loss: 0.0264 - val_mae: 0.1277\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0877 - mae: 0.2508 - val_loss: 0.0148 - val_mae: 0.0971\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0380 - mae: 0.1638 - val_loss: 0.0243 - val_mae: 0.1272\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0189 - mae: 0.1148 - val_loss: 0.0494 - val_mae: 0.1894\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0265 - mae: 0.1399 - val_loss: 0.0823 - val_mae: 0.2637\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0520 - mae: 0.2079 - val_loss: 0.1138 - val_mae: 0.3188\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0820 - mae: 0.2674 - val_loss: 0.1376 - val_mae: 0.3545\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.1054 - mae: 0.3039 - val_loss: 0.1499 - val_mae: 0.3716\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1162 - mae: 0.3198 - val_loss: 0.1503 - val_mae: 0.3724\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1143 - mae: 0.3167 - val_loss: 0.1408 - val_mae: 0.3600\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1026 - mae: 0.2991 - val_loss: 0.1234 - val_mae: 0.3348\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0843 - mae: 0.2706 - val_loss: 0.1015 - val_mae: 0.3002\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0638 - mae: 0.2337 - val_loss: 0.0779 - val_mae: 0.2581\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0445 - mae: 0.1899 - val_loss: 0.0561 - val_mae: 0.2116\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0296 - mae: 0.1433 - val_loss: 0.0385 - val_mae: 0.1639\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0206 - mae: 0.1139 - val_loss: 0.0262 - val_mae: 0.1425\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0176 - mae: 0.1074 - val_loss: 0.0191 - val_mae: 0.1267\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0194 - mae: 0.1155 - val_loss: 0.0154 - val_mae: 0.1127\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0241 - mae: 0.1289 - val_loss: 0.0141 - val_mae: 0.1016\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0296 - mae: 0.1400 - val_loss: 0.0138 - val_mae: 0.0959\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0342 - mae: 0.1498 - val_loss: 0.0138 - val_mae: 0.0955\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0368 - mae: 0.1542 - val_loss: 0.0138 - val_mae: 0.0952\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0369 - mae: 0.1538 - val_loss: 0.0136 - val_mae: 0.0947\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0350 - mae: 0.1495 - val_loss: 0.0133 - val_mae: 0.0943\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0316 - mae: 0.1419 - val_loss: 0.0133 - val_mae: 0.0972\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0275 - mae: 0.1318 - val_loss: 0.0137 - val_mae: 0.1040\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0235 - mae: 0.1228 - val_loss: 0.0149 - val_mae: 0.1115\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0200 - mae: 0.1135 - val_loss: 0.0167 - val_mae: 0.1192\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0175 - mae: 0.1044 - val_loss: 0.0192 - val_mae: 0.1268\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0161 - mae: 0.0988 - val_loss: 0.0222 - val_mae: 0.1339\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0157 - mae: 0.0955 - val_loss: 0.0253 - val_mae: 0.1402\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0162 - mae: 0.0978 - val_loss: 0.0282 - val_mae: 0.1452\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0171 - mae: 0.1025 - val_loss: 0.0305 - val_mae: 0.1488\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0181 - mae: 0.1068 - val_loss: 0.0319 - val_mae: 0.1507\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0188 - mae: 0.1106 - val_loss: 0.0324 - val_mae: 0.1509\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0192 - mae: 0.1123 - val_loss: 0.0318 - val_mae: 0.1497\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0190 - mae: 0.1118 - val_loss: 0.0304 - val_mae: 0.1470\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0184 - mae: 0.1091 - val_loss: 0.0283 - val_mae: 0.1430\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0174 - mae: 0.1046 - val_loss: 0.0257 - val_mae: 0.1380\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0163 - mae: 0.0996 - val_loss: 0.0231 - val_mae: 0.1324\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0154 - mae: 0.0943 - val_loss: 0.0205 - val_mae: 0.1264\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0146 - mae: 0.0907 - val_loss: 0.0183 - val_mae: 0.1204\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0141 - mae: 0.0885 - val_loss: 0.0164 - val_mae: 0.1146\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0139 - mae: 0.0873 - val_loss: 0.0150 - val_mae: 0.1094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841ms/step - loss: 2.0361 - mae: 1.4135 - val_loss: 0.9737 - val_mae: 0.9602\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.6160 - mae: 1.2591 - val_loss: 0.7388 - val_mae: 0.8290\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.2609 - mae: 1.1112 - val_loss: 0.5236 - val_mae: 0.6889\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9521 - mae: 0.9636 - val_loss: 0.3483 - val_mae: 0.5531\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6865 - mae: 0.8164 - val_loss: 0.2134 - val_mae: 0.4205\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4605 - mae: 0.6663 - val_loss: 0.1162 - val_mae: 0.2897\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2789 - mae: 0.5160 - val_loss: 0.0561 - val_mae: 0.1843\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1458 - mae: 0.3697 - val_loss: 0.0286 - val_mae: 0.1618\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0601 - mae: 0.2308 - val_loss: 0.0294 - val_mae: 0.1522\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0164 - mae: 0.1110 - val_loss: 0.0511 - val_mae: 0.1733\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0046 - mae: 0.0604 - val_loss: 0.0859 - val_mae: 0.2602\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0146 - mae: 0.1028 - val_loss: 0.1259 - val_mae: 0.3320\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0376 - mae: 0.1839 - val_loss: 0.1625 - val_mae: 0.3854\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0638 - mae: 0.2455 - val_loss: 0.1903 - val_mae: 0.4217\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0864 - mae: 0.2881 - val_loss: 0.2063 - val_mae: 0.4412\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1004 - mae: 0.3118 - val_loss: 0.2095 - val_mae: 0.4457\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1045 - mae: 0.3184 - val_loss: 0.2017 - val_mae: 0.4376\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0997 - mae: 0.3108 - val_loss: 0.1852 - val_mae: 0.4189\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0884 - mae: 0.2922 - val_loss: 0.1630 - val_mae: 0.3919\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0731 - mae: 0.2648 - val_loss: 0.1377 - val_mae: 0.3583\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0561 - mae: 0.2306 - val_loss: 0.1120 - val_mae: 0.3205\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0396 - mae: 0.1914 - val_loss: 0.0874 - val_mae: 0.2796\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0252 - mae: 0.1490 - val_loss: 0.0656 - val_mae: 0.2376\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0140 - mae: 0.1052 - val_loss: 0.0475 - val_mae: 0.1961\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0066 - mae: 0.0661 - val_loss: 0.0335 - val_mae: 0.1563\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0033 - mae: 0.0511 - val_loss: 0.0233 - val_mae: 0.1197\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0034 - mae: 0.0471 - val_loss: 0.0166 - val_mae: 0.1040\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0061 - mae: 0.0628 - val_loss: 0.0125 - val_mae: 0.0911\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0101 - mae: 0.0867 - val_loss: 0.0103 - val_mae: 0.0899\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0144 - mae: 0.1069 - val_loss: 0.0093 - val_mae: 0.0892\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0181 - mae: 0.1228 - val_loss: 0.0089 - val_mae: 0.0886\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0204 - mae: 0.1322 - val_loss: 0.0087 - val_mae: 0.0881\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0213 - mae: 0.1353 - val_loss: 0.0087 - val_mae: 0.0877\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0205 - mae: 0.1327 - val_loss: 0.0089 - val_mae: 0.0874\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0186 - mae: 0.1251 - val_loss: 0.0094 - val_mae: 0.0871\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0157 - mae: 0.1132 - val_loss: 0.0104 - val_mae: 0.0869\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0125 - mae: 0.0979 - val_loss: 0.0121 - val_mae: 0.0920\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0093 - mae: 0.0823 - val_loss: 0.0145 - val_mae: 0.1005\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0065 - mae: 0.0665 - val_loss: 0.0176 - val_mae: 0.1093\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0045 - mae: 0.0537 - val_loss: 0.0214 - val_mae: 0.1180\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0033 - mae: 0.0471 - val_loss: 0.0256 - val_mae: 0.1321\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0029 - mae: 0.0475 - val_loss: 0.0300 - val_mae: 0.1478\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0030 - mae: 0.0496 - val_loss: 0.0342 - val_mae: 0.1617\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0035 - mae: 0.0513 - val_loss: 0.0381 - val_mae: 0.1734\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0042 - mae: 0.0540 - val_loss: 0.0413 - val_mae: 0.1826\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0049 - mae: 0.0567 - val_loss: 0.0438 - val_mae: 0.1893\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0055 - mae: 0.0594 - val_loss: 0.0453 - val_mae: 0.1934\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0059 - mae: 0.0611 - val_loss: 0.0459 - val_mae: 0.1950\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0060 - mae: 0.0618 - val_loss: 0.0456 - val_mae: 0.1943\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0059 - mae: 0.0611 - val_loss: 0.0444 - val_mae: 0.1915\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - loss: 0.6902 - mae: 0.8230 - val_loss: 0.2397 - val_mae: 0.4835\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3251 - mae: 0.5618 - val_loss: 0.0763 - val_mae: 0.2654\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1122 - mae: 0.3208 - val_loss: 0.0156 - val_mae: 0.0972\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0290 - mae: 0.1432 - val_loss: 0.0089 - val_mae: 0.0848\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0097 - mae: 0.0822 - val_loss: 0.0388 - val_mae: 0.1825\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0333 - mae: 0.1617 - val_loss: 0.0754 - val_mae: 0.2655\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0696 - mae: 0.2484 - val_loss: 0.0983 - val_mae: 0.3057\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0931 - mae: 0.2921 - val_loss: 0.1014 - val_mae: 0.3107\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0954 - mae: 0.2959 - val_loss: 0.0889 - val_mae: 0.2898\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0812 - mae: 0.2707 - val_loss: 0.0678 - val_mae: 0.2506\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0596 - mae: 0.2272 - val_loss: 0.0459 - val_mae: 0.2010\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0379 - mae: 0.1746 - val_loss: 0.0271 - val_mae: 0.1463\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0210 - mae: 0.1235 - val_loss: 0.0142 - val_mae: 0.1052\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0111 - mae: 0.0886 - val_loss: 0.0074 - val_mae: 0.0799\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0083 - mae: 0.0747 - val_loss: 0.0056 - val_mae: 0.0583\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0110 - mae: 0.0849 - val_loss: 0.0069 - val_mae: 0.0619\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0164 - mae: 0.1047 - val_loss: 0.0091 - val_mae: 0.0729\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0221 - mae: 0.1207 - val_loss: 0.0111 - val_mae: 0.0800\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0263 - mae: 0.1337 - val_loss: 0.0118 - val_mae: 0.0828\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0278 - mae: 0.1393 - val_loss: 0.0111 - val_mae: 0.0812\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0266 - mae: 0.1350 - val_loss: 0.0094 - val_mae: 0.0757\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0232 - mae: 0.1239 - val_loss: 0.0074 - val_mae: 0.0670\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0187 - mae: 0.1119 - val_loss: 0.0057 - val_mae: 0.0560\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0140 - mae: 0.0971 - val_loss: 0.0050 - val_mae: 0.0559\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0101 - mae: 0.0821 - val_loss: 0.0058 - val_mae: 0.0678\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0078 - mae: 0.0724 - val_loss: 0.0080 - val_mae: 0.0794\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0071 - mae: 0.0701 - val_loss: 0.0111 - val_mae: 0.0898\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0080 - mae: 0.0746 - val_loss: 0.0145 - val_mae: 0.0998\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0097 - mae: 0.0822 - val_loss: 0.0174 - val_mae: 0.1136\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0116 - mae: 0.0908 - val_loss: 0.0191 - val_mae: 0.1210\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0128 - mae: 0.0954 - val_loss: 0.0194 - val_mae: 0.1222\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0130 - mae: 0.0961 - val_loss: 0.0183 - val_mae: 0.1175\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0123 - mae: 0.0931 - val_loss: 0.0161 - val_mae: 0.1078\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0108 - mae: 0.0870 - val_loss: 0.0134 - val_mae: 0.0945\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0092 - mae: 0.0785 - val_loss: 0.0108 - val_mae: 0.0870\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0077 - mae: 0.0722 - val_loss: 0.0085 - val_mae: 0.0796\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0068 - mae: 0.0682 - val_loss: 0.0068 - val_mae: 0.0723\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0064 - mae: 0.0660 - val_loss: 0.0057 - val_mae: 0.0657\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0066 - mae: 0.0672 - val_loss: 0.0051 - val_mae: 0.0603\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0070 - mae: 0.0694 - val_loss: 0.0049 - val_mae: 0.0564\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0075 - mae: 0.0721 - val_loss: 0.0048 - val_mae: 0.0539\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0079 - mae: 0.0735 - val_loss: 0.0047 - val_mae: 0.0529\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0079 - mae: 0.0738 - val_loss: 0.0047 - val_mae: 0.0533\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0077 - mae: 0.0728 - val_loss: 0.0048 - val_mae: 0.0549\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0073 - mae: 0.0708 - val_loss: 0.0049 - val_mae: 0.0575\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0068 - mae: 0.0679 - val_loss: 0.0052 - val_mae: 0.0608\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0063 - mae: 0.0656 - val_loss: 0.0057 - val_mae: 0.0644\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0060 - mae: 0.0633 - val_loss: 0.0063 - val_mae: 0.0678\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0059 - mae: 0.0636 - val_loss: 0.0069 - val_mae: 0.0709\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0059 - mae: 0.0643 - val_loss: 0.0075 - val_mae: 0.0732\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - loss: 1.6810 - mae: 1.2836 - val_loss: 1.1156 - val_mae: 1.0487\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2152 - mae: 1.0902 - val_loss: 0.8010 - val_mae: 0.8863\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.8176 - mae: 0.8922 - val_loss: 0.5507 - val_mae: 0.7321\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5062 - mae: 0.6975 - val_loss: 0.3464 - val_mae: 0.5764\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2791 - mae: 0.5089 - val_loss: 0.1947 - val_mae: 0.4264\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1293 - mae: 0.3290 - val_loss: 0.0899 - val_mae: 0.2813\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0471 - mae: 0.1777 - val_loss: 0.0298 - val_mae: 0.1440\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0199 - mae: 0.1177 - val_loss: 0.0091 - val_mae: 0.0868\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0353 - mae: 0.1619 - val_loss: 0.0104 - val_mae: 0.0817\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0730 - mae: 0.2313 - val_loss: 0.0217 - val_mae: 0.1206\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1118 - mae: 0.3032 - val_loss: 0.0326 - val_mae: 0.1589\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1391 - mae: 0.3456 - val_loss: 0.0374 - val_mae: 0.1736\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1492 - mae: 0.3606 - val_loss: 0.0357 - val_mae: 0.1686\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1422 - mae: 0.3519 - val_loss: 0.0298 - val_mae: 0.1498\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1233 - mae: 0.3254 - val_loss: 0.0218 - val_mae: 0.1195\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0982 - mae: 0.2856 - val_loss: 0.0145 - val_mae: 0.0860\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0716 - mae: 0.2364 - val_loss: 0.0095 - val_mae: 0.0863\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0476 - mae: 0.1876 - val_loss: 0.0079 - val_mae: 0.0851\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0290 - mae: 0.1457 - val_loss: 0.0102 - val_mae: 0.0854\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0171 - mae: 0.1099 - val_loss: 0.0158 - val_mae: 0.1060\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0123 - mae: 0.0894 - val_loss: 0.0238 - val_mae: 0.1271\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0132 - mae: 0.0879 - val_loss: 0.0334 - val_mae: 0.1590\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0178 - mae: 0.1097 - val_loss: 0.0412 - val_mae: 0.1818\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0238 - mae: 0.1333 - val_loss: 0.0463 - val_mae: 0.1958\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0290 - mae: 0.1505 - val_loss: 0.0481 - val_mae: 0.2009\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0318 - mae: 0.1598 - val_loss: 0.0465 - val_mae: 0.1979\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0320 - mae: 0.1613 - val_loss: 0.0422 - val_mae: 0.1878\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0298 - mae: 0.1561 - val_loss: 0.0362 - val_mae: 0.1720\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0260 - mae: 0.1444 - val_loss: 0.0295 - val_mae: 0.1524\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0213 - mae: 0.1289 - val_loss: 0.0238 - val_mae: 0.1319\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0166 - mae: 0.1127 - val_loss: 0.0185 - val_mae: 0.1095\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0127 - mae: 0.0953 - val_loss: 0.0141 - val_mae: 0.0868\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0103 - mae: 0.0817 - val_loss: 0.0108 - val_mae: 0.0770\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0094 - mae: 0.0797 - val_loss: 0.0086 - val_mae: 0.0758\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0098 - mae: 0.0785 - val_loss: 0.0074 - val_mae: 0.0744\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0110 - mae: 0.0801 - val_loss: 0.0067 - val_mae: 0.0726\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0122 - mae: 0.0856 - val_loss: 0.0064 - val_mae: 0.0705\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0130 - mae: 0.0882 - val_loss: 0.0063 - val_mae: 0.0682\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0128 - mae: 0.0878 - val_loss: 0.0062 - val_mae: 0.0657\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0119 - mae: 0.0849 - val_loss: 0.0065 - val_mae: 0.0629\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0104 - mae: 0.0801 - val_loss: 0.0072 - val_mae: 0.0597\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0086 - mae: 0.0736 - val_loss: 0.0086 - val_mae: 0.0681\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0070 - mae: 0.0660 - val_loss: 0.0108 - val_mae: 0.0784\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0058 - mae: 0.0602 - val_loss: 0.0136 - val_mae: 0.0941\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0052 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.1115\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0052 - mae: 0.0606 - val_loss: 0.0204 - val_mae: 0.1271\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0055 - mae: 0.0623 - val_loss: 0.0235 - val_mae: 0.1387\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0060 - mae: 0.0651 - val_loss: 0.0253 - val_mae: 0.1451\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0061 - mae: 0.0663 - val_loss: 0.0256 - val_mae: 0.1461\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0059 - mae: 0.0653 - val_loss: 0.0246 - val_mae: 0.1423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - loss: 1.1783 - mae: 1.0724 - val_loss: 0.5547 - val_mae: 0.7378\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.7551 - mae: 0.8569 - val_loss: 0.3337 - val_mae: 0.5667\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4332 - mae: 0.6463 - val_loss: 0.1770 - val_mae: 0.4019\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2181 - mae: 0.4534 - val_loss: 0.0695 - val_mae: 0.2297\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0826 - mae: 0.2688 - val_loss: 0.0216 - val_mae: 0.1381\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0167 - mae: 0.1162 - val_loss: 0.0270 - val_mae: 0.1221\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0142 - mae: 0.0889 - val_loss: 0.0604 - val_mae: 0.2065\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0530 - mae: 0.2168 - val_loss: 0.0950 - val_mae: 0.2799\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0953 - mae: 0.3001 - val_loss: 0.1157 - val_mae: 0.3154\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1210 - mae: 0.3408 - val_loss: 0.1183 - val_mae: 0.3203\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1246 - mae: 0.3462 - val_loss: 0.1062 - val_mae: 0.3019\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1107 - mae: 0.3258 - val_loss: 0.0838 - val_mae: 0.2643\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0881 - mae: 0.2892 - val_loss: 0.0596 - val_mae: 0.2155\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0629 - mae: 0.2419 - val_loss: 0.0388 - val_mae: 0.1608\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0391 - mae: 0.1867 - val_loss: 0.0231 - val_mae: 0.1154\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0198 - mae: 0.1252 - val_loss: 0.0134 - val_mae: 0.0832\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0075 - mae: 0.0703 - val_loss: 0.0113 - val_mae: 0.0945\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0037 - mae: 0.0521 - val_loss: 0.0165 - val_mae: 0.1229\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0080 - mae: 0.0757 - val_loss: 0.0242 - val_mae: 0.1439\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0161 - mae: 0.1103 - val_loss: 0.0300 - val_mae: 0.1554\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0232 - mae: 0.1364 - val_loss: 0.0328 - val_mae: 0.1600\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0267 - mae: 0.1482 - val_loss: 0.0320 - val_mae: 0.1588\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0260 - mae: 0.1459 - val_loss: 0.0286 - val_mae: 0.1528\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0221 - mae: 0.1319 - val_loss: 0.0240 - val_mae: 0.1441\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0175 - mae: 0.1139 - val_loss: 0.0209 - val_mae: 0.1383\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0127 - mae: 0.0961 - val_loss: 0.0174 - val_mae: 0.1279\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0090 - mae: 0.0809 - val_loss: 0.0143 - val_mae: 0.1158\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0064 - mae: 0.0678 - val_loss: 0.0124 - val_mae: 0.1051\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0048 - mae: 0.0566 - val_loss: 0.0116 - val_mae: 0.0952\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0043 - mae: 0.0558 - val_loss: 0.0114 - val_mae: 0.0855\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - mae: 0.0577 - val_loss: 0.0118 - val_mae: 0.0786\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0059 - mae: 0.0629 - val_loss: 0.0124 - val_mae: 0.0784\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0072 - mae: 0.0691 - val_loss: 0.0130 - val_mae: 0.0783\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0080 - mae: 0.0738 - val_loss: 0.0133 - val_mae: 0.0779\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0084 - mae: 0.0759 - val_loss: 0.0131 - val_mae: 0.0773\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0082 - mae: 0.0749 - val_loss: 0.0127 - val_mae: 0.0767\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0075 - mae: 0.0714 - val_loss: 0.0122 - val_mae: 0.0760\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - mae: 0.0666 - val_loss: 0.0116 - val_mae: 0.0754\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0056 - mae: 0.0606 - val_loss: 0.0111 - val_mae: 0.0801\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0048 - mae: 0.0570 - val_loss: 0.0109 - val_mae: 0.0856\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0043 - mae: 0.0552 - val_loss: 0.0109 - val_mae: 0.0910\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0040 - mae: 0.0535 - val_loss: 0.0111 - val_mae: 0.0961\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0041 - mae: 0.0533 - val_loss: 0.0115 - val_mae: 0.1005\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0043 - mae: 0.0536 - val_loss: 0.0120 - val_mae: 0.1041\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0046 - mae: 0.0558 - val_loss: 0.0123 - val_mae: 0.1067\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0049 - mae: 0.0581 - val_loss: 0.0126 - val_mae: 0.1082\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0051 - mae: 0.0593 - val_loss: 0.0126 - val_mae: 0.1086\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0051 - mae: 0.0593 - val_loss: 0.0126 - val_mae: 0.1081\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - mae: 0.0582 - val_loss: 0.0123 - val_mae: 0.1067\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0047 - mae: 0.0562 - val_loss: 0.0120 - val_mae: 0.1046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step - loss: 0.0300 - mae: 0.1523 - val_loss: 0.0087 - val_mae: 0.0688\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0126 - mae: 0.0989 - val_loss: 0.0174 - val_mae: 0.1195\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0221 - mae: 0.1279 - val_loss: 0.0108 - val_mae: 0.0886\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0134 - mae: 0.0976 - val_loss: 0.0035 - val_mae: 0.0471\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0060 - mae: 0.0681 - val_loss: 0.0032 - val_mae: 0.0502\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0074 - mae: 0.0642 - val_loss: 0.0060 - val_mae: 0.0652\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0120 - mae: 0.0904 - val_loss: 0.0064 - val_mae: 0.0666\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0126 - mae: 0.0936 - val_loss: 0.0042 - val_mae: 0.0571\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0092 - mae: 0.0737 - val_loss: 0.0024 - val_mae: 0.0433\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0059 - mae: 0.0587 - val_loss: 0.0030 - val_mae: 0.0431\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0055 - mae: 0.0637 - val_loss: 0.0052 - val_mae: 0.0533\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0074 - mae: 0.0770 - val_loss: 0.0067 - val_mae: 0.0645\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0088 - mae: 0.0828 - val_loss: 0.0061 - val_mae: 0.0591\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0082 - mae: 0.0805 - val_loss: 0.0042 - val_mae: 0.0473\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0063 - mae: 0.0717 - val_loss: 0.0027 - val_mae: 0.0434\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0049 - mae: 0.0612 - val_loss: 0.0026 - val_mae: 0.0444\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0051 - mae: 0.0556 - val_loss: 0.0033 - val_mae: 0.0532\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0062 - mae: 0.0584 - val_loss: 0.0037 - val_mae: 0.0561\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0067 - mae: 0.0609 - val_loss: 0.0033 - val_mae: 0.0530\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0061 - mae: 0.0582 - val_loss: 0.0025 - val_mae: 0.0452\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0050 - mae: 0.0548 - val_loss: 0.0023 - val_mae: 0.0404\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mae: 0.0543 - val_loss: 0.0027 - val_mae: 0.0398\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0046 - mae: 0.0592 - val_loss: 0.0034 - val_mae: 0.0434\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0051 - mae: 0.0635 - val_loss: 0.0035 - val_mae: 0.0453\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0052 - mae: 0.0637 - val_loss: 0.0031 - val_mae: 0.0424\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0047 - mae: 0.0599 - val_loss: 0.0022 - val_mae: 0.0362\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0041 - mae: 0.0536 - val_loss: 0.0016 - val_mae: 0.0343\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0014 - val_mae: 0.0337\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0040 - mae: 0.0489 - val_loss: 0.0013 - val_mae: 0.0332\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0042 - mae: 0.0500 - val_loss: 0.0013 - val_mae: 0.0331\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0041 - mae: 0.0491 - val_loss: 0.0013 - val_mae: 0.0330\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0037 - mae: 0.0470 - val_loss: 0.0016 - val_mae: 0.0329\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0035 - mae: 0.0472 - val_loss: 0.0020 - val_mae: 0.0362\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0035 - mae: 0.0493 - val_loss: 0.0024 - val_mae: 0.0395\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0036 - mae: 0.0509 - val_loss: 0.0024 - val_mae: 0.0394\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0035 - mae: 0.0502 - val_loss: 0.0020 - val_mae: 0.0361\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0016 - val_mae: 0.0325\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0030 - mae: 0.0453 - val_loss: 0.0013 - val_mae: 0.0322\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0030 - mae: 0.0447 - val_loss: 0.0013 - val_mae: 0.0320\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0031 - mae: 0.0443 - val_loss: 0.0012 - val_mae: 0.0317\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0030 - mae: 0.0440 - val_loss: 0.0013 - val_mae: 0.0312\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0028 - mae: 0.0435 - val_loss: 0.0016 - val_mae: 0.0326\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0027 - mae: 0.0433 - val_loss: 0.0019 - val_mae: 0.0361\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0027 - mae: 0.0437 - val_loss: 0.0020 - val_mae: 0.0372\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0027 - mae: 0.0433 - val_loss: 0.0018 - val_mae: 0.0354\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0025 - mae: 0.0420 - val_loss: 0.0014 - val_mae: 0.0319\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0024 - mae: 0.0409 - val_loss: 0.0011 - val_mae: 0.0283\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0024 - mae: 0.0403 - val_loss: 0.0010 - val_mae: 0.0268\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0024 - mae: 0.0398 - val_loss: 0.0010 - val_mae: 0.0274\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0023 - mae: 0.0393 - val_loss: 0.0012 - val_mae: 0.0303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step - loss: 4.6502 - mae: 2.1471 - val_loss: 3.1144 - val_mae: 1.7592\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.4892 - mae: 1.8576 - val_loss: 2.2118 - val_mae: 1.4809\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.5147 - mae: 1.5742 - val_loss: 1.5028 - val_mae: 1.2191\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.7216 - mae: 1.2989 - val_loss: 0.9653 - val_mae: 0.9750\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.1308 - mae: 1.0483 - val_loss: 0.5785 - val_mae: 0.7507\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6905 - mae: 0.8128 - val_loss: 0.3284 - val_mae: 0.5607\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3779 - mae: 0.5920 - val_loss: 0.1617 - val_mae: 0.3854\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1835 - mae: 0.3947 - val_loss: 0.0596 - val_mae: 0.2161\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0805 - mae: 0.2275 - val_loss: 0.0171 - val_mae: 0.0978\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0401 - mae: 0.1650 - val_loss: 0.0185 - val_mae: 0.1272\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0382 - mae: 0.1711 - val_loss: 0.0418 - val_mae: 0.1801\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0593 - mae: 0.2109 - val_loss: 0.0745 - val_mae: 0.2410\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0905 - mae: 0.2560 - val_loss: 0.1053 - val_mae: 0.2971\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1210 - mae: 0.2994 - val_loss: 0.1283 - val_mae: 0.3329\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1435 - mae: 0.3302 - val_loss: 0.1410 - val_mae: 0.3515\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.1550 - mae: 0.3445 - val_loss: 0.1428 - val_mae: 0.3544\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1555 - mae: 0.3451 - val_loss: 0.1358 - val_mae: 0.3450\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1467 - mae: 0.3339 - val_loss: 0.1219 - val_mae: 0.3251\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1312 - mae: 0.3132 - val_loss: 0.1045 - val_mae: 0.2980\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1114 - mae: 0.2840 - val_loss: 0.0853 - val_mae: 0.2660\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0902 - mae: 0.2505 - val_loss: 0.0664 - val_mae: 0.2306\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0707 - mae: 0.2216 - val_loss: 0.0503 - val_mae: 0.1951\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0546 - mae: 0.1945 - val_loss: 0.0372 - val_mae: 0.1602\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0430 - mae: 0.1709 - val_loss: 0.0265 - val_mae: 0.1422\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0357 - mae: 0.1520 - val_loss: 0.0189 - val_mae: 0.1247\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0319 - mae: 0.1473 - val_loss: 0.0140 - val_mae: 0.1083\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0316 - mae: 0.1474 - val_loss: 0.0115 - val_mae: 0.0938\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0334 - mae: 0.1540 - val_loss: 0.0106 - val_mae: 0.0815\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0358 - mae: 0.1607 - val_loss: 0.0105 - val_mae: 0.0771\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0382 - mae: 0.1665 - val_loss: 0.0106 - val_mae: 0.0747\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0400 - mae: 0.1698 - val_loss: 0.0106 - val_mae: 0.0752\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0406 - mae: 0.1714 - val_loss: 0.0104 - val_mae: 0.0749\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0401 - mae: 0.1701 - val_loss: 0.0100 - val_mae: 0.0715\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0388 - mae: 0.1659 - val_loss: 0.0094 - val_mae: 0.0666\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0366 - mae: 0.1591 - val_loss: 0.0090 - val_mae: 0.0717\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0342 - mae: 0.1540 - val_loss: 0.0090 - val_mae: 0.0798\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0318 - mae: 0.1484 - val_loss: 0.0097 - val_mae: 0.0891\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0299 - mae: 0.1423 - val_loss: 0.0110 - val_mae: 0.0982\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0286 - mae: 0.1380 - val_loss: 0.0126 - val_mae: 0.1068\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0279 - mae: 0.1346 - val_loss: 0.0145 - val_mae: 0.1141\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0277 - mae: 0.1328 - val_loss: 0.0161 - val_mae: 0.1194\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0279 - mae: 0.1339 - val_loss: 0.0173 - val_mae: 0.1225\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0280 - mae: 0.1358 - val_loss: 0.0178 - val_mae: 0.1229\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0280 - mae: 0.1367 - val_loss: 0.0176 - val_mae: 0.1214\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0277 - mae: 0.1364 - val_loss: 0.0168 - val_mae: 0.1182\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0270 - mae: 0.1352 - val_loss: 0.0155 - val_mae: 0.1134\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0260 - mae: 0.1328 - val_loss: 0.0144 - val_mae: 0.1085\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0249 - mae: 0.1297 - val_loss: 0.0133 - val_mae: 0.1043\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0238 - mae: 0.1262 - val_loss: 0.0125 - val_mae: 0.1010\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0227 - mae: 0.1236 - val_loss: 0.0118 - val_mae: 0.0983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - loss: 3.0871 - mae: 1.7322 - val_loss: 1.2665 - val_mae: 1.1216\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.0573 - mae: 1.4057 - val_loss: 0.6795 - val_mae: 0.8195\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2487 - mae: 1.0842 - val_loss: 0.3433 - val_mae: 0.5765\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6876 - mae: 0.7966 - val_loss: 0.1638 - val_mae: 0.3936\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3368 - mae: 0.5536 - val_loss: 0.0818 - val_mae: 0.2724\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1624 - mae: 0.3801 - val_loss: 0.0356 - val_mae: 0.1680\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0855 - mae: 0.2642 - val_loss: 0.0123 - val_mae: 0.0914\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0409 - mae: 0.1701 - val_loss: 0.0053 - val_mae: 0.0569\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0180 - mae: 0.1233 - val_loss: 0.0118 - val_mae: 0.0906\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0130 - mae: 0.0984 - val_loss: 0.0276 - val_mae: 0.1540\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0212 - mae: 0.1092 - val_loss: 0.0480 - val_mae: 0.2106\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0368 - mae: 0.1615 - val_loss: 0.0669 - val_mae: 0.2519\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0537 - mae: 0.2086 - val_loss: 0.0819 - val_mae: 0.2804\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0670 - mae: 0.2387 - val_loss: 0.0912 - val_mae: 0.2968\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0744 - mae: 0.2538 - val_loss: 0.0936 - val_mae: 0.3008\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0758 - mae: 0.2566 - val_loss: 0.0897 - val_mae: 0.2941\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0716 - mae: 0.2477 - val_loss: 0.0815 - val_mae: 0.2797\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0631 - mae: 0.2295 - val_loss: 0.0704 - val_mae: 0.2588\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0524 - mae: 0.2040 - val_loss: 0.0577 - val_mae: 0.2326\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0411 - mae: 0.1732 - val_loss: 0.0448 - val_mae: 0.2028\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0306 - mae: 0.1385 - val_loss: 0.0330 - val_mae: 0.1708\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0219 - mae: 0.1084 - val_loss: 0.0222 - val_mae: 0.1359\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0158 - mae: 0.0968 - val_loss: 0.0139 - val_mae: 0.1007\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0127 - mae: 0.0975 - val_loss: 0.0085 - val_mae: 0.0783\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0123 - mae: 0.1006 - val_loss: 0.0054 - val_mae: 0.0642\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0138 - mae: 0.1070 - val_loss: 0.0041 - val_mae: 0.0522\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0166 - mae: 0.1184 - val_loss: 0.0038 - val_mae: 0.0486\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0196 - mae: 0.1272 - val_loss: 0.0041 - val_mae: 0.0507\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0221 - mae: 0.1334 - val_loss: 0.0044 - val_mae: 0.0547\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0238 - mae: 0.1367 - val_loss: 0.0045 - val_mae: 0.0561\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0242 - mae: 0.1374 - val_loss: 0.0043 - val_mae: 0.0551\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0235 - mae: 0.1357 - val_loss: 0.0040 - val_mae: 0.0520\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0219 - mae: 0.1319 - val_loss: 0.0037 - val_mae: 0.0472\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0196 - mae: 0.1263 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0171 - mae: 0.1192 - val_loss: 0.0037 - val_mae: 0.0487\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0146 - mae: 0.1112 - val_loss: 0.0044 - val_mae: 0.0560\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0126 - mae: 0.1025 - val_loss: 0.0056 - val_mae: 0.0634\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0112 - mae: 0.0962 - val_loss: 0.0072 - val_mae: 0.0706\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0105 - mae: 0.0925 - val_loss: 0.0092 - val_mae: 0.0775\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0103 - mae: 0.0893 - val_loss: 0.0114 - val_mae: 0.0905\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0883 - val_loss: 0.0134 - val_mae: 0.1012\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0112 - mae: 0.0875 - val_loss: 0.0151 - val_mae: 0.1094\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0118 - mae: 0.0867 - val_loss: 0.0162 - val_mae: 0.1148\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0124 - mae: 0.0860 - val_loss: 0.0168 - val_mae: 0.1173\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0126 - mae: 0.0857 - val_loss: 0.0167 - val_mae: 0.1170\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0126 - mae: 0.0854 - val_loss: 0.0160 - val_mae: 0.1142\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0122 - mae: 0.0847 - val_loss: 0.0148 - val_mae: 0.1091\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0116 - mae: 0.0842 - val_loss: 0.0133 - val_mae: 0.1021\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0109 - mae: 0.0839 - val_loss: 0.0117 - val_mae: 0.0938\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0102 - mae: 0.0836 - val_loss: 0.0100 - val_mae: 0.0846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step - loss: 0.1397 - mae: 0.3095 - val_loss: 0.0675 - val_mae: 0.2242\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0494 - mae: 0.1708 - val_loss: 0.0923 - val_mae: 0.2330\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0668 - mae: 0.2395 - val_loss: 0.0692 - val_mae: 0.2085\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0588 - mae: 0.2178 - val_loss: 0.0387 - val_mae: 0.1686\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0323 - mae: 0.1541 - val_loss: 0.0330 - val_mae: 0.1591\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0236 - mae: 0.1299 - val_loss: 0.0507 - val_mae: 0.1772\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0354 - mae: 0.1554 - val_loss: 0.0612 - val_mae: 0.1916\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0414 - mae: 0.1692 - val_loss: 0.0530 - val_mae: 0.1771\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0328 - mae: 0.1515 - val_loss: 0.0385 - val_mae: 0.1516\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0206 - mae: 0.1264 - val_loss: 0.0295 - val_mae: 0.1537\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0153 - mae: 0.1061 - val_loss: 0.0292 - val_mae: 0.1556\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0185 - mae: 0.1087 - val_loss: 0.0317 - val_mae: 0.1571\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0227 - mae: 0.1171 - val_loss: 0.0311 - val_mae: 0.1569\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0215 - mae: 0.1133 - val_loss: 0.0277 - val_mae: 0.1546\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0160 - mae: 0.0983 - val_loss: 0.0258 - val_mae: 0.1512\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0111 - mae: 0.0844 - val_loss: 0.0281 - val_mae: 0.1485\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0101 - mae: 0.0867 - val_loss: 0.0313 - val_mae: 0.1444\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0121 - mae: 0.0935 - val_loss: 0.0316 - val_mae: 0.1405\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0135 - mae: 0.0990 - val_loss: 0.0290 - val_mae: 0.1394\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0121 - mae: 0.0930 - val_loss: 0.0249 - val_mae: 0.1389\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0093 - mae: 0.0786 - val_loss: 0.0221 - val_mae: 0.1395\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0074 - mae: 0.0667 - val_loss: 0.0219 - val_mae: 0.1413\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0078 - mae: 0.0673 - val_loss: 0.0230 - val_mae: 0.1426\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0092 - mae: 0.0763 - val_loss: 0.0234 - val_mae: 0.1432\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0093 - mae: 0.0773 - val_loss: 0.0226 - val_mae: 0.1428\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0078 - mae: 0.0687 - val_loss: 0.0219 - val_mae: 0.1418\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0062 - mae: 0.0574 - val_loss: 0.0224 - val_mae: 0.1404\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - mae: 0.0556 - val_loss: 0.0238 - val_mae: 0.1397\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0064 - mae: 0.0617 - val_loss: 0.0250 - val_mae: 0.1403\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0069 - mae: 0.0665 - val_loss: 0.0249 - val_mae: 0.1412\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0640 - val_loss: 0.0239 - val_mae: 0.1423\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0231 - val_mae: 0.1436\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - mae: 0.0499 - val_loss: 0.0229 - val_mae: 0.1447\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0048 - mae: 0.0509 - val_loss: 0.0231 - val_mae: 0.1456\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0052 - mae: 0.0540 - val_loss: 0.0234 - val_mae: 0.1460\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0052 - mae: 0.0546 - val_loss: 0.0233 - val_mae: 0.1460\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - mae: 0.0512 - val_loss: 0.0233 - val_mae: 0.1454\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0041 - mae: 0.0475 - val_loss: 0.0237 - val_mae: 0.1446\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0038 - mae: 0.0448 - val_loss: 0.0243 - val_mae: 0.1438\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0039 - mae: 0.0459 - val_loss: 0.0248 - val_mae: 0.1434\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0040 - mae: 0.0477 - val_loss: 0.0248 - val_mae: 0.1433\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0038 - mae: 0.0463 - val_loss: 0.0243 - val_mae: 0.1435\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0034 - mae: 0.0426 - val_loss: 0.0238 - val_mae: 0.1438\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0031 - mae: 0.0413 - val_loss: 0.0235 - val_mae: 0.1441\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0031 - mae: 0.0420 - val_loss: 0.0235 - val_mae: 0.1444\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0032 - mae: 0.0423 - val_loss: 0.0236 - val_mae: 0.1443\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0236 - val_mae: 0.1439\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0028 - mae: 0.0398 - val_loss: 0.0238 - val_mae: 0.1431\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0026 - mae: 0.0379 - val_loss: 0.0241 - val_mae: 0.1424\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0026 - mae: 0.0373 - val_loss: 0.0244 - val_mae: 0.1417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step - loss: 0.8681 - mae: 0.9246 - val_loss: 0.5215 - val_mae: 0.7165\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.7151 - mae: 0.8387 - val_loss: 0.4203 - val_mae: 0.6425\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5860 - mae: 0.7583 - val_loss: 0.3334 - val_mae: 0.5719\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4869 - mae: 0.6895 - val_loss: 0.2571 - val_mae: 0.5020\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3985 - mae: 0.6216 - val_loss: 0.1947 - val_mae: 0.4362\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3211 - mae: 0.5558 - val_loss: 0.1437 - val_mae: 0.3738\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2539 - mae: 0.4922 - val_loss: 0.1022 - val_mae: 0.3141\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1953 - mae: 0.4291 - val_loss: 0.0687 - val_mae: 0.2560\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1450 - mae: 0.3669 - val_loss: 0.0444 - val_mae: 0.2049\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1041 - mae: 0.3074 - val_loss: 0.0267 - val_mae: 0.1571\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0726 - mae: 0.2521 - val_loss: 0.0145 - val_mae: 0.1121\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0482 - mae: 0.2000 - val_loss: 0.0064 - val_mae: 0.0676\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0311 - mae: 0.1534 - val_loss: 0.0021 - val_mae: 0.0365\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0183 - mae: 0.1066 - val_loss: 0.0015 - val_mae: 0.0361\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0097 - mae: 0.0731 - val_loss: 0.0048 - val_mae: 0.0616\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0058 - mae: 0.0627 - val_loss: 0.0112 - val_mae: 0.1016\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0064 - mae: 0.0691 - val_loss: 0.0194 - val_mae: 0.1366\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0100 - mae: 0.0897 - val_loss: 0.0278 - val_mae: 0.1647\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0152 - mae: 0.1107 - val_loss: 0.0348 - val_mae: 0.1852\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0201 - mae: 0.1260 - val_loss: 0.0397 - val_mae: 0.1979\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0238 - mae: 0.1389 - val_loss: 0.0419 - val_mae: 0.2034\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0256 - mae: 0.1454 - val_loss: 0.0415 - val_mae: 0.2026\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0254 - mae: 0.1449 - val_loss: 0.0390 - val_mae: 0.1963\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0236 - mae: 0.1384 - val_loss: 0.0349 - val_mae: 0.1854\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0207 - mae: 0.1274 - val_loss: 0.0299 - val_mae: 0.1713\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0173 - mae: 0.1172 - val_loss: 0.0252 - val_mae: 0.1566\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0141 - mae: 0.1062 - val_loss: 0.0210 - val_mae: 0.1420\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0114 - mae: 0.0953 - val_loss: 0.0174 - val_mae: 0.1285\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0093 - mae: 0.0845 - val_loss: 0.0143 - val_mae: 0.1157\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0078 - mae: 0.0761 - val_loss: 0.0116 - val_mae: 0.1034\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0068 - mae: 0.0707 - val_loss: 0.0095 - val_mae: 0.0923\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0061 - mae: 0.0677 - val_loss: 0.0077 - val_mae: 0.0817\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0058 - mae: 0.0658 - val_loss: 0.0063 - val_mae: 0.0719\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0057 - mae: 0.0645 - val_loss: 0.0051 - val_mae: 0.0630\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0057 - mae: 0.0634 - val_loss: 0.0042 - val_mae: 0.0552\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0059 - mae: 0.0631 - val_loss: 0.0036 - val_mae: 0.0507\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0062 - mae: 0.0635 - val_loss: 0.0031 - val_mae: 0.0481\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0064 - mae: 0.0640 - val_loss: 0.0028 - val_mae: 0.0462\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0066 - mae: 0.0641 - val_loss: 0.0025 - val_mae: 0.0446\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - mae: 0.0639 - val_loss: 0.0024 - val_mae: 0.0435\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - mae: 0.0633 - val_loss: 0.0024 - val_mae: 0.0429\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - mae: 0.0626 - val_loss: 0.0024 - val_mae: 0.0427\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0064 - mae: 0.0618 - val_loss: 0.0025 - val_mae: 0.0429\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0062 - mae: 0.0607 - val_loss: 0.0026 - val_mae: 0.0435\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0059 - mae: 0.0596 - val_loss: 0.0028 - val_mae: 0.0442\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0056 - mae: 0.0584 - val_loss: 0.0031 - val_mae: 0.0459\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0053 - mae: 0.0577 - val_loss: 0.0034 - val_mae: 0.0494\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0051 - mae: 0.0572 - val_loss: 0.0037 - val_mae: 0.0531\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0049 - mae: 0.0573 - val_loss: 0.0042 - val_mae: 0.0572\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0047 - mae: 0.0574 - val_loss: 0.0047 - val_mae: 0.0615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and preprocess the data\n",
    "#data = pd.read_csv('stock_prices.csv')  # Replace with your file\n",
    "data = yf.download('AVGO', start=\"2024-06-20\", end=\"2024-11-20\")\n",
    "closing_prices = data['Close']['AVGO'].values.reshape(-1, 1)\n",
    "\n",
    "ticker_id=[]\n",
    "NextDayPrediction=[]\n",
    "PreviousDayPrice= []\n",
    "EPS= []\n",
    "RMSE= []\n",
    "\n",
    "for i in ticker_lst:\n",
    "    ticker_id.append(i)\n",
    "    data = yf.download(i, start=\"2024-06-20\", end=\"2024-11-21\")\n",
    "    closing_prices = data['Close'][i].values.reshape(-1, 1)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_prices = scaler.fit_transform(closing_prices)\n",
    "\n",
    "    # Create features and labels\n",
    "    def create_dataset(data, window_size):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - window_size):\n",
    "            X.append(data[i:i + window_size])\n",
    "            y.append(data[i + window_size])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    window_size = 90  # Use the past 10 days to predict the next day\n",
    "    X, y = create_dataset(scaled_prices, window_size)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build the ANN model\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)  # Output layer for predicting next day price\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    # Predict the next day's price\n",
    "    last_days = scaled_prices[-window_size:].reshape(1, -1)\n",
    "    predicted_price_scaled = model.predict(last_days)\n",
    "    predicted_price = scaler.inverse_transform(predicted_price_scaled)\n",
    "    \n",
    "    NextDayPrediction.append(predicted_price[0][0])\n",
    "    pd_price= closing_prices[-1][0]\n",
    "    PreviousDayPrice.append(pd_price)\n",
    "    EPS.append(NextDayPrediction-pd_price)\n",
    "\n",
    "    #print(f\"Predicted next day's price: {predicted_price[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_analysis= pd.DataFrame()\n",
    "ANN_analysis['ticker_id']= ticker_id\n",
    "ANN_analysis['NextDayPrediction']= NextDayPrediction\n",
    "ANN_analysis['PreviousDayPrice']= PreviousDayPrice\n",
    "ANN_analysis['EPS']= ANN_analysis['NextDayPrediction']-ANN_analysis['PreviousDayPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_id</th>\n",
       "      <th>NextDayPrediction</th>\n",
       "      <th>PreviousDayPrice</th>\n",
       "      <th>EPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>142.581741</td>\n",
       "      <td>145.889999</td>\n",
       "      <td>-3.308258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>225.196716</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>-3.803284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>414.365234</td>\n",
       "      <td>415.489990</td>\n",
       "      <td>-1.124756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>208.760635</td>\n",
       "      <td>202.880005</td>\n",
       "      <td>5.880630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>175.423828</td>\n",
       "      <td>177.330002</td>\n",
       "      <td>-1.906174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>META</td>\n",
       "      <td>570.804199</td>\n",
       "      <td>565.520020</td>\n",
       "      <td>5.284180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>332.187744</td>\n",
       "      <td>342.029999</td>\n",
       "      <td>-9.842255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BRK-B</td>\n",
       "      <td>469.612793</td>\n",
       "      <td>468.829987</td>\n",
       "      <td>0.782806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AVGO</td>\n",
       "      <td>166.933319</td>\n",
       "      <td>163.250000</td>\n",
       "      <td>3.683319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WMT</td>\n",
       "      <td>87.383652</td>\n",
       "      <td>87.180000</td>\n",
       "      <td>0.203651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LLY</td>\n",
       "      <td>718.576782</td>\n",
       "      <td>753.409973</td>\n",
       "      <td>-34.833191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JPM</td>\n",
       "      <td>252.278030</td>\n",
       "      <td>240.779999</td>\n",
       "      <td>11.498032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V</td>\n",
       "      <td>309.849976</td>\n",
       "      <td>307.390015</td>\n",
       "      <td>2.459961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UNH</td>\n",
       "      <td>596.582703</td>\n",
       "      <td>600.500000</td>\n",
       "      <td>-3.917297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XOM</td>\n",
       "      <td>119.761169</td>\n",
       "      <td>120.320000</td>\n",
       "      <td>-0.558830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORCL</td>\n",
       "      <td>184.600830</td>\n",
       "      <td>190.750000</td>\n",
       "      <td>-6.149170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MA</td>\n",
       "      <td>522.886475</td>\n",
       "      <td>512.539978</td>\n",
       "      <td>10.346497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COST</td>\n",
       "      <td>934.977844</td>\n",
       "      <td>928.080017</td>\n",
       "      <td>6.897827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HD</td>\n",
       "      <td>406.568542</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>6.568542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PG</td>\n",
       "      <td>169.823746</td>\n",
       "      <td>170.889999</td>\n",
       "      <td>-1.066254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>851.864563</td>\n",
       "      <td>883.849976</td>\n",
       "      <td>-31.985413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker_id  NextDayPrediction  PreviousDayPrice        EPS\n",
       "0       NVDA         142.581741        145.889999  -3.308258\n",
       "1       AAPL         225.196716        229.000000  -3.803284\n",
       "2       MSFT         414.365234        415.489990  -1.124756\n",
       "3       AMZN         208.760635        202.880005   5.880630\n",
       "4       GOOG         175.423828        177.330002  -1.906174\n",
       "5       META         570.804199        565.520020   5.284180\n",
       "6       TSLA         332.187744        342.029999  -9.842255\n",
       "7      BRK-B         469.612793        468.829987   0.782806\n",
       "8       AVGO         166.933319        163.250000   3.683319\n",
       "9        WMT          87.383652         87.180000   0.203651\n",
       "10       LLY         718.576782        753.409973 -34.833191\n",
       "11       JPM         252.278030        240.779999  11.498032\n",
       "12         V         309.849976        307.390015   2.459961\n",
       "13       UNH         596.582703        600.500000  -3.917297\n",
       "14       XOM         119.761169        120.320000  -0.558830\n",
       "15      ORCL         184.600830        190.750000  -6.149170\n",
       "16        MA         522.886475        512.539978  10.346497\n",
       "17      COST         934.977844        928.080017   6.897827\n",
       "18        HD         406.568542        400.000000   6.568542\n",
       "19        PG         169.823746        170.889999  -1.066254\n",
       "20      NFLX         851.864563        883.849976 -31.985413"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     136.020004\n",
       "1     232.869995\n",
       "2     418.790009\n",
       "3     201.449997\n",
       "4     169.429993\n",
       "5     565.109985\n",
       "6     338.589996\n",
       "7     477.429993\n",
       "8     164.820007\n",
       "9      89.500000\n",
       "10    755.000000\n",
       "11    250.289993\n",
       "12    313.190002\n",
       "13    605.830017\n",
       "14    119.970001\n",
       "15    187.990005\n",
       "16    526.599976\n",
       "17    960.890015\n",
       "18    428.670013\n",
       "19    177.389999\n",
       "20    865.590027\n",
       "Name: PD_price, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df['PD_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Line plot for prices\n",
    "# ax1.plot(analysis_df.index, analysis_df['PD_price'], label='Actual Price', color='blue')\n",
    "# ax1.plot(analysis_df.index, analysis_df['ND_Predictions'], label='Predicted Price', color='green', linestyle='--')\n",
    "ax1.plot(ANN_analysis.index, ANN_analysis['EPS'], label='EPS ', color='blue')\n",
    "ax1.set_xlabel('Ticker')\n",
    "ax1.set_ylabel('Price', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.set_xticks(ANN_analysis.index)  # Set tick positions\n",
    "ax1.set_xticklabels(ANN_analysis['ticker_id'], rotation=45)  # Optionally set tick labels with rotation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Bar plot for RMSE\n",
    "# ax2 = ax1.twinx()\n",
    "# bars = ax2.bar(analysis_df.index, analysis_df['RMSE'], alpha=0.3, label='RMSE', color='orange')\n",
    "# ax2.set_ylabel('RMSE', color='orange')\n",
    "# ax2.tick_params(axis='y', labelcolor='orange')\n",
    "# ax2.legend(loc='upper right')\n",
    "\n",
    "# # Add TickerID labels on top of bars\n",
    "# for bar, ticker_id in zip(bars, analysis_df['ticker_id']):\n",
    "#     ax2.text(\n",
    "#         bar.get_x() + bar.get_width() / 2,  # X-coordinate (center of the bar)\n",
    "#         bar.get_height(),                  # Y-coordinate (top of the bar)\n",
    "#         ticker_id,                         # TickerID to display\n",
    "#         ha='center', va='bottom', fontsize=9, rotation=45, color='black'\n",
    "#     )\n",
    "\n",
    "plt.title('EPS according to ANN ')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     141.930263\n",
       "1     230.336161\n",
       "2     419.447780\n",
       "3     200.049872\n",
       "4     168.916708\n",
       "5     571.154368\n",
       "6     346.185548\n",
       "7     471.216121\n",
       "8     170.166202\n",
       "9      89.540440\n",
       "10    746.171100\n",
       "11    245.249105\n",
       "12    310.408944\n",
       "13    586.223123\n",
       "14    121.544716\n",
       "15    190.571884\n",
       "16    518.891309\n",
       "17    957.218634\n",
       "18    414.890780\n",
       "19    174.663804\n",
       "20    898.904545\n",
       "Name: ND_Predictions, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df['ND_Predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/k1/k9yjwyjj6txbvvlybvf7xp1w0000gn/T/ipykernel_20917/1305974571.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_closing_price= float(data['Close'][i])\n"
     ]
    }
   ],
   "source": [
    "Actual_Prices= pd.DataFrame()\n",
    "ticker= []\n",
    "price=[]\n",
    "for i in ticker_lst:\n",
    "    data = yf.download(i, start=\"2024-11-20\", end=\"2024-11-21\")\n",
    "    ticker.append(i)\n",
    "\n",
    "    actual_closing_price= float(data['Close'][i])\n",
    "    price.append(actual_closing_price)\n",
    "\n",
    "Actual_Prices['ticker']= ticker\n",
    "Actual_Prices['price']= price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>145.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>415.489990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>202.880005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>177.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>META</td>\n",
       "      <td>565.520020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>342.029999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BRK-B</td>\n",
       "      <td>468.829987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AVGO</td>\n",
       "      <td>163.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WMT</td>\n",
       "      <td>87.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LLY</td>\n",
       "      <td>753.409973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JPM</td>\n",
       "      <td>240.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V</td>\n",
       "      <td>307.390015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UNH</td>\n",
       "      <td>600.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XOM</td>\n",
       "      <td>120.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORCL</td>\n",
       "      <td>190.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MA</td>\n",
       "      <td>512.539978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COST</td>\n",
       "      <td>928.080017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HD</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PG</td>\n",
       "      <td>170.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>883.849976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker       price\n",
       "0    NVDA  145.889999\n",
       "1    AAPL  229.000000\n",
       "2    MSFT  415.489990\n",
       "3    AMZN  202.880005\n",
       "4    GOOG  177.330002\n",
       "5    META  565.520020\n",
       "6    TSLA  342.029999\n",
       "7   BRK-B  468.829987\n",
       "8    AVGO  163.250000\n",
       "9     WMT   87.180000\n",
       "10    LLY  753.409973\n",
       "11    JPM  240.779999\n",
       "12      V  307.390015\n",
       "13    UNH  600.500000\n",
       "14    XOM  120.320000\n",
       "15   ORCL  190.750000\n",
       "16     MA  512.539978\n",
       "17   COST  928.080017\n",
       "18     HD  400.000000\n",
       "19     PG  170.889999\n",
       "20   NFLX  883.849976"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Actual_Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     142.581741\n",
       "1     225.196716\n",
       "2     414.365234\n",
       "3     208.760635\n",
       "4     175.423828\n",
       "5     570.804199\n",
       "6     332.187744\n",
       "7     469.612793\n",
       "8     166.933319\n",
       "9      87.383652\n",
       "10    718.576782\n",
       "11    252.278030\n",
       "12    309.849976\n",
       "13    596.582703\n",
       "14    119.761169\n",
       "15    184.600830\n",
       "16    522.886475\n",
       "17    934.977844\n",
       "18    406.568542\n",
       "19    169.823746\n",
       "20    851.864563\n",
       "Name: NextDayPrediction, dtype: float32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_analysis['NextDayPrediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
