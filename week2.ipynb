{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used Artifitial Neural Networks to predict next day prices in week 2 and investd in the following stocks\n",
    "# 1) AAPL 2) TSLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import yfinance as yf\n",
    "\n",
    "ticker= ['NVDA','AAPL', 'MSFT', 'AMZN', 'GOOG', 'META', 'TSLA', 'BRK-B', 'AVGO', 'WMT', 'LLY', 'JPM', 'V', 'UNH', 'XOM', 'ORCL', 'MA', 'COST', 'HD', 'PG', 'NFLX' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step - loss: 0.0259 - mae: 0.1314 - val_loss: 0.0120 - val_mae: 0.0940\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0138 - mae: 0.1029 - val_loss: 0.0230 - val_mae: 0.1093\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0193 - mae: 0.1118 - val_loss: 0.0117 - val_mae: 0.0970\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0116 - mae: 0.0829 - val_loss: 0.0177 - val_mae: 0.1054\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0162 - mae: 0.0940 - val_loss: 0.0106 - val_mae: 0.0898\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0099 - mae: 0.0830 - val_loss: 0.0085 - val_mae: 0.0892\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0099 - mae: 0.0837 - val_loss: 0.0098 - val_mae: 0.0863\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0107 - mae: 0.0895 - val_loss: 0.0078 - val_mae: 0.0826\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0065 - mae: 0.0693 - val_loss: 0.0068 - val_mae: 0.0778\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0047 - mae: 0.0595 - val_loss: 0.0073 - val_mae: 0.0756\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0058 - mae: 0.0576 - val_loss: 0.0065 - val_mae: 0.0739\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0046 - mae: 0.0541 - val_loss: 0.0067 - val_mae: 0.0723\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0032 - mae: 0.0480 - val_loss: 0.0090 - val_mae: 0.0786\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0037 - mae: 0.0510 - val_loss: 0.0100 - val_mae: 0.0826\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0041 - mae: 0.0524 - val_loss: 0.0084 - val_mae: 0.0758\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0030 - mae: 0.0446 - val_loss: 0.0065 - val_mae: 0.0701\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0026 - mae: 0.0409 - val_loss: 0.0059 - val_mae: 0.0701\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0031 - mae: 0.0483 - val_loss: 0.0058 - val_mae: 0.0700\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0029 - mae: 0.0463 - val_loss: 0.0062 - val_mae: 0.0696\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0021 - mae: 0.0373 - val_loss: 0.0071 - val_mae: 0.0716\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0022 - mae: 0.0378 - val_loss: 0.0075 - val_mae: 0.0749\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0025 - mae: 0.0399 - val_loss: 0.0068 - val_mae: 0.0707\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0021 - mae: 0.0369 - val_loss: 0.0059 - val_mae: 0.0697\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0017 - mae: 0.0332 - val_loss: 0.0057 - val_mae: 0.0696\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0018 - mae: 0.0353 - val_loss: 0.0058 - val_mae: 0.0695\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0019 - mae: 0.0356 - val_loss: 0.0058 - val_mae: 0.0695\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0016 - mae: 0.0335 - val_loss: 0.0058 - val_mae: 0.0695\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0015 - mae: 0.0316 - val_loss: 0.0059 - val_mae: 0.0693\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0017 - mae: 0.0335 - val_loss: 0.0058 - val_mae: 0.0688\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0015 - mae: 0.0316 - val_loss: 0.0055 - val_mae: 0.0680\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0013 - mae: 0.0303 - val_loss: 0.0055 - val_mae: 0.0671\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0014 - mae: 0.0309 - val_loss: 0.0054 - val_mae: 0.0662\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0013 - mae: 0.0303 - val_loss: 0.0050 - val_mae: 0.0652\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0011 - mae: 0.0283 - val_loss: 0.0049 - val_mae: 0.0643\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0011 - mae: 0.0264 - val_loss: 0.0048 - val_mae: 0.0635\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0012 - mae: 0.0269 - val_loss: 0.0046 - val_mae: 0.0628\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0010 - mae: 0.0257 - val_loss: 0.0044 - val_mae: 0.0623\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 9.4708e-04 - mae: 0.0253 - val_loss: 0.0044 - val_mae: 0.0618\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.9344e-04 - mae: 0.0258 - val_loss: 0.0043 - val_mae: 0.0615\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 9.3074e-04 - mae: 0.0250 - val_loss: 0.0041 - val_mae: 0.0613\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8.2790e-04 - mae: 0.0239 - val_loss: 0.0041 - val_mae: 0.0611\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8.5074e-04 - mae: 0.0234 - val_loss: 0.0040 - val_mae: 0.0610\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 8.1461e-04 - mae: 0.0229 - val_loss: 0.0040 - val_mae: 0.0608\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 7.1510e-04 - mae: 0.0222 - val_loss: 0.0041 - val_mae: 0.0607\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 7.1293e-04 - mae: 0.0217 - val_loss: 0.0041 - val_mae: 0.0606\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 6.9058e-04 - mae: 0.0212 - val_loss: 0.0040 - val_mae: 0.0606\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6.1107e-04 - mae: 0.0203 - val_loss: 0.0039 - val_mae: 0.0606\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 6.0378e-04 - mae: 0.0198 - val_loss: 0.0039 - val_mae: 0.0606\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 5.9253e-04 - mae: 0.0196 - val_loss: 0.0039 - val_mae: 0.0605\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 5.3439e-04 - mae: 0.0188 - val_loss: 0.0040 - val_mae: 0.0604\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604ms/step - loss: 0.3289 - mae: 0.5436 - val_loss: 0.2566 - val_mae: 0.3995\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0899 - mae: 0.2527 - val_loss: 0.1152 - val_mae: 0.3044\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0210 - mae: 0.1233 - val_loss: 0.0842 - val_mae: 0.2876\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0571 - mae: 0.1998 - val_loss: 0.0842 - val_mae: 0.2658\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0854 - mae: 0.2634 - val_loss: 0.0722 - val_mae: 0.2414\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0767 - mae: 0.2509 - val_loss: 0.0533 - val_mae: 0.2163\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0511 - mae: 0.1985 - val_loss: 0.0385 - val_mae: 0.1939\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0281 - mae: 0.1365 - val_loss: 0.0354 - val_mae: 0.1850\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0142 - mae: 0.0936 - val_loss: 0.0389 - val_mae: 0.1813\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0096 - mae: 0.0833 - val_loss: 0.0458 - val_mae: 0.1772\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0100 - mae: 0.0846 - val_loss: 0.0531 - val_mae: 0.1876\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0128 - mae: 0.0922 - val_loss: 0.0578 - val_mae: 0.1953\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0152 - mae: 0.0992 - val_loss: 0.0586 - val_mae: 0.1968\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0159 - mae: 0.1017 - val_loss: 0.0559 - val_mae: 0.1932\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0147 - mae: 0.0978 - val_loss: 0.0509 - val_mae: 0.1862\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0126 - mae: 0.0916 - val_loss: 0.0450 - val_mae: 0.1765\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0105 - mae: 0.0848 - val_loss: 0.0396 - val_mae: 0.1669\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0091 - mae: 0.0833 - val_loss: 0.0352 - val_mae: 0.1654\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0085 - mae: 0.0834 - val_loss: 0.0319 - val_mae: 0.1630\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0088 - mae: 0.0852 - val_loss: 0.0299 - val_mae: 0.1610\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0094 - mae: 0.0869 - val_loss: 0.0288 - val_mae: 0.1594\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0098 - mae: 0.0875 - val_loss: 0.0282 - val_mae: 0.1582\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0096 - mae: 0.0863 - val_loss: 0.0281 - val_mae: 0.1574\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0088 - mae: 0.0829 - val_loss: 0.0285 - val_mae: 0.1555\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0076 - mae: 0.0776 - val_loss: 0.0296 - val_mae: 0.1536\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0063 - mae: 0.0712 - val_loss: 0.0316 - val_mae: 0.1517\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0054 - mae: 0.0664 - val_loss: 0.0342 - val_mae: 0.1559\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0049 - mae: 0.0630 - val_loss: 0.0370 - val_mae: 0.1627\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0049 - mae: 0.0608 - val_loss: 0.0392 - val_mae: 0.1676\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0051 - mae: 0.0598 - val_loss: 0.0404 - val_mae: 0.1700\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0050 - mae: 0.0588 - val_loss: 0.0403 - val_mae: 0.1697\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0047 - mae: 0.0570 - val_loss: 0.0390 - val_mae: 0.1673\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0042 - mae: 0.0540 - val_loss: 0.0370 - val_mae: 0.1635\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0036 - mae: 0.0512 - val_loss: 0.0348 - val_mae: 0.1592\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0031 - mae: 0.0484 - val_loss: 0.0328 - val_mae: 0.1546\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0028 - mae: 0.0459 - val_loss: 0.0310 - val_mae: 0.1506\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0027 - mae: 0.0449 - val_loss: 0.0297 - val_mae: 0.1476\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0028 - mae: 0.0439 - val_loss: 0.0291 - val_mae: 0.1460\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0028 - mae: 0.0438 - val_loss: 0.0290 - val_mae: 0.1462\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0027 - mae: 0.0428 - val_loss: 0.0295 - val_mae: 0.1478\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0025 - mae: 0.0415 - val_loss: 0.0306 - val_mae: 0.1506\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0022 - mae: 0.0398 - val_loss: 0.0320 - val_mae: 0.1541\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0020 - mae: 0.0378 - val_loss: 0.0337 - val_mae: 0.1577\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0018 - mae: 0.0364 - val_loss: 0.0353 - val_mae: 0.1610\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0018 - mae: 0.0351 - val_loss: 0.0365 - val_mae: 0.1633\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0018 - mae: 0.0340 - val_loss: 0.0371 - val_mae: 0.1644\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0019 - mae: 0.0332 - val_loss: 0.0369 - val_mae: 0.1642\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 0.0361 - val_mae: 0.1629\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0016 - mae: 0.0316 - val_loss: 0.0348 - val_mae: 0.1607\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0015 - mae: 0.0307 - val_loss: 0.0332 - val_mae: 0.1579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step - loss: 0.0139 - mae: 0.0957 - val_loss: 0.0362 - val_mae: 0.1731\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0236 - mae: 0.1301 - val_loss: 0.0391 - val_mae: 0.1688\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0117 - mae: 0.0945 - val_loss: 0.0595 - val_mae: 0.2093\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0121 - mae: 0.0834 - val_loss: 0.0715 - val_mae: 0.2228\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0149 - mae: 0.0918 - val_loss: 0.0634 - val_mae: 0.2112\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0114 - mae: 0.0788 - val_loss: 0.0500 - val_mae: 0.1895\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0084 - mae: 0.0677 - val_loss: 0.0408 - val_mae: 0.1693\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0093 - mae: 0.0769 - val_loss: 0.0369 - val_mae: 0.1632\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0108 - mae: 0.0851 - val_loss: 0.0367 - val_mae: 0.1602\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0100 - mae: 0.0808 - val_loss: 0.0397 - val_mae: 0.1692\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0081 - mae: 0.0682 - val_loss: 0.0452 - val_mae: 0.1816\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0072 - mae: 0.0612 - val_loss: 0.0507 - val_mae: 0.1912\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0078 - mae: 0.0665 - val_loss: 0.0521 - val_mae: 0.1939\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0083 - mae: 0.0693 - val_loss: 0.0481 - val_mae: 0.1882\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0077 - mae: 0.0676 - val_loss: 0.0408 - val_mae: 0.1770\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0066 - mae: 0.0625 - val_loss: 0.0340 - val_mae: 0.1644\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0062 - mae: 0.0599 - val_loss: 0.0293 - val_mae: 0.1540\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0066 - mae: 0.0608 - val_loss: 0.0272 - val_mae: 0.1486\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0069 - mae: 0.0626 - val_loss: 0.0269 - val_mae: 0.1486\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0066 - mae: 0.0602 - val_loss: 0.0281 - val_mae: 0.1529\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0060 - mae: 0.0577 - val_loss: 0.0305 - val_mae: 0.1594\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0057 - mae: 0.0571 - val_loss: 0.0328 - val_mae: 0.1645\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0059 - mae: 0.0573 - val_loss: 0.0336 - val_mae: 0.1658\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0059 - mae: 0.0572 - val_loss: 0.0322 - val_mae: 0.1623\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0056 - mae: 0.0550 - val_loss: 0.0296 - val_mae: 0.1559\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0052 - mae: 0.0515 - val_loss: 0.0272 - val_mae: 0.1496\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0051 - mae: 0.0523 - val_loss: 0.0256 - val_mae: 0.1451\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0251 - val_mae: 0.1434\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0051 - mae: 0.0536 - val_loss: 0.0256 - val_mae: 0.1450\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0049 - mae: 0.0516 - val_loss: 0.0269 - val_mae: 0.1484\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0047 - mae: 0.0495 - val_loss: 0.0282 - val_mae: 0.1514\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0046 - mae: 0.0490 - val_loss: 0.0286 - val_mae: 0.1527\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0046 - mae: 0.0484 - val_loss: 0.0278 - val_mae: 0.1511\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0045 - mae: 0.0476 - val_loss: 0.0258 - val_mae: 0.1469\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0043 - mae: 0.0468 - val_loss: 0.0236 - val_mae: 0.1415\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0042 - mae: 0.0467 - val_loss: 0.0219 - val_mae: 0.1370\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0042 - mae: 0.0471 - val_loss: 0.0211 - val_mae: 0.1351\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0041 - mae: 0.0467 - val_loss: 0.0212 - val_mae: 0.1356\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0040 - mae: 0.0455 - val_loss: 0.0219 - val_mae: 0.1376\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0038 - mae: 0.0439 - val_loss: 0.0226 - val_mae: 0.1395\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0038 - mae: 0.0426 - val_loss: 0.0228 - val_mae: 0.1398\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0037 - mae: 0.0423 - val_loss: 0.0222 - val_mae: 0.1380\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0036 - mae: 0.0418 - val_loss: 0.0212 - val_mae: 0.1348\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0035 - mae: 0.0414 - val_loss: 0.0201 - val_mae: 0.1316\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0034 - mae: 0.0412 - val_loss: 0.0195 - val_mae: 0.1297\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0034 - mae: 0.0409 - val_loss: 0.0194 - val_mae: 0.1296\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0033 - mae: 0.0400 - val_loss: 0.0197 - val_mae: 0.1308\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0031 - mae: 0.0393 - val_loss: 0.0202 - val_mae: 0.1323\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0031 - mae: 0.0389 - val_loss: 0.0203 - val_mae: 0.1328\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0030 - mae: 0.0386 - val_loss: 0.0198 - val_mae: 0.1316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - loss: 5.7615 - mae: 2.3963 - val_loss: 3.8525 - val_mae: 1.9529\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 4.3010 - mae: 2.0691 - val_loss: 2.8211 - val_mae: 1.6696\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.1452 - mae: 1.7674 - val_loss: 1.9978 - val_mae: 1.4015\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.2499 - mae: 1.4929 - val_loss: 1.3611 - val_mae: 1.1530\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.5611 - mae: 1.2412 - val_loss: 0.8903 - val_mae: 0.9275\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.0593 - mae: 1.0196 - val_loss: 0.5692 - val_mae: 0.7357\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.6937 - mae: 0.8202 - val_loss: 0.3430 - val_mae: 0.5651\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.4304 - mae: 0.6384 - val_loss: 0.1835 - val_mae: 0.4039\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2490 - mae: 0.4751 - val_loss: 0.0902 - val_mae: 0.2654\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1297 - mae: 0.3281 - val_loss: 0.0382 - val_mae: 0.1423\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0590 - mae: 0.2045 - val_loss: 0.0197 - val_mae: 0.1065\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0254 - mae: 0.1246 - val_loss: 0.0190 - val_mae: 0.1309\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0155 - mae: 0.1089 - val_loss: 0.0313 - val_mae: 0.1678\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0217 - mae: 0.1217 - val_loss: 0.0471 - val_mae: 0.1911\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0368 - mae: 0.1589 - val_loss: 0.0618 - val_mae: 0.2224\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0542 - mae: 0.2042 - val_loss: 0.0705 - val_mae: 0.2442\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0689 - mae: 0.2386 - val_loss: 0.0761 - val_mae: 0.2575\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0797 - mae: 0.2608 - val_loss: 0.0781 - val_mae: 0.2633\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0859 - mae: 0.2726 - val_loss: 0.0752 - val_mae: 0.2600\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0870 - mae: 0.2748 - val_loss: 0.0672 - val_mae: 0.2460\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0832 - mae: 0.2685 - val_loss: 0.0564 - val_mae: 0.2249\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0751 - mae: 0.2542 - val_loss: 0.0442 - val_mae: 0.1980\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0642 - mae: 0.2324 - val_loss: 0.0319 - val_mae: 0.1665\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0518 - mae: 0.2048 - val_loss: 0.0212 - val_mae: 0.1330\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0396 - mae: 0.1732 - val_loss: 0.0127 - val_mae: 0.0984\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0280 - mae: 0.1412 - val_loss: 0.0065 - val_mae: 0.0753\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0187 - mae: 0.1135 - val_loss: 0.0033 - val_mae: 0.0563\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0120 - mae: 0.0901 - val_loss: 0.0031 - val_mae: 0.0379\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0080 - mae: 0.0729 - val_loss: 0.0056 - val_mae: 0.0519\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0068 - mae: 0.0688 - val_loss: 0.0100 - val_mae: 0.0838\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0082 - mae: 0.0736 - val_loss: 0.0153 - val_mae: 0.1102\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0113 - mae: 0.0870 - val_loss: 0.0203 - val_mae: 0.1307\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0149 - mae: 0.1041 - val_loss: 0.0242 - val_mae: 0.1447\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0182 - mae: 0.1186 - val_loss: 0.0263 - val_mae: 0.1517\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0202 - mae: 0.1263 - val_loss: 0.0266 - val_mae: 0.1526\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0205 - mae: 0.1276 - val_loss: 0.0253 - val_mae: 0.1483\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0192 - mae: 0.1233 - val_loss: 0.0227 - val_mae: 0.1395\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0170 - mae: 0.1145 - val_loss: 0.0194 - val_mae: 0.1273\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0143 - mae: 0.1024 - val_loss: 0.0158 - val_mae: 0.1126\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0117 - mae: 0.0884 - val_loss: 0.0123 - val_mae: 0.0964\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0094 - mae: 0.0776 - val_loss: 0.0093 - val_mae: 0.0797\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0079 - mae: 0.0706 - val_loss: 0.0068 - val_mae: 0.0629\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0070 - mae: 0.0694 - val_loss: 0.0050 - val_mae: 0.0471\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0066 - mae: 0.0679 - val_loss: 0.0037 - val_mae: 0.0372\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0068 - mae: 0.0689 - val_loss: 0.0030 - val_mae: 0.0367\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0073 - mae: 0.0700 - val_loss: 0.0026 - val_mae: 0.0376\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0079 - mae: 0.0718 - val_loss: 0.0025 - val_mae: 0.0409\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0084 - mae: 0.0742 - val_loss: 0.0024 - val_mae: 0.0431\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0089 - mae: 0.0767 - val_loss: 0.0024 - val_mae: 0.0441\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0091 - mae: 0.0780 - val_loss: 0.0024 - val_mae: 0.0441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step - loss: 0.1924 - mae: 0.4258 - val_loss: 0.0586 - val_mae: 0.1833\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0779 - mae: 0.2571 - val_loss: 0.0317 - val_mae: 0.1422\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0199 - mae: 0.1038 - val_loss: 0.0527 - val_mae: 0.2163\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0159 - mae: 0.1130 - val_loss: 0.0959 - val_mae: 0.2669\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0417 - mae: 0.1798 - val_loss: 0.1174 - val_mae: 0.3023\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0588 - mae: 0.2205 - val_loss: 0.1100 - val_mae: 0.2914\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0560 - mae: 0.2151 - val_loss: 0.0867 - val_mae: 0.2522\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0410 - mae: 0.1793 - val_loss: 0.0599 - val_mae: 0.2186\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0241 - mae: 0.1365 - val_loss: 0.0384 - val_mae: 0.1829\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0123 - mae: 0.0983 - val_loss: 0.0254 - val_mae: 0.1492\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0081 - mae: 0.0750 - val_loss: 0.0200 - val_mae: 0.1210\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0100 - mae: 0.0754 - val_loss: 0.0193 - val_mae: 0.0999\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0147 - mae: 0.0951 - val_loss: 0.0200 - val_mae: 0.1013\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0189 - mae: 0.1144 - val_loss: 0.0203 - val_mae: 0.1046\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0205 - mae: 0.1221 - val_loss: 0.0193 - val_mae: 0.1010\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0192 - mae: 0.1187 - val_loss: 0.0170 - val_mae: 0.0911\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0155 - mae: 0.1052 - val_loss: 0.0149 - val_mae: 0.0885\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0110 - mae: 0.0863 - val_loss: 0.0138 - val_mae: 0.0991\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0072 - mae: 0.0659 - val_loss: 0.0144 - val_mae: 0.1107\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0050 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.1222\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0048 - mae: 0.0574 - val_loss: 0.0200 - val_mae: 0.1320\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0060 - mae: 0.0638 - val_loss: 0.0232 - val_mae: 0.1390\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0078 - mae: 0.0743 - val_loss: 0.0254 - val_mae: 0.1430\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0091 - mae: 0.0800 - val_loss: 0.0260 - val_mae: 0.1436\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0094 - mae: 0.0811 - val_loss: 0.0249 - val_mae: 0.1410\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0086 - mae: 0.0777 - val_loss: 0.0225 - val_mae: 0.1358\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0070 - mae: 0.0704 - val_loss: 0.0195 - val_mae: 0.1286\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0053 - mae: 0.0602 - val_loss: 0.0166 - val_mae: 0.1202\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0040 - mae: 0.0511 - val_loss: 0.0142 - val_mae: 0.1117\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0034 - mae: 0.0480 - val_loss: 0.0126 - val_mae: 0.1039\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0035 - mae: 0.0477 - val_loss: 0.0118 - val_mae: 0.0975\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0041 - mae: 0.0517 - val_loss: 0.0114 - val_mae: 0.0932\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0047 - mae: 0.0554 - val_loss: 0.0112 - val_mae: 0.0913\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0049 - mae: 0.0569 - val_loss: 0.0112 - val_mae: 0.0917\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0047 - mae: 0.0557 - val_loss: 0.0114 - val_mae: 0.0945\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0042 - mae: 0.0527 - val_loss: 0.0119 - val_mae: 0.0989\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0035 - mae: 0.0478 - val_loss: 0.0128 - val_mae: 0.1045\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0029 - mae: 0.0448 - val_loss: 0.0141 - val_mae: 0.1104\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0026 - mae: 0.0427 - val_loss: 0.0156 - val_mae: 0.1159\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0027 - mae: 0.0428 - val_loss: 0.0171 - val_mae: 0.1203\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0029 - mae: 0.0449 - val_loss: 0.0180 - val_mae: 0.1230\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0032 - mae: 0.0474 - val_loss: 0.0183 - val_mae: 0.1237\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0033 - mae: 0.0482 - val_loss: 0.0179 - val_mae: 0.1224\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0032 - mae: 0.0472 - val_loss: 0.0169 - val_mae: 0.1196\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0029 - mae: 0.0447 - val_loss: 0.0157 - val_mae: 0.1155\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0026 - mae: 0.0430 - val_loss: 0.0144 - val_mae: 0.1110\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0023 - mae: 0.0413 - val_loss: 0.0133 - val_mae: 0.1066\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0023 - mae: 0.0410 - val_loss: 0.0125 - val_mae: 0.1028\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0024 - mae: 0.0416 - val_loss: 0.0119 - val_mae: 0.0999\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0025 - mae: 0.0420 - val_loss: 0.0116 - val_mae: 0.0982\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x17715b060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step - loss: 1.5571 - mae: 1.2433 - val_loss: 0.9639 - val_mae: 0.9682\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.9955 - mae: 0.9917 - val_loss: 0.5677 - val_mae: 0.7344\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.6199 - mae: 0.7788 - val_loss: 0.3500 - val_mae: 0.5683\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3731 - mae: 0.5998 - val_loss: 0.1901 - val_mae: 0.4060\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1908 - mae: 0.4227 - val_loss: 0.0868 - val_mae: 0.2504\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0699 - mae: 0.2453 - val_loss: 0.0297 - val_mae: 0.1213\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0153 - mae: 0.1076 - val_loss: 0.0153 - val_mae: 0.1008\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0082 - mae: 0.0691 - val_loss: 0.0264 - val_mae: 0.1375\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0292 - mae: 0.1540 - val_loss: 0.0462 - val_mae: 0.1769\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0592 - mae: 0.2334 - val_loss: 0.0620 - val_mae: 0.2167\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0821 - mae: 0.2788 - val_loss: 0.0660 - val_mae: 0.2268\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0898 - mae: 0.2926 - val_loss: 0.0591 - val_mae: 0.2120\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0819 - mae: 0.2788 - val_loss: 0.0460 - val_mae: 0.1793\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0648 - mae: 0.2463 - val_loss: 0.0313 - val_mae: 0.1328\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0447 - mae: 0.2012 - val_loss: 0.0197 - val_mae: 0.0979\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0269 - mae: 0.1499 - val_loss: 0.0132 - val_mae: 0.0893\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0139 - mae: 0.0972 - val_loss: 0.0125 - val_mae: 0.0980\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0068 - mae: 0.0666 - val_loss: 0.0167 - val_mae: 0.1198\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0053 - mae: 0.0636 - val_loss: 0.0245 - val_mae: 0.1399\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0076 - mae: 0.0750 - val_loss: 0.0326 - val_mae: 0.1541\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0120 - mae: 0.0904 - val_loss: 0.0399 - val_mae: 0.1668\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0169 - mae: 0.1081 - val_loss: 0.0451 - val_mae: 0.1815\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0207 - mae: 0.1236 - val_loss: 0.0476 - val_mae: 0.1883\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0225 - mae: 0.1310 - val_loss: 0.0471 - val_mae: 0.1874\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0224 - mae: 0.1307 - val_loss: 0.0441 - val_mae: 0.1796\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0205 - mae: 0.1235 - val_loss: 0.0391 - val_mae: 0.1658\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0173 - mae: 0.1105 - val_loss: 0.0332 - val_mae: 0.1526\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0136 - mae: 0.0962 - val_loss: 0.0271 - val_mae: 0.1413\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0100 - mae: 0.0834 - val_loss: 0.0215 - val_mae: 0.1291\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0072 - mae: 0.0747 - val_loss: 0.0170 - val_mae: 0.1162\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0055 - mae: 0.0677 - val_loss: 0.0137 - val_mae: 0.1033\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0051 - mae: 0.0623 - val_loss: 0.0118 - val_mae: 0.0918\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0058 - mae: 0.0594 - val_loss: 0.0109 - val_mae: 0.0875\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0070 - mae: 0.0648 - val_loss: 0.0108 - val_mae: 0.0872\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0084 - mae: 0.0716 - val_loss: 0.0108 - val_mae: 0.0870\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0094 - mae: 0.0765 - val_loss: 0.0108 - val_mae: 0.0868\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0098 - mae: 0.0784 - val_loss: 0.0107 - val_mae: 0.0866\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0096 - mae: 0.0775 - val_loss: 0.0106 - val_mae: 0.0865\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0089 - mae: 0.0743 - val_loss: 0.0105 - val_mae: 0.0861\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0078 - mae: 0.0692 - val_loss: 0.0107 - val_mae: 0.0858\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0067 - mae: 0.0635 - val_loss: 0.0113 - val_mae: 0.0903\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0057 - mae: 0.0591 - val_loss: 0.0123 - val_mae: 0.0973\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0051 - mae: 0.0588 - val_loss: 0.0136 - val_mae: 0.1042\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0048 - mae: 0.0604 - val_loss: 0.0151 - val_mae: 0.1104\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0049 - mae: 0.0633 - val_loss: 0.0166 - val_mae: 0.1156\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0052 - mae: 0.0661 - val_loss: 0.0178 - val_mae: 0.1192\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0056 - mae: 0.0682 - val_loss: 0.0186 - val_mae: 0.1213\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0059 - mae: 0.0695 - val_loss: 0.0188 - val_mae: 0.1219\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0060 - mae: 0.0700 - val_loss: 0.0186 - val_mae: 0.1211\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0060 - mae: 0.0696 - val_loss: 0.0179 - val_mae: 0.1193\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x17832fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720ms/step - loss: 1.2572 - mae: 1.0669 - val_loss: 0.3014 - val_mae: 0.5269\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.8897 - mae: 0.8780 - val_loss: 0.1547 - val_mae: 0.3589\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.5873 - mae: 0.6858 - val_loss: 0.0627 - val_mae: 0.2020\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3603 - mae: 0.5120 - val_loss: 0.0294 - val_mae: 0.1245\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2095 - mae: 0.4191 - val_loss: 0.0444 - val_mae: 0.1951\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1260 - mae: 0.3394 - val_loss: 0.0978 - val_mae: 0.2664\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0976 - mae: 0.2765 - val_loss: 0.1726 - val_mae: 0.3833\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1098 - mae: 0.2313 - val_loss: 0.2444 - val_mae: 0.4692\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.1424 - mae: 0.2649 - val_loss: 0.2949 - val_mae: 0.5222\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1744 - mae: 0.3248 - val_loss: 0.3152 - val_mae: 0.5429\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1924 - mae: 0.3555 - val_loss: 0.3084 - val_mae: 0.5380\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1926 - mae: 0.3620 - val_loss: 0.2801 - val_mae: 0.5122\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1772 - mae: 0.3474 - val_loss: 0.2377 - val_mae: 0.4700\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1523 - mae: 0.3184 - val_loss: 0.1912 - val_mae: 0.4185\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1233 - mae: 0.2784 - val_loss: 0.1465 - val_mae: 0.3622\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0958 - mae: 0.2320 - val_loss: 0.1061 - val_mae: 0.3023\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0729 - mae: 0.1853 - val_loss: 0.0716 - val_mae: 0.2406\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0565 - mae: 0.1658 - val_loss: 0.0457 - val_mae: 0.1809\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0470 - mae: 0.1673 - val_loss: 0.0285 - val_mae: 0.1409\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0437 - mae: 0.1795 - val_loss: 0.0182 - val_mae: 0.1151\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0453 - mae: 0.1960 - val_loss: 0.0131 - val_mae: 0.0925\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0496 - mae: 0.2088 - val_loss: 0.0114 - val_mae: 0.0846\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0543 - mae: 0.2169 - val_loss: 0.0113 - val_mae: 0.0854\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0572 - mae: 0.2196 - val_loss: 0.0116 - val_mae: 0.0912\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0575 - mae: 0.2174 - val_loss: 0.0117 - val_mae: 0.0931\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0551 - mae: 0.2111 - val_loss: 0.0115 - val_mae: 0.0922\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0500 - mae: 0.2005 - val_loss: 0.0110 - val_mae: 0.0887\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0437 - mae: 0.1872 - val_loss: 0.0102 - val_mae: 0.0837\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0373 - mae: 0.1723 - val_loss: 0.0100 - val_mae: 0.0820\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0317 - mae: 0.1562 - val_loss: 0.0106 - val_mae: 0.0803\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0274 - mae: 0.1405 - val_loss: 0.0120 - val_mae: 0.0795\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0247 - mae: 0.1285 - val_loss: 0.0139 - val_mae: 0.0808\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0235 - mae: 0.1210 - val_loss: 0.0158 - val_mae: 0.0849\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0233 - mae: 0.1184 - val_loss: 0.0172 - val_mae: 0.0863\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0235 - mae: 0.1183 - val_loss: 0.0178 - val_mae: 0.0887\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0237 - mae: 0.1186 - val_loss: 0.0175 - val_mae: 0.0870\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0235 - mae: 0.1193 - val_loss: 0.0164 - val_mae: 0.0803\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0225 - mae: 0.1172 - val_loss: 0.0147 - val_mae: 0.0768\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0209 - mae: 0.1126 - val_loss: 0.0128 - val_mae: 0.0735\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0189 - mae: 0.1067 - val_loss: 0.0112 - val_mae: 0.0722\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0170 - mae: 0.1010 - val_loss: 0.0101 - val_mae: 0.0745\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0153 - mae: 0.0958 - val_loss: 0.0096 - val_mae: 0.0830\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0142 - mae: 0.0920 - val_loss: 0.0099 - val_mae: 0.0909\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0137 - mae: 0.0898 - val_loss: 0.0106 - val_mae: 0.0980\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0136 - mae: 0.0892 - val_loss: 0.0116 - val_mae: 0.1035\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0136 - mae: 0.0893 - val_loss: 0.0126 - val_mae: 0.1074\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0135 - mae: 0.0894 - val_loss: 0.0134 - val_mae: 0.1101\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0132 - mae: 0.0886 - val_loss: 0.0138 - val_mae: 0.1113\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0126 - mae: 0.0868 - val_loss: 0.0139 - val_mae: 0.1110\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0119 - mae: 0.0841 - val_loss: 0.0137 - val_mae: 0.1094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - loss: 0.4214 - mae: 0.6316 - val_loss: 0.1454 - val_mae: 0.3640\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2464 - mae: 0.4775 - val_loss: 0.0673 - val_mae: 0.2296\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1210 - mae: 0.3243 - val_loss: 0.0235 - val_mae: 0.1236\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0472 - mae: 0.1895 - val_loss: 0.0146 - val_mae: 0.1034\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0136 - mae: 0.1059 - val_loss: 0.0379 - val_mae: 0.1605\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0221 - mae: 0.1155 - val_loss: 0.0711 - val_mae: 0.2441\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0496 - mae: 0.1990 - val_loss: 0.0915 - val_mae: 0.2827\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0648 - mae: 0.2338 - val_loss: 0.0884 - val_mae: 0.2777\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0603 - mae: 0.2238 - val_loss: 0.0698 - val_mae: 0.2420\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0424 - mae: 0.1797 - val_loss: 0.0442 - val_mae: 0.1823\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0239 - mae: 0.1220 - val_loss: 0.0263 - val_mae: 0.1400\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0130 - mae: 0.0820 - val_loss: 0.0172 - val_mae: 0.1187\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0091 - mae: 0.0758 - val_loss: 0.0120 - val_mae: 0.1003\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0099 - mae: 0.0877 - val_loss: 0.0099 - val_mae: 0.0866\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0125 - mae: 0.1006 - val_loss: 0.0092 - val_mae: 0.0776\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0150 - mae: 0.1077 - val_loss: 0.0088 - val_mae: 0.0738\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0154 - mae: 0.1084 - val_loss: 0.0087 - val_mae: 0.0754\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0140 - mae: 0.1037 - val_loss: 0.0090 - val_mae: 0.0814\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0112 - mae: 0.0934 - val_loss: 0.0106 - val_mae: 0.0912\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0086 - mae: 0.0804 - val_loss: 0.0131 - val_mae: 0.1007\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0073 - mae: 0.0700 - val_loss: 0.0165 - val_mae: 0.1096\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0074 - mae: 0.0622 - val_loss: 0.0201 - val_mae: 0.1162\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0086 - mae: 0.0661 - val_loss: 0.0226 - val_mae: 0.1249\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0098 - mae: 0.0740 - val_loss: 0.0230 - val_mae: 0.1276\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0101 - mae: 0.0774 - val_loss: 0.0214 - val_mae: 0.1219\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0094 - mae: 0.0734 - val_loss: 0.0183 - val_mae: 0.1093\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0081 - mae: 0.0646 - val_loss: 0.0147 - val_mae: 0.1000\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0068 - mae: 0.0583 - val_loss: 0.0115 - val_mae: 0.0900\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0060 - mae: 0.0560 - val_loss: 0.0091 - val_mae: 0.0809\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0058 - mae: 0.0597 - val_loss: 0.0075 - val_mae: 0.0733\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0062 - mae: 0.0629 - val_loss: 0.0066 - val_mae: 0.0677\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0063 - mae: 0.0633 - val_loss: 0.0064 - val_mae: 0.0655\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0062 - mae: 0.0619 - val_loss: 0.0068 - val_mae: 0.0679\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0058 - mae: 0.0586 - val_loss: 0.0077 - val_mae: 0.0723\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0053 - mae: 0.0531 - val_loss: 0.0088 - val_mae: 0.0770\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0052 - mae: 0.0502 - val_loss: 0.0098 - val_mae: 0.0803\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0053 - mae: 0.0520 - val_loss: 0.0101 - val_mae: 0.0810\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0054 - mae: 0.0521 - val_loss: 0.0096 - val_mae: 0.0788\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0051 - mae: 0.0503 - val_loss: 0.0085 - val_mae: 0.0743\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0048 - mae: 0.0472 - val_loss: 0.0073 - val_mae: 0.0686\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0045 - mae: 0.0449 - val_loss: 0.0065 - val_mae: 0.0630\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0044 - mae: 0.0436 - val_loss: 0.0061 - val_mae: 0.0589\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0045 - mae: 0.0439 - val_loss: 0.0059 - val_mae: 0.0567\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0045 - mae: 0.0431 - val_loss: 0.0060 - val_mae: 0.0566\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0043 - mae: 0.0409 - val_loss: 0.0062 - val_mae: 0.0581\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0041 - mae: 0.0395 - val_loss: 0.0065 - val_mae: 0.0605\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0040 - mae: 0.0399 - val_loss: 0.0068 - val_mae: 0.0626\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0040 - mae: 0.0419 - val_loss: 0.0070 - val_mae: 0.0634\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0041 - mae: 0.0435 - val_loss: 0.0069 - val_mae: 0.0626\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0041 - mae: 0.0435 - val_loss: 0.0066 - val_mae: 0.0602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - loss: 0.8395 - mae: 0.8800 - val_loss: 0.7913 - val_mae: 0.8863\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4679 - mae: 0.6403 - val_loss: 0.3996 - val_mae: 0.6252\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2137 - mae: 0.3997 - val_loss: 0.1600 - val_mae: 0.3863\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0750 - mae: 0.2344 - val_loss: 0.0397 - val_mae: 0.1661\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0534 - mae: 0.2080 - val_loss: 0.0138 - val_mae: 0.0957\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1062 - mae: 0.2620 - val_loss: 0.0288 - val_mae: 0.1424\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1586 - mae: 0.3407 - val_loss: 0.0413 - val_mae: 0.1641\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1739 - mae: 0.3686 - val_loss: 0.0398 - val_mae: 0.1603\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1542 - mae: 0.3470 - val_loss: 0.0300 - val_mae: 0.1404\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1174 - mae: 0.2958 - val_loss: 0.0196 - val_mae: 0.1132\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0780 - mae: 0.2301 - val_loss: 0.0143 - val_mae: 0.1032\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0466 - mae: 0.1735 - val_loss: 0.0168 - val_mae: 0.1119\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0274 - mae: 0.1279 - val_loss: 0.0272 - val_mae: 0.1425\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0203 - mae: 0.1228 - val_loss: 0.0434 - val_mae: 0.1710\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0224 - mae: 0.1325 - val_loss: 0.0614 - val_mae: 0.2167\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0295 - mae: 0.1473 - val_loss: 0.0757 - val_mae: 0.2473\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0372 - mae: 0.1590 - val_loss: 0.0836 - val_mae: 0.2626\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0424 - mae: 0.1677 - val_loss: 0.0845 - val_mae: 0.2641\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0434 - mae: 0.1694 - val_loss: 0.0790 - val_mae: 0.2533\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0403 - mae: 0.1619 - val_loss: 0.0688 - val_mae: 0.2320\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0339 - mae: 0.1479 - val_loss: 0.0560 - val_mae: 0.2025\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0261 - mae: 0.1298 - val_loss: 0.0427 - val_mae: 0.1738\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0189 - mae: 0.1110 - val_loss: 0.0311 - val_mae: 0.1545\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0136 - mae: 0.0958 - val_loss: 0.0224 - val_mae: 0.1348\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0110 - mae: 0.0829 - val_loss: 0.0170 - val_mae: 0.1162\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0112 - mae: 0.0819 - val_loss: 0.0148 - val_mae: 0.1011\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0132 - mae: 0.0977 - val_loss: 0.0146 - val_mae: 0.1007\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0158 - mae: 0.1098 - val_loss: 0.0153 - val_mae: 0.1009\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0176 - mae: 0.1182 - val_loss: 0.0159 - val_mae: 0.1020\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0178 - mae: 0.1196 - val_loss: 0.0160 - val_mae: 0.1032\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0164 - mae: 0.1146 - val_loss: 0.0158 - val_mae: 0.1048\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0139 - mae: 0.1040 - val_loss: 0.0157 - val_mae: 0.1066\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0111 - mae: 0.0905 - val_loss: 0.0162 - val_mae: 0.1084\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0088 - mae: 0.0783 - val_loss: 0.0173 - val_mae: 0.1126\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0076 - mae: 0.0709 - val_loss: 0.0190 - val_mae: 0.1224\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0074 - mae: 0.0673 - val_loss: 0.0209 - val_mae: 0.1304\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0080 - mae: 0.0677 - val_loss: 0.0224 - val_mae: 0.1362\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0088 - mae: 0.0710 - val_loss: 0.0234 - val_mae: 0.1396\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0094 - mae: 0.0724 - val_loss: 0.0237 - val_mae: 0.1405\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0096 - mae: 0.0722 - val_loss: 0.0232 - val_mae: 0.1389\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0091 - mae: 0.0701 - val_loss: 0.0220 - val_mae: 0.1351\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0082 - mae: 0.0659 - val_loss: 0.0204 - val_mae: 0.1295\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0072 - mae: 0.0610 - val_loss: 0.0190 - val_mae: 0.1229\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0062 - mae: 0.0581 - val_loss: 0.0178 - val_mae: 0.1159\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0056 - mae: 0.0581 - val_loss: 0.0173 - val_mae: 0.1094\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0055 - mae: 0.0597 - val_loss: 0.0171 - val_mae: 0.1079\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0056 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.1074\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0059 - mae: 0.0645 - val_loss: 0.0174 - val_mae: 0.1070\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0061 - mae: 0.0664 - val_loss: 0.0176 - val_mae: 0.1068\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0061 - mae: 0.0666 - val_loss: 0.0177 - val_mae: 0.1067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - loss: 0.2987 - mae: 0.5381 - val_loss: 0.1904 - val_mae: 0.4343\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1219 - mae: 0.3327 - val_loss: 0.0639 - val_mae: 0.2488\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0311 - mae: 0.1522 - val_loss: 0.0088 - val_mae: 0.0805\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0167 - mae: 0.1028 - val_loss: 0.0050 - val_mae: 0.0682\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0467 - mae: 0.1808 - val_loss: 0.0175 - val_mae: 0.1218\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0746 - mae: 0.2493 - val_loss: 0.0226 - val_mae: 0.1414\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0779 - mae: 0.2596 - val_loss: 0.0179 - val_mae: 0.1246\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0618 - mae: 0.2303 - val_loss: 0.0092 - val_mae: 0.0838\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0381 - mae: 0.1757 - val_loss: 0.0028 - val_mae: 0.0525\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0174 - mae: 0.1074 - val_loss: 0.0028 - val_mae: 0.0351\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0062 - mae: 0.0591 - val_loss: 0.0093 - val_mae: 0.0866\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0054 - mae: 0.0630 - val_loss: 0.0196 - val_mae: 0.1338\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0116 - mae: 0.0953 - val_loss: 0.0297 - val_mae: 0.1674\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0198 - mae: 0.1283 - val_loss: 0.0355 - val_mae: 0.1839\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0254 - mae: 0.1497 - val_loss: 0.0355 - val_mae: 0.1839\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0262 - mae: 0.1531 - val_loss: 0.0304 - val_mae: 0.1694\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0222 - mae: 0.1403 - val_loss: 0.0223 - val_mae: 0.1431\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0155 - mae: 0.1142 - val_loss: 0.0137 - val_mae: 0.1087\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0085 - mae: 0.0817 - val_loss: 0.0068 - val_mae: 0.0702\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0038 - mae: 0.0529 - val_loss: 0.0030 - val_mae: 0.0409\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0025 - mae: 0.0388 - val_loss: 0.0020 - val_mae: 0.0376\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0043 - mae: 0.0523 - val_loss: 0.0029 - val_mae: 0.0506\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0075 - mae: 0.0706 - val_loss: 0.0043 - val_mae: 0.0594\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0102 - mae: 0.0879 - val_loss: 0.0049 - val_mae: 0.0625\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0111 - mae: 0.0930 - val_loss: 0.0044 - val_mae: 0.0596\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0098 - mae: 0.0864 - val_loss: 0.0032 - val_mae: 0.0518\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0072 - mae: 0.0699 - val_loss: 0.0021 - val_mae: 0.0407\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0044 - mae: 0.0533 - val_loss: 0.0019 - val_mae: 0.0394\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0025 - mae: 0.0393 - val_loss: 0.0028 - val_mae: 0.0395\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0022 - mae: 0.0402 - val_loss: 0.0045 - val_mae: 0.0521\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0031 - mae: 0.0450 - val_loss: 0.0064 - val_mae: 0.0677\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0044 - mae: 0.0560 - val_loss: 0.0076 - val_mae: 0.0761\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0055 - mae: 0.0635 - val_loss: 0.0077 - val_mae: 0.0769\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0056 - mae: 0.0645 - val_loss: 0.0068 - val_mae: 0.0705\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0048 - mae: 0.0590 - val_loss: 0.0053 - val_mae: 0.0582\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0036 - mae: 0.0495 - val_loss: 0.0037 - val_mae: 0.0434\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0024 - mae: 0.0414 - val_loss: 0.0025 - val_mae: 0.0400\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0018 - mae: 0.0381 - val_loss: 0.0020 - val_mae: 0.0400\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0019 - mae: 0.0361 - val_loss: 0.0020 - val_mae: 0.0400\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0023 - val_mae: 0.0423\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0030 - mae: 0.0430 - val_loss: 0.0024 - val_mae: 0.0444\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0033 - mae: 0.0453 - val_loss: 0.0024 - val_mae: 0.0437\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0031 - mae: 0.0434 - val_loss: 0.0022 - val_mae: 0.0406\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0021 - val_mae: 0.0403\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 0.0022 - val_mae: 0.0404\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0016 - mae: 0.0342 - val_loss: 0.0026 - val_mae: 0.0405\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0016 - mae: 0.0359 - val_loss: 0.0031 - val_mae: 0.0406\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0018 - mae: 0.0381 - val_loss: 0.0035 - val_mae: 0.0432\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0021 - mae: 0.0401 - val_loss: 0.0037 - val_mae: 0.0446\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0022 - mae: 0.0408 - val_loss: 0.0036 - val_mae: 0.0439\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step - loss: 0.0358 - mae: 0.1574 - val_loss: 0.0264 - val_mae: 0.1394\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0554 - mae: 0.1980 - val_loss: 0.0309 - val_mae: 0.1605\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0276 - mae: 0.1372 - val_loss: 0.0714 - val_mae: 0.2279\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0201 - mae: 0.1179 - val_loss: 0.1100 - val_mae: 0.2961\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0326 - mae: 0.1471 - val_loss: 0.0988 - val_mae: 0.2766\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0279 - mae: 0.1333 - val_loss: 0.0626 - val_mae: 0.2160\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0163 - mae: 0.1060 - val_loss: 0.0362 - val_mae: 0.1738\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0155 - mae: 0.1096 - val_loss: 0.0273 - val_mae: 0.1475\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0211 - mae: 0.1210 - val_loss: 0.0275 - val_mae: 0.1474\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0202 - mae: 0.1180 - val_loss: 0.0340 - val_mae: 0.1679\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0139 - mae: 0.1034 - val_loss: 0.0488 - val_mae: 0.1955\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0109 - mae: 0.0893 - val_loss: 0.0662 - val_mae: 0.2185\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0133 - mae: 0.0953 - val_loss: 0.0740 - val_mae: 0.2269\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0149 - mae: 0.0989 - val_loss: 0.0679 - val_mae: 0.2193\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0121 - mae: 0.0911 - val_loss: 0.0545 - val_mae: 0.2014\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0085 - mae: 0.0786 - val_loss: 0.0429 - val_mae: 0.1820\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0079 - mae: 0.0784 - val_loss: 0.0374 - val_mae: 0.1696\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0095 - mae: 0.0828 - val_loss: 0.0374 - val_mae: 0.1687\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0095 - mae: 0.0808 - val_loss: 0.0423 - val_mae: 0.1787\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0074 - mae: 0.0731 - val_loss: 0.0516 - val_mae: 0.1947\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0056 - mae: 0.0686 - val_loss: 0.0629 - val_mae: 0.2104\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0058 - mae: 0.0678 - val_loss: 0.0711 - val_mae: 0.2200\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0068 - mae: 0.0689 - val_loss: 0.0720 - val_mae: 0.2205\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0065 - mae: 0.0672 - val_loss: 0.0661 - val_mae: 0.2127\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0051 - mae: 0.0634 - val_loss: 0.0577 - val_mae: 0.2007\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0042 - mae: 0.0617 - val_loss: 0.0512 - val_mae: 0.1898\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0047 - mae: 0.0604 - val_loss: 0.0488 - val_mae: 0.1850\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0053 - mae: 0.0605 - val_loss: 0.0508 - val_mae: 0.1882\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0048 - mae: 0.0590 - val_loss: 0.0566 - val_mae: 0.1974\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0039 - mae: 0.0570 - val_loss: 0.0642 - val_mae: 0.2082\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0037 - mae: 0.0559 - val_loss: 0.0700 - val_mae: 0.2156\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0042 - mae: 0.0547 - val_loss: 0.0712 - val_mae: 0.2167\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0043 - mae: 0.0535 - val_loss: 0.0675 - val_mae: 0.2117\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0037 - mae: 0.0522 - val_loss: 0.0616 - val_mae: 0.2032\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0033 - mae: 0.0509 - val_loss: 0.0567 - val_mae: 0.1954\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0036 - mae: 0.0521 - val_loss: 0.0548 - val_mae: 0.1920\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0038 - mae: 0.0534 - val_loss: 0.0562 - val_mae: 0.1942\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0036 - mae: 0.0515 - val_loss: 0.0602 - val_mae: 0.2003\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0647 - val_mae: 0.2067\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0033 - mae: 0.0473 - val_loss: 0.0672 - val_mae: 0.2100\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0035 - mae: 0.0475 - val_loss: 0.0664 - val_mae: 0.2087\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0033 - mae: 0.0467 - val_loss: 0.0630 - val_mae: 0.2039\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0591 - val_mae: 0.1981\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0569 - val_mae: 0.1945\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0031 - mae: 0.0480 - val_loss: 0.0570 - val_mae: 0.1946\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0593 - val_mae: 0.1981\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0623 - val_mae: 0.2027\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0028 - mae: 0.0450 - val_loss: 0.0645 - val_mae: 0.2057\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0029 - mae: 0.0448 - val_loss: 0.0645 - val_mae: 0.2057\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0028 - mae: 0.0446 - val_loss: 0.0625 - val_mae: 0.2028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - loss: 0.7006 - mae: 0.8219 - val_loss: 0.2559 - val_mae: 0.4913\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4874 - mae: 0.6815 - val_loss: 0.1630 - val_mae: 0.3867\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3289 - mae: 0.5557 - val_loss: 0.0958 - val_mae: 0.2871\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2112 - mae: 0.4384 - val_loss: 0.0500 - val_mae: 0.1932\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1258 - mae: 0.3272 - val_loss: 0.0220 - val_mae: 0.1086\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0682 - mae: 0.2245 - val_loss: 0.0109 - val_mae: 0.0877\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0336 - mae: 0.1483 - val_loss: 0.0118 - val_mae: 0.0908\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0172 - mae: 0.1041 - val_loss: 0.0214 - val_mae: 0.1191\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0158 - mae: 0.0956 - val_loss: 0.0366 - val_mae: 0.1750\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0240 - mae: 0.1342 - val_loss: 0.0515 - val_mae: 0.2145\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0360 - mae: 0.1727 - val_loss: 0.0614 - val_mae: 0.2367\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0457 - mae: 0.1985 - val_loss: 0.0648 - val_mae: 0.2440\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0496 - mae: 0.2080 - val_loss: 0.0620 - val_mae: 0.2383\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0478 - mae: 0.2047 - val_loss: 0.0542 - val_mae: 0.2213\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0414 - mae: 0.1899 - val_loss: 0.0436 - val_mae: 0.1958\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0327 - mae: 0.1664 - val_loss: 0.0325 - val_mae: 0.1650\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0239 - mae: 0.1373 - val_loss: 0.0225 - val_mae: 0.1309\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0168 - mae: 0.1089 - val_loss: 0.0145 - val_mae: 0.0962\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0124 - mae: 0.0854 - val_loss: 0.0092 - val_mae: 0.0639\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0110 - mae: 0.0759 - val_loss: 0.0064 - val_mae: 0.0632\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0120 - mae: 0.0792 - val_loss: 0.0054 - val_mae: 0.0636\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0144 - mae: 0.0882 - val_loss: 0.0055 - val_mae: 0.0639\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0172 - mae: 0.1004 - val_loss: 0.0060 - val_mae: 0.0698\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0194 - mae: 0.1086 - val_loss: 0.0064 - val_mae: 0.0733\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0203 - mae: 0.1125 - val_loss: 0.0065 - val_mae: 0.0738\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0199 - mae: 0.1111 - val_loss: 0.0062 - val_mae: 0.0717\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0184 - mae: 0.1052 - val_loss: 0.0057 - val_mae: 0.0673\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0162 - mae: 0.0957 - val_loss: 0.0054 - val_mae: 0.0619\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0138 - mae: 0.0849 - val_loss: 0.0056 - val_mae: 0.0614\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0117 - mae: 0.0746 - val_loss: 0.0064 - val_mae: 0.0611\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0104 - mae: 0.0663 - val_loss: 0.0077 - val_mae: 0.0608\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0098 - mae: 0.0680 - val_loss: 0.0095 - val_mae: 0.0647\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0101 - mae: 0.0721 - val_loss: 0.0113 - val_mae: 0.0742\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0108 - mae: 0.0771 - val_loss: 0.0130 - val_mae: 0.0841\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0117 - mae: 0.0836 - val_loss: 0.0140 - val_mae: 0.0900\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0124 - mae: 0.0888 - val_loss: 0.0144 - val_mae: 0.0917\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0127 - mae: 0.0907 - val_loss: 0.0140 - val_mae: 0.0895\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0125 - mae: 0.0893 - val_loss: 0.0130 - val_mae: 0.0838\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0119 - mae: 0.0851 - val_loss: 0.0116 - val_mae: 0.0753\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0110 - mae: 0.0788 - val_loss: 0.0101 - val_mae: 0.0694\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0103 - mae: 0.0734 - val_loss: 0.0087 - val_mae: 0.0634\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0097 - mae: 0.0692 - val_loss: 0.0076 - val_mae: 0.0588\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0094 - mae: 0.0657 - val_loss: 0.0067 - val_mae: 0.0587\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0094 - mae: 0.0640 - val_loss: 0.0062 - val_mae: 0.0587\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0097 - mae: 0.0640 - val_loss: 0.0059 - val_mae: 0.0586\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0099 - mae: 0.0640 - val_loss: 0.0058 - val_mae: 0.0585\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0102 - mae: 0.0647 - val_loss: 0.0057 - val_mae: 0.0584\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0102 - mae: 0.0651 - val_loss: 0.0057 - val_mae: 0.0582\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0102 - mae: 0.0646 - val_loss: 0.0058 - val_mae: 0.0580\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0099 - mae: 0.0635 - val_loss: 0.0059 - val_mae: 0.0579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - loss: 0.8548 - mae: 0.9025 - val_loss: 0.2783 - val_mae: 0.4946\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.6342 - mae: 0.7709 - val_loss: 0.1679 - val_mae: 0.3684\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.4445 - mae: 0.6366 - val_loss: 0.0872 - val_mae: 0.2381\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2874 - mae: 0.5000 - val_loss: 0.0405 - val_mae: 0.1140\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1672 - mae: 0.3621 - val_loss: 0.0286 - val_mae: 0.1560\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0852 - mae: 0.2543 - val_loss: 0.0487 - val_mae: 0.2150\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0412 - mae: 0.1911 - val_loss: 0.0955 - val_mae: 0.2701\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0326 - mae: 0.1487 - val_loss: 0.1554 - val_mae: 0.3613\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0494 - mae: 0.1626 - val_loss: 0.2109 - val_mae: 0.4316\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0773 - mae: 0.2233 - val_loss: 0.2512 - val_mae: 0.4760\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1016 - mae: 0.2753 - val_loss: 0.2710 - val_mae: 0.4964\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1153 - mae: 0.3005 - val_loss: 0.2712 - val_mae: 0.4964\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1158 - mae: 0.3020 - val_loss: 0.2552 - val_mae: 0.4795\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1053 - mae: 0.2842 - val_loss: 0.2263 - val_mae: 0.4481\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0878 - mae: 0.2515 - val_loss: 0.1912 - val_mae: 0.4067\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0680 - mae: 0.2083 - val_loss: 0.1556 - val_mae: 0.3598\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0498 - mae: 0.1683 - val_loss: 0.1229 - val_mae: 0.3107\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0359 - mae: 0.1389 - val_loss: 0.0949 - val_mae: 0.2711\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0272 - mae: 0.1274 - val_loss: 0.0723 - val_mae: 0.2469\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0237 - mae: 0.1355 - val_loss: 0.0555 - val_mae: 0.2247\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0244 - mae: 0.1461 - val_loss: 0.0439 - val_mae: 0.2056\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0276 - mae: 0.1553 - val_loss: 0.0366 - val_mae: 0.1905\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0317 - mae: 0.1659 - val_loss: 0.0321 - val_mae: 0.1788\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0355 - mae: 0.1730 - val_loss: 0.0295 - val_mae: 0.1707\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0378 - mae: 0.1764 - val_loss: 0.0280 - val_mae: 0.1660\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0383 - mae: 0.1764 - val_loss: 0.0275 - val_mae: 0.1645\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0369 - mae: 0.1730 - val_loss: 0.0278 - val_mae: 0.1659\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0339 - mae: 0.1668 - val_loss: 0.0288 - val_mae: 0.1696\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0300 - mae: 0.1581 - val_loss: 0.0308 - val_mae: 0.1752\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0258 - mae: 0.1475 - val_loss: 0.0339 - val_mae: 0.1821\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0220 - mae: 0.1386 - val_loss: 0.0379 - val_mae: 0.1898\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0189 - mae: 0.1299 - val_loss: 0.0428 - val_mae: 0.1977\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0168 - mae: 0.1209 - val_loss: 0.0481 - val_mae: 0.2053\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0159 - mae: 0.1123 - val_loss: 0.0535 - val_mae: 0.2121\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0158 - mae: 0.1070 - val_loss: 0.0585 - val_mae: 0.2176\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0164 - mae: 0.1026 - val_loss: 0.0624 - val_mae: 0.2215\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0172 - mae: 0.1011 - val_loss: 0.0649 - val_mae: 0.2235\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0180 - mae: 0.1005 - val_loss: 0.0659 - val_mae: 0.2239\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0183 - mae: 0.1004 - val_loss: 0.0653 - val_mae: 0.2225\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0182 - mae: 0.0996 - val_loss: 0.0632 - val_mae: 0.2194\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0175 - mae: 0.0982 - val_loss: 0.0598 - val_mae: 0.2149\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0164 - mae: 0.0963 - val_loss: 0.0555 - val_mae: 0.2091\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0150 - mae: 0.0942 - val_loss: 0.0507 - val_mae: 0.2025\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0137 - mae: 0.0932 - val_loss: 0.0459 - val_mae: 0.1953\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0125 - mae: 0.0922 - val_loss: 0.0412 - val_mae: 0.1880\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0117 - mae: 0.0929 - val_loss: 0.0369 - val_mae: 0.1806\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0111 - mae: 0.0937 - val_loss: 0.0333 - val_mae: 0.1739\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0110 - mae: 0.0949 - val_loss: 0.0304 - val_mae: 0.1680\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0110 - mae: 0.0969 - val_loss: 0.0282 - val_mae: 0.1629\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0111 - mae: 0.0983 - val_loss: 0.0265 - val_mae: 0.1588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - loss: 0.2027 - mae: 0.4323 - val_loss: 0.0791 - val_mae: 0.2511\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1010 - mae: 0.2948 - val_loss: 0.0375 - val_mae: 0.1635\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0433 - mae: 0.1698 - val_loss: 0.0183 - val_mae: 0.1126\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0179 - mae: 0.0981 - val_loss: 0.0198 - val_mae: 0.1165\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0184 - mae: 0.1211 - val_loss: 0.0304 - val_mae: 0.1482\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0313 - mae: 0.1578 - val_loss: 0.0411 - val_mae: 0.1683\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0419 - mae: 0.1838 - val_loss: 0.0455 - val_mae: 0.1800\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0446 - mae: 0.1885 - val_loss: 0.0436 - val_mae: 0.1769\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0404 - mae: 0.1794 - val_loss: 0.0376 - val_mae: 0.1657\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0322 - mae: 0.1602 - val_loss: 0.0286 - val_mae: 0.1502\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0232 - mae: 0.1343 - val_loss: 0.0197 - val_mae: 0.1296\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0160 - mae: 0.1117 - val_loss: 0.0128 - val_mae: 0.1067\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0118 - mae: 0.0965 - val_loss: 0.0096 - val_mae: 0.0857\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0107 - mae: 0.0839 - val_loss: 0.0097 - val_mae: 0.0718\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0123 - mae: 0.0795 - val_loss: 0.0119 - val_mae: 0.0825\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0155 - mae: 0.0927 - val_loss: 0.0139 - val_mae: 0.0916\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0182 - mae: 0.1069 - val_loss: 0.0141 - val_mae: 0.0926\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0186 - mae: 0.1092 - val_loss: 0.0128 - val_mae: 0.0880\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0171 - mae: 0.1023 - val_loss: 0.0107 - val_mae: 0.0793\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0145 - mae: 0.0882 - val_loss: 0.0090 - val_mae: 0.0695\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0118 - mae: 0.0780 - val_loss: 0.0084 - val_mae: 0.0722\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0099 - mae: 0.0768 - val_loss: 0.0089 - val_mae: 0.0826\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0091 - mae: 0.0767 - val_loss: 0.0105 - val_mae: 0.0927\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0089 - mae: 0.0777 - val_loss: 0.0120 - val_mae: 0.0999\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0092 - mae: 0.0813 - val_loss: 0.0131 - val_mae: 0.1037\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0095 - mae: 0.0852 - val_loss: 0.0135 - val_mae: 0.1048\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0097 - mae: 0.0866 - val_loss: 0.0130 - val_mae: 0.1025\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0095 - mae: 0.0854 - val_loss: 0.0116 - val_mae: 0.0963\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0090 - mae: 0.0819 - val_loss: 0.0098 - val_mae: 0.0879\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0085 - mae: 0.0786 - val_loss: 0.0080 - val_mae: 0.0780\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0079 - mae: 0.0754 - val_loss: 0.0064 - val_mae: 0.0676\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0073 - mae: 0.0712 - val_loss: 0.0054 - val_mae: 0.0583\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0069 - mae: 0.0667 - val_loss: 0.0049 - val_mae: 0.0512\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0067 - mae: 0.0637 - val_loss: 0.0047 - val_mae: 0.0537\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0066 - mae: 0.0628 - val_loss: 0.0046 - val_mae: 0.0563\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0065 - mae: 0.0622 - val_loss: 0.0045 - val_mae: 0.0570\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0062 - mae: 0.0621 - val_loss: 0.0043 - val_mae: 0.0560\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0059 - mae: 0.0606 - val_loss: 0.0040 - val_mae: 0.0531\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0054 - mae: 0.0578 - val_loss: 0.0038 - val_mae: 0.0490\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0049 - mae: 0.0546 - val_loss: 0.0038 - val_mae: 0.0446\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0045 - mae: 0.0524 - val_loss: 0.0040 - val_mae: 0.0464\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0043 - mae: 0.0516 - val_loss: 0.0044 - val_mae: 0.0511\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0042 - mae: 0.0523 - val_loss: 0.0049 - val_mae: 0.0555\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0041 - mae: 0.0531 - val_loss: 0.0055 - val_mae: 0.0588\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0040 - mae: 0.0532 - val_loss: 0.0059 - val_mae: 0.0606\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0039 - mae: 0.0529 - val_loss: 0.0061 - val_mae: 0.0609\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0038 - mae: 0.0520 - val_loss: 0.0060 - val_mae: 0.0601\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0036 - mae: 0.0507 - val_loss: 0.0056 - val_mae: 0.0578\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0035 - mae: 0.0490 - val_loss: 0.0051 - val_mae: 0.0547\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0032 - mae: 0.0470 - val_loss: 0.0044 - val_mae: 0.0508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - loss: 0.6121 - mae: 0.7403 - val_loss: 0.1061 - val_mae: 0.3147\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3321 - mae: 0.5225 - val_loss: 0.0261 - val_mae: 0.1350\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1509 - mae: 0.3420 - val_loss: 0.0108 - val_mae: 0.0944\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0686 - mae: 0.2316 - val_loss: 0.0416 - val_mae: 0.1741\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0536 - mae: 0.1716 - val_loss: 0.0859 - val_mae: 0.2719\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0718 - mae: 0.1959 - val_loss: 0.1165 - val_mae: 0.3236\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0936 - mae: 0.2340 - val_loss: 0.1225 - val_mae: 0.3332\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1006 - mae: 0.2513 - val_loss: 0.1084 - val_mae: 0.3127\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0927 - mae: 0.2413 - val_loss: 0.0836 - val_mae: 0.2724\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0757 - mae: 0.2116 - val_loss: 0.0558 - val_mae: 0.2184\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0567 - mae: 0.1729 - val_loss: 0.0318 - val_mae: 0.1576\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0408 - mae: 0.1431 - val_loss: 0.0156 - val_mae: 0.0972\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0299 - mae: 0.1195 - val_loss: 0.0077 - val_mae: 0.0763\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0247 - mae: 0.1169 - val_loss: 0.0060 - val_mae: 0.0750\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0241 - mae: 0.1316 - val_loss: 0.0077 - val_mae: 0.0726\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0264 - mae: 0.1478 - val_loss: 0.0107 - val_mae: 0.0870\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0290 - mae: 0.1576 - val_loss: 0.0132 - val_mae: 0.0966\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0303 - mae: 0.1612 - val_loss: 0.0145 - val_mae: 0.1016\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0297 - mae: 0.1588 - val_loss: 0.0138 - val_mae: 0.1013\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0271 - mae: 0.1510 - val_loss: 0.0117 - val_mae: 0.0959\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0232 - mae: 0.1389 - val_loss: 0.0090 - val_mae: 0.0866\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0191 - mae: 0.1234 - val_loss: 0.0066 - val_mae: 0.0754\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0157 - mae: 0.1079 - val_loss: 0.0050 - val_mae: 0.0634\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0138 - mae: 0.0983 - val_loss: 0.0045 - val_mae: 0.0577\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0132 - mae: 0.0902 - val_loss: 0.0048 - val_mae: 0.0579\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0137 - mae: 0.0846 - val_loss: 0.0053 - val_mae: 0.0573\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0146 - mae: 0.0829 - val_loss: 0.0055 - val_mae: 0.0562\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0152 - mae: 0.0853 - val_loss: 0.0053 - val_mae: 0.0550\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0150 - mae: 0.0861 - val_loss: 0.0047 - val_mae: 0.0533\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0140 - mae: 0.0832 - val_loss: 0.0039 - val_mae: 0.0514\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0124 - mae: 0.0770 - val_loss: 0.0033 - val_mae: 0.0491\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0107 - mae: 0.0721 - val_loss: 0.0031 - val_mae: 0.0464\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0093 - mae: 0.0706 - val_loss: 0.0036 - val_mae: 0.0529\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0084 - mae: 0.0713 - val_loss: 0.0045 - val_mae: 0.0585\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0081 - mae: 0.0741 - val_loss: 0.0057 - val_mae: 0.0630\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0082 - mae: 0.0762 - val_loss: 0.0068 - val_mae: 0.0661\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0084 - mae: 0.0771 - val_loss: 0.0074 - val_mae: 0.0708\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0085 - mae: 0.0775 - val_loss: 0.0076 - val_mae: 0.0724\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0082 - mae: 0.0763 - val_loss: 0.0072 - val_mae: 0.0703\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0076 - mae: 0.0733 - val_loss: 0.0064 - val_mae: 0.0647\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0068 - mae: 0.0686 - val_loss: 0.0053 - val_mae: 0.0557\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0061 - mae: 0.0629 - val_loss: 0.0043 - val_mae: 0.0495\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0055 - mae: 0.0566 - val_loss: 0.0034 - val_mae: 0.0439\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0052 - mae: 0.0522 - val_loss: 0.0029 - val_mae: 0.0390\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0053 - mae: 0.0520 - val_loss: 0.0026 - val_mae: 0.0354\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0054 - mae: 0.0532 - val_loss: 0.0025 - val_mae: 0.0334\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0055 - mae: 0.0536 - val_loss: 0.0025 - val_mae: 0.0329\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0054 - mae: 0.0530 - val_loss: 0.0026 - val_mae: 0.0338\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0052 - mae: 0.0522 - val_loss: 0.0029 - val_mae: 0.0361\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0049 - mae: 0.0513 - val_loss: 0.0035 - val_mae: 0.0394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780ms/step - loss: 0.5286 - mae: 0.7133 - val_loss: 0.1919 - val_mae: 0.4220\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.2855 - mae: 0.5195 - val_loss: 0.0972 - val_mae: 0.2876\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1561 - mae: 0.3769 - val_loss: 0.0501 - val_mae: 0.1883\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0789 - mae: 0.2601 - val_loss: 0.0241 - val_mae: 0.0979\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0355 - mae: 0.1602 - val_loss: 0.0145 - val_mae: 0.0965\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0136 - mae: 0.0961 - val_loss: 0.0183 - val_mae: 0.1345\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0096 - mae: 0.0829 - val_loss: 0.0310 - val_mae: 0.1654\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0180 - mae: 0.1139 - val_loss: 0.0461 - val_mae: 0.1883\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0313 - mae: 0.1544 - val_loss: 0.0581 - val_mae: 0.2132\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0428 - mae: 0.1870 - val_loss: 0.0640 - val_mae: 0.2274\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0490 - mae: 0.2033 - val_loss: 0.0637 - val_mae: 0.2274\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0492 - mae: 0.2041 - val_loss: 0.0586 - val_mae: 0.2161\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0447 - mae: 0.1925 - val_loss: 0.0501 - val_mae: 0.1956\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0369 - mae: 0.1710 - val_loss: 0.0404 - val_mae: 0.1769\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0280 - mae: 0.1445 - val_loss: 0.0310 - val_mae: 0.1621\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0198 - mae: 0.1206 - val_loss: 0.0233 - val_mae: 0.1467\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0133 - mae: 0.0959 - val_loss: 0.0177 - val_mae: 0.1316\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0095 - mae: 0.0814 - val_loss: 0.0144 - val_mae: 0.1175\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0082 - mae: 0.0796 - val_loss: 0.0130 - val_mae: 0.1047\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0090 - mae: 0.0803 - val_loss: 0.0130 - val_mae: 0.0939\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0111 - mae: 0.0836 - val_loss: 0.0137 - val_mae: 0.0852\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0136 - mae: 0.0951 - val_loss: 0.0145 - val_mae: 0.0786\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0157 - mae: 0.1029 - val_loss: 0.0151 - val_mae: 0.0744\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0169 - mae: 0.1069 - val_loss: 0.0151 - val_mae: 0.0739\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0170 - mae: 0.1072 - val_loss: 0.0146 - val_mae: 0.0733\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0161 - mae: 0.1043 - val_loss: 0.0138 - val_mae: 0.0743\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0144 - mae: 0.0985 - val_loss: 0.0128 - val_mae: 0.0776\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0124 - mae: 0.0906 - val_loss: 0.0119 - val_mae: 0.0820\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0104 - mae: 0.0813 - val_loss: 0.0113 - val_mae: 0.0870\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0088 - mae: 0.0765 - val_loss: 0.0110 - val_mae: 0.0922\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0077 - mae: 0.0751 - val_loss: 0.0112 - val_mae: 0.0972\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0072 - mae: 0.0738 - val_loss: 0.0117 - val_mae: 0.1019\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0072 - mae: 0.0728 - val_loss: 0.0123 - val_mae: 0.1058\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0076 - mae: 0.0739 - val_loss: 0.0130 - val_mae: 0.1086\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0081 - mae: 0.0747 - val_loss: 0.0135 - val_mae: 0.1103\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0086 - mae: 0.0756 - val_loss: 0.0137 - val_mae: 0.1108\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0089 - mae: 0.0763 - val_loss: 0.0136 - val_mae: 0.1099\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0088 - mae: 0.0758 - val_loss: 0.0133 - val_mae: 0.1081\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0085 - mae: 0.0743 - val_loss: 0.0127 - val_mae: 0.1054\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0080 - mae: 0.0722 - val_loss: 0.0121 - val_mae: 0.1019\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0074 - mae: 0.0694 - val_loss: 0.0114 - val_mae: 0.0980\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0068 - mae: 0.0673 - val_loss: 0.0108 - val_mae: 0.0937\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0063 - mae: 0.0665 - val_loss: 0.0104 - val_mae: 0.0895\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0060 - mae: 0.0659 - val_loss: 0.0100 - val_mae: 0.0852\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0059 - mae: 0.0653 - val_loss: 0.0098 - val_mae: 0.0811\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0059 - mae: 0.0657 - val_loss: 0.0096 - val_mae: 0.0775\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0060 - mae: 0.0664 - val_loss: 0.0095 - val_mae: 0.0744\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0061 - mae: 0.0675 - val_loss: 0.0093 - val_mae: 0.0718\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0061 - mae: 0.0680 - val_loss: 0.0093 - val_mae: 0.0703\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0061 - mae: 0.0680 - val_loss: 0.0093 - val_mae: 0.0697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570ms/step - loss: 1.2157 - mae: 1.0942 - val_loss: 0.5558 - val_mae: 0.7351\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.7104 - mae: 0.8332 - val_loss: 0.2731 - val_mae: 0.5122\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3500 - mae: 0.5802 - val_loss: 0.0973 - val_mae: 0.2985\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1236 - mae: 0.3331 - val_loss: 0.0142 - val_mae: 0.0877\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0238 - mae: 0.1303 - val_loss: 0.0176 - val_mae: 0.1200\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0320 - mae: 0.1418 - val_loss: 0.0715 - val_mae: 0.2578\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1020 - mae: 0.2894 - val_loss: 0.1234 - val_mae: 0.3448\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1679 - mae: 0.3867 - val_loss: 0.1442 - val_mae: 0.3739\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1937 - mae: 0.4192 - val_loss: 0.1349 - val_mae: 0.3616\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1806 - mae: 0.4052 - val_loss: 0.1056 - val_mae: 0.3187\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1436 - mae: 0.3594 - val_loss: 0.0693 - val_mae: 0.2555\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1003 - mae: 0.2954 - val_loss: 0.0388 - val_mae: 0.1855\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0621 - mae: 0.2228 - val_loss: 0.0174 - val_mae: 0.1149\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0325 - mae: 0.1486 - val_loss: 0.0060 - val_mae: 0.0774\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0151 - mae: 0.0992 - val_loss: 0.0055 - val_mae: 0.0469\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0104 - mae: 0.0814 - val_loss: 0.0121 - val_mae: 0.0828\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0161 - mae: 0.1113 - val_loss: 0.0221 - val_mae: 0.1287\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0273 - mae: 0.1452 - val_loss: 0.0316 - val_mae: 0.1602\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0383 - mae: 0.1720 - val_loss: 0.0375 - val_mae: 0.1767\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0453 - mae: 0.1892 - val_loss: 0.0392 - val_mae: 0.1811\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0470 - mae: 0.1941 - val_loss: 0.0369 - val_mae: 0.1744\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0441 - mae: 0.1869 - val_loss: 0.0315 - val_mae: 0.1578\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0381 - mae: 0.1709 - val_loss: 0.0247 - val_mae: 0.1360\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0304 - mae: 0.1521 - val_loss: 0.0178 - val_mae: 0.1093\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0224 - mae: 0.1302 - val_loss: 0.0117 - val_mae: 0.0791\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0155 - mae: 0.1095 - val_loss: 0.0073 - val_mae: 0.0571\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0110 - mae: 0.0891 - val_loss: 0.0050 - val_mae: 0.0542\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0092 - mae: 0.0764 - val_loss: 0.0046 - val_mae: 0.0615\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0099 - mae: 0.0790 - val_loss: 0.0056 - val_mae: 0.0728\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0122 - mae: 0.0871 - val_loss: 0.0072 - val_mae: 0.0817\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0152 - mae: 0.0977 - val_loss: 0.0087 - val_mae: 0.0877\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0176 - mae: 0.1058 - val_loss: 0.0096 - val_mae: 0.0908\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0188 - mae: 0.1099 - val_loss: 0.0096 - val_mae: 0.0910\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0185 - mae: 0.1091 - val_loss: 0.0088 - val_mae: 0.0886\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0169 - mae: 0.1041 - val_loss: 0.0076 - val_mae: 0.0839\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0145 - mae: 0.0962 - val_loss: 0.0064 - val_mae: 0.0776\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0120 - mae: 0.0868 - val_loss: 0.0055 - val_mae: 0.0704\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0099 - mae: 0.0783 - val_loss: 0.0052 - val_mae: 0.0629\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0087 - mae: 0.0732 - val_loss: 0.0055 - val_mae: 0.0599\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0083 - mae: 0.0714 - val_loss: 0.0063 - val_mae: 0.0620\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0087 - mae: 0.0733 - val_loss: 0.0073 - val_mae: 0.0638\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0094 - mae: 0.0805 - val_loss: 0.0082 - val_mae: 0.0653\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0103 - mae: 0.0862 - val_loss: 0.0089 - val_mae: 0.0663\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0109 - mae: 0.0896 - val_loss: 0.0092 - val_mae: 0.0669\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0111 - mae: 0.0905 - val_loss: 0.0090 - val_mae: 0.0670\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0108 - mae: 0.0890 - val_loss: 0.0084 - val_mae: 0.0667\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0101 - mae: 0.0853 - val_loss: 0.0077 - val_mae: 0.0661\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0093 - mae: 0.0799 - val_loss: 0.0070 - val_mae: 0.0653\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0085 - mae: 0.0735 - val_loss: 0.0064 - val_mae: 0.0644\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0079 - mae: 0.0691 - val_loss: 0.0060 - val_mae: 0.0634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - loss: 1.4335 - mae: 1.1791 - val_loss: 0.5603 - val_mae: 0.7468\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.8007 - mae: 0.8768 - val_loss: 0.2556 - val_mae: 0.5044\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3874 - mae: 0.6046 - val_loss: 0.0868 - val_mae: 0.2932\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1413 - mae: 0.3499 - val_loss: 0.0113 - val_mae: 0.0885\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0272 - mae: 0.1220 - val_loss: 0.0188 - val_mae: 0.1053\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0326 - mae: 0.1513 - val_loss: 0.0737 - val_mae: 0.2512\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1001 - mae: 0.2909 - val_loss: 0.1199 - val_mae: 0.3292\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1548 - mae: 0.3734 - val_loss: 0.1310 - val_mae: 0.3456\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1668 - mae: 0.3895 - val_loss: 0.1122 - val_mae: 0.3187\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1422 - mae: 0.3572 - val_loss: 0.0783 - val_mae: 0.2622\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0997 - mae: 0.2927 - val_loss: 0.0438 - val_mae: 0.1898\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0572 - mae: 0.2091 - val_loss: 0.0180 - val_mae: 0.1133\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0278 - mae: 0.1442 - val_loss: 0.0043 - val_mae: 0.0511\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0144 - mae: 0.1126 - val_loss: 0.0012 - val_mae: 0.0297\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0127 - mae: 0.0938 - val_loss: 0.0052 - val_mae: 0.0585\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0170 - mae: 0.0961 - val_loss: 0.0112 - val_mae: 0.0904\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0243 - mae: 0.1165 - val_loss: 0.0162 - val_mae: 0.1122\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0306 - mae: 0.1337 - val_loss: 0.0200 - val_mae: 0.1255\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0345 - mae: 0.1456 - val_loss: 0.0208 - val_mae: 0.1284\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0354 - mae: 0.1491 - val_loss: 0.0194 - val_mae: 0.1235\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0336 - mae: 0.1446 - val_loss: 0.0163 - val_mae: 0.1106\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0298 - mae: 0.1335 - val_loss: 0.0122 - val_mae: 0.0916\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0247 - mae: 0.1182 - val_loss: 0.0082 - val_mae: 0.0680\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0195 - mae: 0.1043 - val_loss: 0.0051 - val_mae: 0.0416\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0150 - mae: 0.0923 - val_loss: 0.0033 - val_mae: 0.0403\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0119 - mae: 0.0864 - val_loss: 0.0029 - val_mae: 0.0506\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0105 - mae: 0.0871 - val_loss: 0.0037 - val_mae: 0.0600\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0105 - mae: 0.0896 - val_loss: 0.0054 - val_mae: 0.0682\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0115 - mae: 0.0954 - val_loss: 0.0074 - val_mae: 0.0742\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0127 - mae: 0.1011 - val_loss: 0.0092 - val_mae: 0.0861\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0138 - mae: 0.1043 - val_loss: 0.0101 - val_mae: 0.0924\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0142 - mae: 0.1053 - val_loss: 0.0102 - val_mae: 0.0937\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0140 - mae: 0.1041 - val_loss: 0.0094 - val_mae: 0.0904\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0132 - mae: 0.1014 - val_loss: 0.0081 - val_mae: 0.0831\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0120 - mae: 0.0972 - val_loss: 0.0064 - val_mae: 0.0727\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0105 - mae: 0.0916 - val_loss: 0.0046 - val_mae: 0.0600\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0092 - mae: 0.0854 - val_loss: 0.0031 - val_mae: 0.0463\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0081 - mae: 0.0787 - val_loss: 0.0019 - val_mae: 0.0376\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0074 - mae: 0.0738 - val_loss: 0.0011 - val_mae: 0.0292\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0071 - mae: 0.0693 - val_loss: 8.4464e-04 - val_mae: 0.0239\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0071 - mae: 0.0663 - val_loss: 8.7188e-04 - val_mae: 0.0245\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0073 - mae: 0.0668 - val_loss: 0.0011 - val_mae: 0.0291\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0076 - mae: 0.0687 - val_loss: 0.0013 - val_mae: 0.0322\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0078 - mae: 0.0696 - val_loss: 0.0014 - val_mae: 0.0337\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0078 - mae: 0.0695 - val_loss: 0.0014 - val_mae: 0.0339\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0076 - mae: 0.0685 - val_loss: 0.0013 - val_mae: 0.0326\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0072 - mae: 0.0667 - val_loss: 0.0011 - val_mae: 0.0303\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0066 - mae: 0.0641 - val_loss: 8.1331e-04 - val_mae: 0.0272\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0061 - mae: 0.0612 - val_loss: 6.0333e-04 - val_mae: 0.0235\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0056 - mae: 0.0598 - val_loss: 4.7344e-04 - val_mae: 0.0196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step - loss: 0.0896 - mae: 0.2818 - val_loss: 0.0557 - val_mae: 0.2150\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0154 - mae: 0.1046 - val_loss: 0.0144 - val_mae: 0.0887\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0167 - mae: 0.0948 - val_loss: 0.0083 - val_mae: 0.0783\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0324 - mae: 0.1505 - val_loss: 0.0076 - val_mae: 0.0783\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0326 - mae: 0.1545 - val_loss: 0.0063 - val_mae: 0.0651\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0219 - mae: 0.1195 - val_loss: 0.0073 - val_mae: 0.0592\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0109 - mae: 0.0803 - val_loss: 0.0128 - val_mae: 0.0896\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0061 - mae: 0.0613 - val_loss: 0.0213 - val_mae: 0.1321\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0082 - mae: 0.0764 - val_loss: 0.0286 - val_mae: 0.1594\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0129 - mae: 0.1013 - val_loss: 0.0310 - val_mae: 0.1680\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0153 - mae: 0.1098 - val_loss: 0.0274 - val_mae: 0.1569\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0137 - mae: 0.1033 - val_loss: 0.0204 - val_mae: 0.1318\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0098 - mae: 0.0838 - val_loss: 0.0136 - val_mae: 0.1016\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0064 - mae: 0.0616 - val_loss: 0.0084 - val_mae: 0.0682\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0058 - mae: 0.0604 - val_loss: 0.0056 - val_mae: 0.0467\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0075 - mae: 0.0699 - val_loss: 0.0046 - val_mae: 0.0445\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0091 - mae: 0.0791 - val_loss: 0.0043 - val_mae: 0.0440\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0091 - mae: 0.0785 - val_loss: 0.0046 - val_mae: 0.0414\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0076 - mae: 0.0706 - val_loss: 0.0056 - val_mae: 0.0452\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0057 - mae: 0.0620 - val_loss: 0.0071 - val_mae: 0.0622\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0047 - mae: 0.0550 - val_loss: 0.0091 - val_mae: 0.0773\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0047 - mae: 0.0521 - val_loss: 0.0110 - val_mae: 0.0890\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0052 - mae: 0.0567 - val_loss: 0.0120 - val_mae: 0.0943\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0057 - mae: 0.0621 - val_loss: 0.0116 - val_mae: 0.0922\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0055 - mae: 0.0625 - val_loss: 0.0102 - val_mae: 0.0848\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0049 - mae: 0.0582 - val_loss: 0.0084 - val_mae: 0.0732\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0041 - mae: 0.0522 - val_loss: 0.0066 - val_mae: 0.0593\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0035 - mae: 0.0471 - val_loss: 0.0051 - val_mae: 0.0454\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0033 - mae: 0.0437 - val_loss: 0.0042 - val_mae: 0.0389\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0037 - val_mae: 0.0365\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0036 - val_mae: 0.0387\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0036 - val_mae: 0.0390\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0040 - mae: 0.0493 - val_loss: 0.0039 - val_mae: 0.0372\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0044 - val_mae: 0.0357\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0033 - mae: 0.0449 - val_loss: 0.0052 - val_mae: 0.0423\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0030 - mae: 0.0415 - val_loss: 0.0063 - val_mae: 0.0524\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0074 - val_mae: 0.0613\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0029 - mae: 0.0400 - val_loss: 0.0083 - val_mae: 0.0680\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 0.0089 - val_mae: 0.0712\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0030 - mae: 0.0432 - val_loss: 0.0091 - val_mae: 0.0717\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0029 - mae: 0.0423 - val_loss: 0.0089 - val_mae: 0.0697\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0027 - mae: 0.0395 - val_loss: 0.0084 - val_mae: 0.0652\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0025 - mae: 0.0367 - val_loss: 0.0078 - val_mae: 0.0595\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0024 - mae: 0.0356 - val_loss: 0.0073 - val_mae: 0.0540\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0023 - mae: 0.0360 - val_loss: 0.0068 - val_mae: 0.0496\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0066 - val_mae: 0.0469\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0066 - val_mae: 0.0464\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0068 - val_mae: 0.0482\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0072 - val_mae: 0.0518\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0022 - mae: 0.0351 - val_loss: 0.0077 - val_mae: 0.0567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - loss: 0.2696 - mae: 0.4906 - val_loss: 0.0452 - val_mae: 0.1873\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1026 - mae: 0.2788 - val_loss: 0.0276 - val_mae: 0.1414\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0333 - mae: 0.1314 - val_loss: 0.0688 - val_mae: 0.2015\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0463 - mae: 0.1912 - val_loss: 0.1046 - val_mae: 0.2787\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0731 - mae: 0.2287 - val_loss: 0.1072 - val_mae: 0.2896\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0779 - mae: 0.2329 - val_loss: 0.0911 - val_mae: 0.2647\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0656 - mae: 0.2132 - val_loss: 0.0700 - val_mae: 0.2279\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0519 - mae: 0.1884 - val_loss: 0.0493 - val_mae: 0.1840\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0388 - mae: 0.1641 - val_loss: 0.0347 - val_mae: 0.1507\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0291 - mae: 0.1399 - val_loss: 0.0249 - val_mae: 0.1313\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0241 - mae: 0.1222 - val_loss: 0.0193 - val_mae: 0.1210\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0229 - mae: 0.1161 - val_loss: 0.0171 - val_mae: 0.1219\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0240 - mae: 0.1217 - val_loss: 0.0168 - val_mae: 0.1221\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0260 - mae: 0.1277 - val_loss: 0.0171 - val_mae: 0.1219\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0272 - mae: 0.1309 - val_loss: 0.0171 - val_mae: 0.1210\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0171 - val_mae: 0.1218\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0258 - mae: 0.1282 - val_loss: 0.0169 - val_mae: 0.1226\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0235 - mae: 0.1218 - val_loss: 0.0169 - val_mae: 0.1233\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0208 - mae: 0.1129 - val_loss: 0.0173 - val_mae: 0.1240\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0182 - mae: 0.1041 - val_loss: 0.0183 - val_mae: 0.1244\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0163 - mae: 0.0979 - val_loss: 0.0201 - val_mae: 0.1247\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0155 - mae: 0.0957 - val_loss: 0.0221 - val_mae: 0.1253\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0154 - mae: 0.0965 - val_loss: 0.0240 - val_mae: 0.1318\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0157 - mae: 0.0964 - val_loss: 0.0253 - val_mae: 0.1359\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0159 - mae: 0.0965 - val_loss: 0.0257 - val_mae: 0.1375\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0158 - mae: 0.0957 - val_loss: 0.0252 - val_mae: 0.1366\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0151 - mae: 0.0931 - val_loss: 0.0237 - val_mae: 0.1332\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0139 - mae: 0.0889 - val_loss: 0.0215 - val_mae: 0.1273\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0125 - mae: 0.0842 - val_loss: 0.0194 - val_mae: 0.1192\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0112 - mae: 0.0796 - val_loss: 0.0176 - val_mae: 0.1180\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0105 - mae: 0.0755 - val_loss: 0.0165 - val_mae: 0.1173\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0102 - mae: 0.0727 - val_loss: 0.0159 - val_mae: 0.1165\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0101 - mae: 0.0722 - val_loss: 0.0156 - val_mae: 0.1157\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0101 - mae: 0.0725 - val_loss: 0.0154 - val_mae: 0.1148\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0099 - mae: 0.0718 - val_loss: 0.0152 - val_mae: 0.1137\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0094 - mae: 0.0695 - val_loss: 0.0149 - val_mae: 0.1126\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0087 - mae: 0.0654 - val_loss: 0.0148 - val_mae: 0.1119\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0079 - mae: 0.0617 - val_loss: 0.0148 - val_mae: 0.1112\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0074 - mae: 0.0584 - val_loss: 0.0149 - val_mae: 0.1104\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0071 - mae: 0.0579 - val_loss: 0.0150 - val_mae: 0.1095\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0070 - mae: 0.0574 - val_loss: 0.0151 - val_mae: 0.1086\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0069 - mae: 0.0566 - val_loss: 0.0150 - val_mae: 0.1079\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0068 - mae: 0.0558 - val_loss: 0.0148 - val_mae: 0.1072\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0065 - mae: 0.0541 - val_loss: 0.0143 - val_mae: 0.1066\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0061 - mae: 0.0517 - val_loss: 0.0139 - val_mae: 0.1058\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0058 - mae: 0.0494 - val_loss: 0.0135 - val_mae: 0.1051\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0055 - mae: 0.0471 - val_loss: 0.0132 - val_mae: 0.1043\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0053 - mae: 0.0463 - val_loss: 0.0130 - val_mae: 0.1035\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0053 - mae: 0.0471 - val_loss: 0.0130 - val_mae: 0.1028\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0052 - mae: 0.0480 - val_loss: 0.0129 - val_mae: 0.1021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/pranavsharma/Desktop/VS/StockMarketAnanlysis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step - loss: 0.5536 - mae: 0.7343 - val_loss: 0.2807 - val_mae: 0.5290\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3928 - mae: 0.6187 - val_loss: 0.1824 - val_mae: 0.4260\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.2607 - mae: 0.5033 - val_loss: 0.1019 - val_mae: 0.3179\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1558 - mae: 0.3876 - val_loss: 0.0455 - val_mae: 0.2119\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0778 - mae: 0.2716 - val_loss: 0.0125 - val_mae: 0.1097\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0285 - mae: 0.1591 - val_loss: 7.7751e-04 - val_mae: 0.0270\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0053 - mae: 0.0561 - val_loss: 0.0050 - val_mae: 0.0652\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0039 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.1268\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0156 - mae: 0.1165 - val_loss: 0.0304 - val_mae: 0.1714\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0296 - mae: 0.1668 - val_loss: 0.0402 - val_mae: 0.1980\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0406 - mae: 0.1970 - val_loss: 0.0435 - val_mae: 0.2059\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0452 - mae: 0.2083 - val_loss: 0.0406 - val_mae: 0.1990\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0428 - mae: 0.2021 - val_loss: 0.0333 - val_mae: 0.1796\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0346 - mae: 0.1805 - val_loss: 0.0238 - val_mae: 0.1511\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0241 - mae: 0.1479 - val_loss: 0.0147 - val_mae: 0.1169\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0141 - mae: 0.1086 - val_loss: 0.0073 - val_mae: 0.0797\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0068 - mae: 0.0745 - val_loss: 0.0027 - val_mae: 0.0420\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0032 - mae: 0.0463 - val_loss: 9.8036e-04 - val_mae: 0.0244\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0033 - mae: 0.0417 - val_loss: 0.0015 - val_mae: 0.0370\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0060 - mae: 0.0608 - val_loss: 0.0032 - val_mae: 0.0485\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0097 - mae: 0.0808 - val_loss: 0.0050 - val_mae: 0.0639\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0129 - mae: 0.0973 - val_loss: 0.0060 - val_mae: 0.0714\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0145 - mae: 0.1052 - val_loss: 0.0060 - val_mae: 0.0712\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0141 - mae: 0.1040 - val_loss: 0.0051 - val_mae: 0.0644\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0121 - mae: 0.0951 - val_loss: 0.0036 - val_mae: 0.0521\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0092 - mae: 0.0798 - val_loss: 0.0022 - val_mae: 0.0423\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0062 - mae: 0.0632 - val_loss: 0.0012 - val_mae: 0.0331\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0037 - mae: 0.0489 - val_loss: 8.6929e-04 - val_mae: 0.0236\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0013 - val_mae: 0.0213\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0021 - mae: 0.0339 - val_loss: 0.0023 - val_mae: 0.0378\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0034 - val_mae: 0.0509\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0041 - mae: 0.0562 - val_loss: 0.0044 - val_mae: 0.0597\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0052 - mae: 0.0632 - val_loss: 0.0049 - val_mae: 0.0635\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0059 - mae: 0.0667 - val_loss: 0.0048 - val_mae: 0.0623\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0058 - mae: 0.0661 - val_loss: 0.0042 - val_mae: 0.0569\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0051 - mae: 0.0616 - val_loss: 0.0032 - val_mae: 0.0480\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0040 - mae: 0.0548 - val_loss: 0.0022 - val_mae: 0.0367\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0014 - val_mae: 0.0246\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0022 - mae: 0.0363 - val_loss: 9.7707e-04 - val_mae: 0.0209\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 8.4449e-04 - val_mae: 0.0249\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0019 - mae: 0.0315 - val_loss: 9.5970e-04 - val_mae: 0.0297\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0022 - mae: 0.0360 - val_loss: 0.0012 - val_mae: 0.0336\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0026 - mae: 0.0408 - val_loss: 0.0014 - val_mae: 0.0362\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0015 - val_mae: 0.0373\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0031 - mae: 0.0444 - val_loss: 0.0015 - val_mae: 0.0370\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0029 - mae: 0.0434 - val_loss: 0.0014 - val_mae: 0.0356\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0026 - mae: 0.0406 - val_loss: 0.0012 - val_mae: 0.0331\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0023 - mae: 0.0366 - val_loss: 0.0010 - val_mae: 0.0300\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0019 - mae: 0.0320 - val_loss: 9.5710e-04 - val_mae: 0.0266\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0017 - mae: 0.0297 - val_loss: 9.9361e-04 - val_mae: 0.0234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and preprocess the data\n",
    "#data = pd.read_csv('stock_prices.csv')  # Replace with your file\n",
    "data = yf.download('AVGO', start=\"2024-06-20\", end=\"2024-11-30\")\n",
    "closing_prices = data['Close']['AVGO'].values.reshape(-1, 1)\n",
    "\n",
    "ticker_id=[]\n",
    "NextDayPrediction=[]\n",
    "PreviousDayPrice= []\n",
    "EPS= []\n",
    "RMSE= []\n",
    "\n",
    "for i in ticker:\n",
    "    ticker_id.append(i)\n",
    "    data = yf.download(i, start=\"2024-06-20\", end=\"2024-11-21\")\n",
    "    closing_prices = data['Close'][i].values.reshape(-1, 1)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_prices = scaler.fit_transform(closing_prices)\n",
    "\n",
    "    # Create features and labels\n",
    "    def create_dataset(data, window_size):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - window_size):\n",
    "            X.append(data[i:i + window_size])\n",
    "            y.append(data[i + window_size])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    window_size = 90  # Use the past 10 days to predict the next day\n",
    "    X, y = create_dataset(scaled_prices, window_size)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build the ANN model\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)  # Output layer for predicting next day price\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    # Predict the next day's price\n",
    "    last_days = scaled_prices[-window_size:].reshape(1, -1)\n",
    "    predicted_price_scaled = model.predict(last_days)\n",
    "    predicted_price = scaler.inverse_transform(predicted_price_scaled)\n",
    "    \n",
    "    NextDayPrediction.append(predicted_price[0][0])\n",
    "    pd_price= closing_prices[-1][0]\n",
    "    PreviousDayPrice.append(pd_price)\n",
    "    EPS.append(NextDayPrediction-pd_price)\n",
    "\n",
    "    #print(f\"Predicted next day's price: {predicted_price[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_analysis= pd.DataFrame()\n",
    "ANN_analysis['ticker_id']= ticker_id\n",
    "ANN_analysis['NextDayPrediction']= NextDayPrediction\n",
    "ANN_analysis['PreviousDayPrice']= PreviousDayPrice\n",
    "ANN_analysis['EPS']= ANN_analysis['NextDayPrediction']-ANN_analysis['PreviousDayPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Line plot for prices\n",
    "# ax1.plot(analysis_df.index, analysis_df['PD_price'], label='Actual Price', color='blue')\n",
    "# ax1.plot(analysis_df.index, analysis_df['ND_Predictions'], label='Predicted Price', color='green', linestyle='--')\n",
    "ax1.plot(ANN_analysis.index, ANN_analysis['EPS'], label='EPS ', color='blue')\n",
    "ax1.set_xlabel('Ticker')\n",
    "ax1.set_ylabel('Price', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.set_xticks(ANN_analysis.index)  # Set tick positions\n",
    "ax1.set_xticklabels(ANN_analysis['ticker_id'], rotation=45)  # Optionally set tick labels with rotation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Bar plot for RMSE\n",
    "# ax2 = ax1.twinx()\n",
    "# bars = ax2.bar(analysis_df.index, analysis_df['RMSE'], alpha=0.3, label='RMSE', color='orange')\n",
    "# ax2.set_ylabel('RMSE', color='orange')\n",
    "# ax2.tick_params(axis='y', labelcolor='orange')\n",
    "# ax2.legend(loc='upper right')\n",
    "\n",
    "# # Add TickerID labels on top of bars\n",
    "# for bar, ticker_id in zip(bars, analysis_df['ticker_id']):\n",
    "#     ax2.text(\n",
    "#         bar.get_x() + bar.get_width() / 2,  # X-coordinate (center of the bar)\n",
    "#         bar.get_height(),                  # Y-coordinate (top of the bar)\n",
    "#         ticker_id,                         # TickerID to display\n",
    "#         ha='center', va='bottom', fontsize=9, rotation=45, color='black'\n",
    "#     )\n",
    "\n",
    "plt.title('EPS according to ANN ')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
